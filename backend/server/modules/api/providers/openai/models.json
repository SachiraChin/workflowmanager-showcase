{
  "default": {
    "api_endpoint": "responses",
    "supports": {
      "temperature": { "min": 0, "max": 2, "default": 1 },
      "max_tokens": { "max": 16384 },
      "vision": true,
      "structured_output": true,
      "reasoning_effort": false,
      "cache_control": false
    },
    "pricing": {
      "prompt_token": 0.0000025,
      "completion_token": 0.00001,
      "cached_token": 0.00000125
    }
  },
  "gpt-4o": {
    "api_endpoint": "responses",
    "supports": {
      "temperature": { "min": 0, "max": 2, "default": 1 },
      "max_tokens": { "max": 16384 },
      "vision": true,
      "structured_output": true,
      "reasoning_effort": false,
      "cache_control": false
    },
    "pricing": {
      "prompt_token": 0.0000025,
      "completion_token": 0.00001,
      "cached_token": 0.00000125
    }
  },
  "gpt-4o-mini": {
    "api_endpoint": "responses",
    "supports": {
      "temperature": { "min": 0, "max": 2, "default": 1 },
      "max_tokens": { "max": 16384 },
      "vision": true,
      "structured_output": true,
      "reasoning_effort": false,
      "cache_control": false
    },
    "pricing": {
      "prompt_token": 0.00000015,
      "completion_token": 0.0000006,
      "cached_token": 0.000000075
    }
  },
  "gpt-4.1": {
    "api_endpoint": "responses",
    "supports": {
      "temperature": { "min": 0, "max": 2, "default": 1 },
      "max_tokens": { "max": 32768 },
      "vision": true,
      "structured_output": true,
      "reasoning_effort": false,
      "cache_control": false
    },
    "pricing": {
      "prompt_token": 0.000002,
      "completion_token": 0.000008,
      "cached_token": 0.0000005
    }
  },
  "gpt-4.1-mini": {
    "api_endpoint": "responses",
    "supports": {
      "temperature": { "min": 0, "max": 2, "default": 1 },
      "max_tokens": { "max": 32768 },
      "vision": true,
      "structured_output": true,
      "reasoning_effort": false,
      "cache_control": false
    },
    "pricing": {
      "prompt_token": 0.0000004,
      "completion_token": 0.0000016,
      "cached_token": 0.0000001
    }
  },
  "gpt-5.2": {
    "api_endpoint": "responses",
    "supports": {
      "temperature": false,
      "max_tokens": { "max": 100000 },
      "vision": true,
      "structured_output": true,
      "reasoning_effort": { "values": ["low", "medium", "high"], "default": "medium" },
      "cache_control": true
    },
    "pricing": {
      "prompt_token": 0.000004,
      "completion_token": 0.000016,
      "cached_token": 0.000001
    }
  },
  "gpt-5.1": {
    "api_endpoint": "responses",
    "supports": {
      "temperature": false,
      "max_tokens": { "max": 100000 },
      "vision": true,
      "structured_output": true,
      "reasoning_effort": { "values": ["low", "medium", "high"], "default": "medium" },
      "cache_control": true
    },
    "pricing": {
      "prompt_token": 0.000004,
      "completion_token": 0.000016,
      "cached_token": 0.000001
    }
  },
  "gpt-5-mini": {
    "api_endpoint": "responses",
    "supports": {
      "temperature": false,
      "max_tokens": { "max": 65536 },
      "vision": false,
      "structured_output": true,
      "reasoning_effort": { "values": ["low", "medium", "high"], "default": "low" },
      "cache_control": true
    },
    "pricing": {
      "prompt_token": 0.0000012,
      "completion_token": 0.0000048,
      "cached_token": 0.0000003
    }
  },
  "o1": {
    "api_endpoint": "responses",
    "supports": {
      "temperature": false,
      "max_tokens": { "max": 100000 },
      "vision": true,
      "structured_output": true,
      "reasoning_effort": { "values": ["low", "medium", "high"], "default": "medium" },
      "cache_control": false
    },
    "pricing": {
      "prompt_token": 0.000015,
      "completion_token": 0.00006,
      "cached_token": 0.0000075
    }
  },
  "o1-mini": {
    "api_endpoint": "responses",
    "supports": {
      "temperature": false,
      "max_tokens": { "max": 65536 },
      "vision": false,
      "structured_output": true,
      "reasoning_effort": { "values": ["low", "medium", "high"], "default": "low" },
      "cache_control": false
    },
    "pricing": {
      "prompt_token": 0.000001,
      "completion_token": 0.000004,
      "cached_token": 0.0000005
    }
  },
  "o3": {
    "api_endpoint": "responses",
    "supports": {
      "temperature": false,
      "max_tokens": { "max": 100000 },
      "vision": true,
      "structured_output": true,
      "reasoning_effort": { "values": ["low", "medium", "high"], "default": "medium" },
      "cache_control": false
    },
    "pricing": {
      "prompt_token": 0.00001,
      "completion_token": 0.00004,
      "cached_token": 0.000005
    }
  },
  "o3-mini": {
    "api_endpoint": "responses",
    "supports": {
      "temperature": false,
      "max_tokens": { "max": 65536 },
      "vision": false,
      "structured_output": true,
      "reasoning_effort": { "values": ["low", "medium", "high"], "default": "low" },
      "cache_control": false
    },
    "pricing": {
      "prompt_token": 0.0000011,
      "completion_token": 0.0000044,
      "cached_token": 0.00000055
    }
  },
  "o4-mini": {
    "api_endpoint": "responses",
    "supports": {
      "temperature": false,
      "max_tokens": { "max": 100000 },
      "vision": true,
      "structured_output": true,
      "reasoning_effort": { "values": ["low", "medium", "high"], "default": "low" },
      "cache_control": false
    },
    "pricing": {
      "prompt_token": 0.0000011,
      "completion_token": 0.0000044,
      "cached_token": 0.00000055
    }
  },
  "gpt-4-turbo": {
    "api_endpoint": "completions",
    "supports": {
      "temperature": { "min": 0, "max": 2, "default": 1 },
      "max_tokens": { "max": 4096 },
      "vision": true,
      "structured_output": false,
      "reasoning_effort": false,
      "cache_control": false
    },
    "pricing": {
      "prompt_token": 0.00001,
      "completion_token": 0.00003,
      "cached_token": 0.000005
    }
  },
  "gpt-4": {
    "api_endpoint": "completions",
    "supports": {
      "temperature": { "min": 0, "max": 2, "default": 1 },
      "max_tokens": { "max": 8192 },
      "vision": false,
      "structured_output": false,
      "reasoning_effort": false,
      "cache_control": false
    },
    "pricing": {
      "prompt_token": 0.00003,
      "completion_token": 0.00006,
      "cached_token": 0.000015
    }
  },
  "gpt-3.5-turbo": {
    "api_endpoint": "completions",
    "supports": {
      "temperature": { "min": 0, "max": 2, "default": 1 },
      "max_tokens": { "max": 4096 },
      "vision": false,
      "structured_output": false,
      "reasoning_effort": false,
      "cache_control": false
    },
    "pricing": {
      "prompt_token": 0.0000005,
      "completion_token": 0.0000015,
      "cached_token": 0.00000025
    }
  }
}
