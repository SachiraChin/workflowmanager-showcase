# Provider Data Resolution - Revision 3 (Final)

## Summary

This revision presents the final solution based on iterative discussion. The
goal: remove the `api.fetch` module that exposes internal API endpoints and
replace with a secure, universal mechanism that leverages existing data/schema
matching patterns.

## Problem Statement

Step 3 of CC workflow has this security/architecture issue:

```json
// step.json - Module 2 (PROBLEMATIC)
{
  "module_id": "api.fetch",
  "inputs": {
    "url": "/wm-api/models/by_category",
    "base_url": "http://192.168.1.181:7860"
  },
  "outputs_to_state": { "response": "sd_model_categories" }
}
```

Display schema references it via Jinja2:
```json
"model_category": {
  "enum": "{{ state.sd_model_categories }}",
  ...
}
```

**Issues:**
1. Hardcoded internal API endpoint in workflow JSON
2. Security risk (workflow can call arbitrary URLs)
3. Inconsistent with other providers

## Key Insight: Provider Names From Prompts

The LLM output schema (`cc_image_prompts_schema.json`) already contains
provider names as keys under `prompts`:

```json
{
  "scene_title": "...",
  "key_moment": "...",
  "prompts": {
    "midjourney": { "prompt": "...", "style_notes": "..." },
    "leonardo": { "phoenix_1_0": { "prompt": "...", "style_notes": "..." } },
    "openai": { "prompt": "...", "camera_notes": "..." },
    "stable_diffusion": { "tag_prompt": "...", "natural_prompt": "...", ... }
  }
}
```

**Insight**: We don't need an explicit `providers` input - the module can
extract provider names from `prompts` keys.

## Final Solution: Co-located Provider Metadata

Inject `_provider_metadata` and `_generations` as sibling fields within each
provider node. This keeps data co-located and follows the 1:1 data/schema
matching pattern.

### Data Structure (After Module Processing)

```json
{
  "scene_title": "...",
  "key_moment": "...",
  "prompts": {
    "midjourney": {
      "_provider_metadata": {
        "versions": [
          { "key": "7", "label": "V7" },
          { "key": "6.1", "label": "V6.1" }
        ]
      },
      "_generations": [],
      "prompt": "Lorem nostrud adipisicing deserunt",
      "style_notes": "est aliquip voluptate proident magna"
    },
    "leonardo": {
      "_provider_metadata": {
        "models": [
          {
            "key": "de7d3faf-762f-48e0-b3b7-9d0ac3a3fcf3",
            "label": "Leonardo Phoenix 1.0",
            "styles": [...]
          }
        ]
      },
      "_generations": [],
      "phoenix_1_0": {
        "prompt": "veniam commodo ut incididunt consequat",
        "style_notes": "mollit ad dolore"
      }
    },
    "openai": {
      "_provider_metadata": {
        "models": [
          { "key": "gpt-image-1.5", "label": "GPT Image 1.5" },
          { "key": "gpt-image-1", "label": "GPT Image 1" }
        ]
      },
      "_generations": [],
      "prompt": "ut amet",
      "camera_notes": "proident tempor non culpa qui"
    },
    "stable_diffusion": {
      "_provider_metadata": {
        "categories": [
          {
            "id": "realistic",
            "name": "Realistic",
            "models": [
              {
                "checkpoint_name": "realisticVision_v51.safetensors",
                "model_name": "Realistic Vision V5.1",
                "params": { "sampler_combo": [...], "resolution": [...] }
              }
            ]
          }
        ]
      },
      "_generations": [],
      "tag_prompt": "aliqua minim",
      "natural_prompt": "ullamco minim occaecat labore dolor",
      "negative_prompt": "aliquip",
      "style_notes": "nulla cillum magna"
    }
  }
}
```

### Why This Works

1. **1:1 Data/Schema Matching**: `_provider_metadata` is a sibling field at
   the same level as `tag_prompt`, `style_notes`, etc. The display schema can
   have a matching field definition.

2. **Co-located Data**: Each provider's prompts, metadata, and generations are
   together in one object. No need to map across different top-level keys.

3. **Underscore Convention**: `_provider_metadata` and `_generations` are
   clearly "system-injected" vs LLM-generated fields.

4. **No Explicit Providers Input**: Module extracts providers from `prompts`
   keys automatically.

## WebUI Rendering Flow

Based on code analysis:

### Current Flow

```
MediaGenerationHost
  └─ SchemaRenderer (walks display schema)
       └─ ObjectSchemaRenderer (for prompts object)
            └─ For each provider (midjourney, leonardo, etc.):
                 └─ SchemaRenderer with render_as="tab.media[input_schema,...]"
                      └─ TabLayout wraps content
                           └─ InputSchemaComposer (manages input values)
                                ├─ InputSchemaRenderer (renders input fields)
                                └─ ImageGeneration (generation UI)
```

### Key Files

| File | Purpose |
|------|---------|
| `MediaGenerationHost.tsx` | Extracts `data` and `schema` from `display_data` |
| `SchemaRenderer.tsx` | Routes by `render_as` and `type` |
| `ObjectSchemaRenderer.tsx` | Matches `schema.properties` keys to `data` keys |
| `InputSchemaComposer.tsx` | Provides context for input value management |
| `InputSchemaRenderer.tsx` | Renders input fields from `input_schema` |

### Data Matching Pattern

From `ObjectSchemaRenderer.tsx` (lines 90-101):

```typescript
for (const [key, propSchema] of Object.entries(properties)) {
  const propUx = getUx(propSchema);
  const propDisplay = normalizeDisplay(propUx.display);
  if (propDisplay !== "hidden" && key in dataObj) {
    items.push({ key, value: dataObj[key], schema: propSchema, ux: propUx });
  }
}
```

**Key insight**: For each key in `schema.properties`, it looks for `data[key]`.
If present and not hidden, it renders. This is pure 1:1 matching by field name.

### InputSchemaComposer Data Flow

From `InputSchemaComposer.tsx` (lines 63-89):

```typescript
const [values, setValues] = useState<Record<string, unknown>>(() => {
  const initial: Record<string, unknown> = {};
  const dataRecord = (data || {}) as Record<string, unknown>;

  for (const [key, fieldSchema] of Object.entries(properties)) {
    // Value priority: source_data > source_field > data[key] > schema.default
    if (sourceData) {
      initial[key] = resolveTemplate(sourceData, dataRecord);
    } else if (sourceField && dataRecord[sourceField] !== undefined) {
      initial[key] = dataRecord[sourceField];
    } else {
      initial[key] = dataRecord[key] ?? schemaRecord.default;
    }
  }
  return initial;
});
```

**Key insight**: `InputSchemaComposer` receives the full `data` object for the
current node (e.g., `data.prompts.stable_diffusion`). This includes
`_provider_metadata` if we inject it there.

## Implementation: input_schema Accessing _provider_metadata

### The Challenge

Currently, `model_category.enum` uses:
```json
"enum": "{{ state.sd_model_categories }}"
```

This is resolved **server-side** by `Jinja2Resolver` before the display schema
is sent to the client. But with the new approach, `_provider_metadata` is
injected by the module AFTER schema resolution.

**Chicken-and-egg**: Schema templates resolve → Module runs → Metadata injected

### Solution: Client-Side Enum Resolution

Instead of server-side Jinja2 templates, use a marker that the client resolves:

```json
"model_category": {
  "type": "string",
  "title": "Category",
  "enum_from": "_provider_metadata.categories",
  "value_key": "id",
  "label_key": "name",
  "_ux": { "input_type": "select" }
}
```

**How it works:**

1. Display schema uses `enum_from` instead of `enum` template
2. `InputSchemaRenderer` (or a helper) sees `enum_from`
3. Looks up the path in the current data context: `data._provider_metadata.categories`
4. Uses result as enum options

### Alternative: Leverage Existing Patterns

The WebUI already has mechanisms for dynamic data:

1. **`source_field`**: Input values can come from a different field in data
2. **`source_data`**: Template with `{field}` placeholders resolved from data
3. **`computed` fields**: Virtual fields computed from data + templates
4. **`controls`**: Cascading select dependencies

We may be able to reuse one of these patterns for enum population.

### Recommended Approach: `enum_from` Convention

Add support for `enum_from` in the input schema select renderer:

```typescript
// In select input renderer
function getEnumOptions(fieldSchema, data) {
  if (fieldSchema.enum_from) {
    // Resolve path like "_provider_metadata.categories"
    return getNestedValue(data, fieldSchema.enum_from);
  }
  return fieldSchema.enum;
}
```

This is minimal, explicit, and follows existing patterns.

## Display Schema Changes

### Current (with state reference)

```json
"stable_diffusion": {
  "_ux": {
    "provider": "stable_diffusion",
    "render_as": "tab.media[input_schema,image_generation]",
    "input_schema": {
      "properties": {
        "model_category": {
          "enum": "{{ state.sd_model_categories }}",
          "value_key": "id",
          "label_key": "name"
        }
      }
    }
  },
  "properties": {
    "tag_prompt": { ... },
    "style_notes": { ... }
  }
}
```

### After (with co-located data)

```json
"stable_diffusion": {
  "_ux": {
    "provider": "stable_diffusion",
    "render_as": "tab.media[input_schema,image_generation]",
    "input_schema": {
      "properties": {
        "model_category": {
          "enum_from": "_provider_metadata.categories",
          "value_key": "id",
          "label_key": "name"
        }
      }
    }
  },
  "properties": {
    "_provider_metadata": {
      "_ux.display": false,
      "type": "object"
    },
    "_generations": {
      "_ux.display": false,
      "type": "array"
    },
    "tag_prompt": { ... },
    "style_notes": { ... }
  }
}
```

## Backend Changes

### media.generate Module

Modify `get_interaction_request()` in
`backend/server/modules/media/generate.py`:

```python
def get_interaction_request(self, inputs, context):
    prompts = inputs.get('prompts', {})
    schema = inputs.get('schema', {})
    title = self.get_input_value(inputs, 'title')

    # Extract providers from prompts keys
    providers = list(prompts.keys()) if isinstance(prompts, dict) else []

    # Inject provider metadata into each provider node
    enriched_prompts = {}
    for provider_name in providers:
        provider_data = prompts.get(provider_name, {})
        if isinstance(provider_data, dict):
            # Get metadata from provider interface
            metadata = self._get_provider_metadata(provider_name)

            # Inject as sibling fields
            enriched_prompts[provider_name] = {
                "_provider_metadata": metadata,
                "_generations": [],
                **provider_data
            }
        else:
            enriched_prompts[provider_name] = provider_data

    # Build data object
    data = {"prompts": enriched_prompts}
    if source_image:
        data["_source_image"] = source_image

    return InteractionRequest(...)

def _get_provider_metadata(self, provider_name: str) -> dict:
    """Fetch metadata from provider interface."""
    from backend.providers import get_provider

    provider = get_provider(provider_name)
    if provider:
        return provider.get_metadata()
    return {}
```

### Provider Interface

```python
# backend/providers/base.py
class BaseProvider(ABC):
    @abstractmethod
    def get_id(self) -> str:
        pass

    def get_metadata(self) -> dict:
        """
        Return provider metadata for UI rendering.

        Structure varies by provider:
        - stable_diffusion: { categories: [...] }
        - leonardo: { models: [...] }
        - openai: { models: [...] }
        - midjourney: { versions: [...] }
        """
        return {}
```

### Provider Implementations

```python
# backend/providers/stable_diffusion/provider.py
class StableDiffusionProvider(BaseProvider):
    def get_metadata(self) -> dict:
        # Fetch from local SD API
        response = httpx.get(f"{self.api_base}/wm-api/models/by_category")
        return {"categories": response.json()["categories"]}

# backend/providers/leonardo/provider.py
class LeonardoProvider(BaseProvider):
    def get_metadata(self) -> dict:
        return {
            "models": [
                {"key": "de7d3faf-...", "label": "Phoenix 1.0", "styles": [...]},
                ...
            ]
        }
```

## WebUI Changes

### InputSchemaRenderer Enhancement

Add `enum_from` support in the select input renderer:

```typescript
// In the component that renders select inputs
function resolveEnumOptions(
  fieldSchema: Record<string, unknown>,
  data: Record<string, unknown>
): unknown[] | undefined {
  // If enum_from is specified, resolve from data
  if (fieldSchema.enum_from) {
    const path = fieldSchema.enum_from as string;
    return getNestedValue(data, path);
  }
  // Otherwise use static enum
  return fieldSchema.enum as unknown[];
}

function getNestedValue(obj: Record<string, unknown>, path: string): unknown {
  return path.split('.').reduce(
    (current, key) => (current as Record<string, unknown>)?.[key],
    obj
  );
}
```

### Context for Data Access

`InputSchemaComposer` already receives `data` for the current node. We need to
pass this to child components so they can resolve `enum_from`:

```typescript
// InputSchemaContext additions
interface InputSchemaContextValue {
  // ... existing fields
  nodeData: Record<string, unknown>;  // Full data for current node
}
```

## step.json Changes

### Before

```json
{
  "step_id": "image_prompts",
  "modules": [
    { "module_id": "api.llm", ... },
    {
      "module_id": "api.fetch",
      "inputs": {
        "url": "/wm-api/models/by_category",
        "base_url": "http://192.168.1.181:7860"
      },
      "outputs_to_state": { "response": "sd_model_categories" }
    },
    { "module_id": "media.generate", ... }
  ]
}
```

### After

```json
{
  "step_id": "image_prompts",
  "modules": [
    { "module_id": "api.llm", ... },
    { "module_id": "media.generate", ... }
  ]
}
```

**Note**: The `api.fetch` module is removed entirely. Provider metadata is
fetched internally by the `media.generate` module.

## Files to Modify

### Backend

| File | Changes |
|------|---------|
| `backend/server/modules/media/generate.py` | Inject `_provider_metadata` |
| `backend/providers/base.py` | Add `get_metadata()` method |
| `backend/providers/stable_diffusion/provider.py` | Implement metadata fetch |
| `backend/providers/leonardo/provider.py` | Return static model list |
| `backend/providers/openai/provider.py` | Return static model list |
| `backend/providers/midjourney/provider.py` | Return static version list |

### Workflow

| File | Changes |
|------|---------|
| `workflows/cc/steps/3_image_prompts/step.json` | Remove `api.fetch` module |
| `workflows/cc/steps/3_image_prompts/schemas/cc_image_prompts_display_schema.json` | Add `_provider_metadata` field, change `enum` to `enum_from` |

### WebUI

| File | Changes |
|------|---------|
| `ui/webui/src/interactions/schema/input/InputSchemaContext.tsx` | Add `nodeData` to context |
| `ui/webui/src/interactions/schema/input/InputSchemaComposer.tsx` | Pass `data` to context |
| Select input component | Support `enum_from` resolution |

## Migration Notes

1. **Backwards Compatibility**: Existing `enum` with Jinja2 templates continues
   to work (resolved server-side). New `enum_from` is additive.

2. **Provider Registry**: May need to add provider registration mechanism if
   not already present.

3. **Error Handling**: If provider metadata fetch fails, should return empty
   object and let UI handle gracefully.

4. **Caching**: Provider metadata could be cached per-session to avoid repeated
   API calls for SD.

## Implementation Notes

### Stable Diffusion API

For Stable Diffusion, use the **existing API endpoint** currently in the
workflow:

```
GET http://192.168.1.181:7860/wm-api/models/by_category
```

This endpoint is moved from the workflow `api.fetch` module into the
`StableDiffusionProvider.get_metadata()` method. The API contract remains
unchanged.

### Provider Params to Support

All current UI params must be captured in `_provider_metadata`. Below is the
complete reference for each provider.

---

## Appendix: Complete Provider Params Reference

### Midjourney

| Param | Type | Values | Default |
|-------|------|--------|---------|
| `aspect_ratio` | select | 1:1, 16:9, 9:16, 4:3, 3:4, 3:2, 2:3 | 9:16 |
| `speed` | select | relaxed, fast, turbo | fast |
| `version` | select | 7, 6.1, 6, 5.2, niji6 | 7 |
| `stylization` | slider | 0-1000, step 10 | 100 |
| `weirdness` | slider | 0-3000, step 50 | 0 |
| `variety` | slider | 0-100, step 5 | 0 |

### Leonardo

| Param | Type | Values | Default |
|-------|------|--------|---------|
| `model_id` | select | (dynamic - models with nested styles/presets) | Phoenix 1.0 |
| `aspect_ratio` | select | 1:1, 16:9, 9:16, 4:3, 3:4, 3:2, 2:3 | 9:16 |
| `size` | select | small, medium, large | medium |
| `generation_mode` | select | fast, quality, ultra | fast |
| `style_uuid` | select | (cascading from model_id.styles) | - |
| `preset_style` | select | (cascading from model_id.presets) | - |
| `num_images` | select | 1, 2, 4 | 4 |
| `guidance_scale` | slider | 1-20, step 1 | 7 |
| `contrast` | select | 1.0, 1.3, 1.8, 2.5, 3.0, 3.5, 4.0, 4.5 | 3.0 |
| `num_inference_steps` | slider | 10-60, step 1 | 15 |
| `scheduler` | select | EULER_DISCRETE, EULER_ANCESTRAL_DISCRETE, LEONARDO, DPM_SOLVER, DDIM, KLMS, PNDM | EULER_DISCRETE |

**Leonardo Models (from current schema):**
- Leonardo Phoenix 1.0 (de7d3faf-...) - has styles
- Leonardo Phoenix 0.9 (6b645e3a-...) - has styles
- Lucid Origin (7b592283-...) - has styles
- Lucid Realism (05ce0082-...) - has styles
- Flux Dev (b2614463-...) - has styles
- Flux Schnell (1dd50843-...) - has styles
- FLUX.1 Kontext (28aeddf8-...) - has styles
- Leonardo Anime XL (e71a1c2f-...) - has presets
- Leonardo Lightning XL (b24e16ff-...) - has presets
- Leonardo Kino XL (aa77f04e-...) - has presets
- Leonardo Vision XL (5c232a9e-...) - has presets
- Leonardo Diffusion XL (1e60896f-...) - has presets
- SDXL 1.0 (16e7060a-...) - has presets
- SDXL 0.9 (b63f7119-...) - has presets
- AlbedoBase XL (2067ae52-...) - has presets
- RPG v5 (f1929ea3-...) - has presets
- 3D Animation Style (d69c8273-...) - has presets
- DreamShaper v7 (ac614f96-...) - has presets

**Styles** (for Phoenix/Lucid/Flux models): None, Cinematic, Cinematic Concept,
Creative, Dynamic, Fashion, HDR, Illustration, Bokeh, Macro, Minimalist, Moody,
Portrait, Portrait Fashion, Pro B&W Photography, Pro Color Photography,
Pro Film Photography, 3D Render, Ray Traced, Sketch (B&W), Sketch (Color),
Stock Photo, Vibrant, Graphic Design Pop Art, Graphic Design Vector

**Presets** (for XL models): NONE, BOKEH, CINEMATIC, CINEMATIC_CLOSEUP,
CREATIVE, FASHION, FILM, FOOD, HDR, LONG_EXPOSURE, MACRO

### OpenAI

| Param | Type | Values | Default |
|-------|------|--------|---------|
| `model` | select | gpt-image-1.5, gpt-image-1, gpt-image-1-mini | gpt-image-1-mini |
| `aspect_ratio` | select | 1:1, 2:3, 3:2 | 2:3 |
| `quality` | select | low, medium, high | medium |
| `num_images` | select | 1, 2, 4 | 4 |
| `background` | select | auto, opaque, transparent | auto |
| `output_format` | select | png, jpeg, webp | png |

### Stable Diffusion

| Param | Type | Values | Default |
|-------|------|--------|---------|
| `model_category` | select | (dynamic from API - starting point) | - |
| `checkpoint` | select | (cascading from category.models) | - |
| `sampler_combo` | select | (cascading from checkpoint.params) | - |
| `resolution` | select | (cascading from checkpoint.params) | - |
| `vae` | select | (cascading from checkpoint.params) | - |
| `hires` | select | (cascading from checkpoint.params) | - |
| `adetailer` | select | (cascading from checkpoint.params) | - |
| `batch_size` | select | 1, 2, 4 | 4 |

**Not in metadata** (comes from LLM output):
- `tag_prompt`, `natural_prompt`, `negative_prompt`, `style_notes`

**UI-only** (not a generation param):
- `prompt_type` - switches which prompt field to display

**Cascading hierarchy**: `model_category` → `checkpoint` → sampler/resolution/
vae/hires/adetailer. The metadata structure from the API must preserve this
hierarchy for the controls system to work.

