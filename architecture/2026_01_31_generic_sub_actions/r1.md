# Generic Sub-Actions Architecture

## Summary

The current sub-action implementation is tightly coupled to media generation
(`media.generate` module). We need a generic, schema-driven sub-action system
that allows any module to define sub-actions that can be triggered from within
an interaction without completing it.

**Use Case**: Step 2 (scene selection) needs a "regenerate scenes" sub-action
that calls the LLM, updates the scene options in-place, and lets the user
continue selecting without restarting the workflow.

## Problem Analysis

### Current Implementation Limitations

1. **Hardcoded Module Routing** (streaming.py:244-268)
   ```python
   if module_id == "media.generate":
       # Only media.generate is supported
   ```

2. **Media-Specific Payload** (SubActionRequest)
   - `provider`, `action_type`, `prompt_id`, `source_data`
   - These fields only make sense for media generation

3. **Tightly Coupled to Worker/TaskQueue**
   - All sub-actions go through TaskQueue → Worker → Media Actor
   - No path for synchronous/streaming LLM calls

4. **No Schema-Driven Definition**
   - Sub-actions are defined in step.json but server doesn't use schema
   - Server has hardcoded knowledge of what each action does

### What We Need

1. **Schema-defined sub-actions** - Module declares what actions it supports
2. **Generic execution path** - Server routes based on action definition
3. **Multiple execution modes** - Async (task queue) vs streaming (SSE)
4. **In-place data updates** - Update interaction data without completing it

## Design Options

### Option A: Module-Based Sub-Action Handlers

Each module that supports sub-actions implements a handler interface:

```
Module declares:
  - supported_sub_actions: [{id, inputs_schema, outputs_schema, mode}]
  - execute_sub_action(action_id, inputs, context) -> outputs

Server:
  - Looks up module from interaction
  - Calls module.execute_sub_action()
  - Returns result to client
```

**Pros**: Clean separation, modules own their behavior
**Cons**: Requires module code changes, less flexible

<!--I dont understand cons above, how come this is a con when next option also
need lots of code changes? if all solution have con, is it really con, it is
requirement for the implementation, there's no way out of it. also, how come
its not flexible? if anything B is less flexible compared to this is it not?
-->

### Option B: Action Type Registry (Recommended)

<!--I dont think works, this is still hardcoding different action types and
routing to modules, this essencially same thing as we have routing vise-->

Define action types that can be reused across modules:

```
Action Types (server-side registry):
  - "llm_generate": Call LLM with prompt template, return structured output
  - "media_generate": Enqueue media generation task (existing behavior)
  - "transform": Run data transformation pipeline

Step Schema:
  sub_actions: [
    {
      id: "regenerate",
      label: "Generate New Scenes",
      action_type: "llm_generate",
      config: {
        prompt_template: "prompts/scene_generation_user.txt",
        output_schema: "schemas/scene_concepts_schema.json",
        target_field: "scenes"  // Where to put results in interaction data
      }
    }
  ]
```

**Pros**: Reusable action types, schema-driven, no module code changes
**Cons**: Need to define and implement each action type

### Option C: Hybrid - Module + Action Type

<!--how come this is an option? this is something which has to be done for both
A and B, this is not an option, its part of both A and B, but with changes to
schema based on logic of A/B-->

Modules can either:
1. Handle sub-actions themselves (for complex cases)
2. Delegate to registered action types (for common patterns)

```
sub_actions: [
  {
    id: "regenerate",
    handler: "action_type",  // or "module"
    action_type: "llm_generate",
    config: {...}
  }
]
```

## Proposed Design (Option B with extensions)

<!--I think you didnt undestand the problenm at all, and didnt read enough to
differnt branches of the issue

1. In step 1 scene regen case, you missed to identify that the select_scene
   step itself doesnt generate data, they are generated at generate_scenes
   module. then there are 2 other modules which is required to happen before
   come to select scene. both of your solututions doesnt address issues like
   this.
2. for step all steps which has sub actions, and step 1, you didnt identify how
   all these changes connect to ui and how to expand or replace existing layout
   of the page. -->

### 1. Sub-Action Schema Definition

```json
{
  "sub_actions": [
    {
      "id": "regenerate_scenes",
      "label": "Generate New Scenes",
      "shortcut": "r",
      "loading_label": "Generating new scenes...",

      "action_type": "llm_generate",
      "execution_mode": "streaming",

      "config": {
        "input": {
          "$ref": "prompts/scene_generation_user.txt",
          "type": "jinja2"
        },
        "system": [
          {"$ref": "prompts/role_pet_storyteller.txt", "type": "text"},
          {"$ref": "prompts/scene_generation_system.txt", "type": "text"}
        ],
        "output_schema": {
          "$ref": "schemas/scene_concepts_schema.json",
          "type": "json"
        },
        "provider": "openai"
      },

      "result_mapping": {
        "target_path": "data.scenes",
        "merge_mode": "replace"
      },

      "feedback": {
        "enabled": true,
        "prompt": "What would you like different?",
        "inject_as": "user_feedback"
      }
    }
  ]
}
```

### 2. Action Type Registry

Server maintains registry of action type handlers:

| Action Type     | Execution Mode | Description                          |
|-----------------|----------------|--------------------------------------|
| llm_generate    | streaming      | Call LLM, stream tokens, return JSON |
| media_generate  | async          | Enqueue to TaskQueue, return task_id |
| transform       | sync           | Run pipeline transformation          |
| fetch           | sync           | Call external API                    |

### 3. Server Endpoint Changes

**New Generic Sub-Action Request:**

```python
class SubActionRequest(BaseModel):
    interaction_id: str
    action_id: str           # References sub_action.id in schema
    params: Dict[str, Any]   # Action-specific params (e.g., feedback)
```

**Endpoint Flow:**

```
POST /workflow/{id}/sub-action
  1. Find interaction by interaction_id
  2. Get sub_action config from interaction's module schema
  3. Look up action_type handler
  4. Execute handler with config + params
  5. Return result (or task_id for async)
```

### 4. Execution Modes

**Streaming Mode** (for LLM calls):
- Client connects to SSE endpoint
- Server streams progress/tokens
- Final result updates interaction data
- Client receives updated data

**Async Mode** (for media generation):
- Server enqueues task, returns task_id
- Client polls/streams task progress separately
- On completion, interaction data is updated

**Sync Mode** (for transforms):
- Server executes immediately
- Returns result in response body

### 5. Interaction Data Updates

Sub-actions need to update the interaction's display_data in-place:

```python
# After sub-action completes:
interaction_event = db.events.find_one({
    "data.interaction_id": interaction_id
})

# Update the data at target_path
updated_data = apply_result(
    current_data=interaction_event["data"]["display_data"]["data"],
    result=sub_action_result,
    target_path=config["result_mapping"]["target_path"],
    merge_mode=config["result_mapping"]["merge_mode"]
)

# Store updated interaction
db.events.update_one(
    {"_id": interaction_event["_id"]},
    {"$set": {"data.display_data.data": updated_data}}
)
```

## Questions for Review

1. **Execution Mode Selection**: Should `execution_mode` be explicit in schema
   or inferred from `action_type`?

2. **State Access**: LLM sub-actions need workflow state for Jinja templates.
   Should we pass full state or let schema declare required state keys?

3. **Result Mapping Complexity**: Is `target_path` + `merge_mode` sufficient?
   Cases to consider:
   - Replace entire array (scenes)
   - Append to array (generations)
   - Update specific item by index

4. **Error Handling**: If sub-action fails, should we:
   - Show error in UI and let user retry?
   - Revert to previous data?
   - Leave interaction in error state?

5. **Backward Compatibility**: How do we migrate existing `media.generate`
   sub-actions to new schema format?

## Files Affected

- `backend/server/api/routes/streaming.py` - Refactor sub-action endpoint
- `backend/server/api/models.py` - New SubActionRequest model
- `backend/server/engine/` - New action type handlers
- `workflows/cc/steps/2_scene_generation/step.json` - Add sub_actions
- `ui/webui/` - Handle new sub-action response format
- `contracts/` - Shared sub-action types

## Next Steps

1. Finalize schema format based on feedback
2. Implement action type registry
3. Refactor `/sub-action` endpoint
4. Add `llm_generate` action type
5. Migrate `media_generate` to new pattern
6. Update step 2 schema with sub_actions
7. Update WebUI to handle streaming sub-actions
