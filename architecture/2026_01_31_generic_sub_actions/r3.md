# Generic Sub-Actions Architecture - Revision 3

## Summary

Design a generic sub-action system that allows executing operations from within
an interaction without completing it. Two action types:

1. **`target_sub_action`**: Execute a mini-workflow of modules with state
   isolation, then merge results back to main state
2. **`self_sub_action`**: Invoke the current module's own `sub_action()` method
   (e.g., media generation)

## Core Rules

1. **Streaming-only**: Sub-action endpoint is always SSE. Client waits for
   stream completion to get final data.

2. **State Isolation**: All inner actions use `{{sub_action_id}}` replacement
   in state keys. This creates unique namespaces per execution. Results are
   only merged to main state via `result_mapping` at the end.

3. **Event Tracking**: Every sub-action creates events:
   - `sub_action_requested`: At start, stores input data
   - `sub_action_response`: At completion, stores result data
   - Event ID format: `{sub_action_id}_{uuid_v7}`

4. **No Type Mixing**: A sub_action uses either `target_sub_action` actions
   OR `self_sub_action`, not both in the same sub_action definition.

## Schema Format

### Type 1: target_sub_action (Mini-Workflow)

For running a chain of modules with isolated state:

```json
{
  "sub_actions": [
    {
      "id": "regenerate_scenes",
      "label": "Generate New Scenes",
      "loading_label": "Generating new scenes...",

      "actions": [
        {
          "type": "target_sub_action",
          "module_id": "api.llm",
          "ref": {
            "step_id": "scene_generation",
            "module_name": "generate_scenes"
          },
          "overrides": {
            "outputs_to_state": {
              "response": "scene_concepts_{{sub_action_id}}"
            }
          }
        },
        {
          "type": "target_sub_action",
          "module_id": "transform.query",
          "ref": {
            "step_id": "scene_generation",
            "module_name": "flatten_keywords"
          },
          "overrides": {
            "inputs": {
              "data": "{{ state.scene_concepts_{{sub_action_id}}.scenes }}"
            },
            "outputs_to_state": {
              "result": "flattened_keywords_{{sub_action_id}}"
            }
          }
        },
        {
          "type": "target_sub_action",
          "module_id": "io.weighted_keywords",
          "inputs": {
            "resolver_schema": {
              "type": "object",
              "properties": {
                "weighted_keywords": { "resolver": "server" }
              }
            },
            "mode": "save",
            "weighted_keywords": "{{ state.flattened_keywords_{{sub_action_id}} }}"
          },
          "outputs_to_state": {
            "saved_count": "keywords_saved_count_{{sub_action_id}}"
          },
          "name": "save_keywords_{{sub_action_id}}"
        }
      ],

      "result_mapping": {
        "source": "state.scene_concepts_{{sub_action_id}}",
        "target": "state.scene_concepts",
        "mode": "replace"
      },

      "feedback": {
        "enabled": true,
        "prompt": "What would you like different in the new scenes?",
        "state_key": "_retry_feedback"
      }
    }
  ]
}
```

**Action Resolution Rules:**

| Has `ref`? | Has full config? | Behavior |
|------------|------------------|----------|
| Yes | No | Load from ref, apply overrides |
| Yes | Yes | Load from ref, merge with config, apply overrides |
| No | Yes | Use config directly (must be valid module def) |
| No | No | Error: insufficient configuration |

### Type 2: self_sub_action (Module Self-Invocation)

For modules that implement their own `sub_action()` method:

```json
{
  "sub_actions": [
    {
      "id": "generate",
      "label": "Generate Images",
      "loading_label": "Generating...",

      "actions": [
        {
          "type": "self_sub_action",
          "params": {
            "action_type": "txt2img"
          }
        }
      ],

      "result_key": "generations"
    }
  ]
}
```

The module's `sub_action()` method receives:
- `sub_action_id`: Unique ID for this execution
- `params`: From action config
- `request_params`: From client request (provider, prompt_id, etc.)
- `context`: Execution context with state access

## Server Implementation

### 1. Sub-Action Endpoint (Streaming)

```python
@router.post("/{workflow_run_id}/sub-action")
async def execute_sub_action(
    workflow_run_id: str,
    request: SubActionRequest,
    db = Depends(get_db),
    processor = Depends(get_processor)
):
    """
    Execute a sub-action via SSE streaming.

    Request:
        interaction_id: Current interaction
        action_id: Sub-action ID from schema
        params: Client-provided parameters (feedback, provider, etc.)
    """
    # Generate unique sub_action_id
    sub_action_id = f"{request.action_id}_{uuid7().hex}"

    # Store sub_action_requested event

    <!--not, this meant to store all data, we probably need to come up with
    format so that everytime we add new field/action, we dont need to update
    this to make sure all data are included. for example, previous section you
    mentioned request_params, and its missing here.-->

    db.event_repo.store_event(
        workflow_run_id=workflow_run_id,
        event_type=DbEventType.SUB_ACTION_REQUESTED,
        event_id=sub_action_id,
        data={
            "sub_action_id": sub_action_id,
            "interaction_id": request.interaction_id,
            "action_id": request.action_id,
            "params": request.params
        }
    )

    async def event_generator():
        try:
            async for event in processor.execute_sub_action(
                workflow_run_id=workflow_run_id,
                sub_action_id=sub_action_id,
                <!--where does following 2 fields coming from?-->
                interaction_id=request.interaction_id,
                action_id=request.action_id,
                params=request.params
            ):
                yield {"event": event.type.value, "data": json.dumps(event.data)}

        except Exception as e:
            yield {"event": "error", "data": json.dumps({"message": str(e)})}

        finally:
            # Store sub_action_response event
            # (processor stores this with final result)
            pass

    return EventSourceResponse(event_generator())
```

### 2. Sub-Action Request Model

```python
<!--no need for backwards compatibility. applies for everything in the doc-->
class SubActionRequest(BaseModel):
    """Generic sub-action request."""
    interaction_id: str
    action_id: str
    params: Dict[str, Any] = {}

    # Legacy fields for backward compatibility during migration
    provider: Optional[str] = None
    action_type: Optional[str] = None
    prompt_id: Optional[str] = None
    source_data: Optional[Any] = None
```

### 3. Sub-Action Processor

```python
class SubActionProcessor:
    """Processes sub-action execution."""

    def __init__(self, db: Database, executor: WorkflowExecutor):
        self.db = db
        self.executor = executor

    async def execute_sub_action(
        self,
        workflow_run_id: str,
        sub_action_id: str,
        interaction_id: str,
        action_id: str,
        params: Dict[str, Any]
    ) -> AsyncIterator[StreamEvent]:
        """Execute sub-action and yield progress events."""

        # 1. Get interaction and module config
        interaction = self.db.event_repo.get_event_by_id(interaction_id)
        module_config = self._get_module_config(interaction)
        sub_action_def = self._find_sub_action(module_config, action_id)

        # 2. Determine action type
        actions = sub_action_def.get("actions", [])
        if not actions:
            raise ValueError(f"Sub-action '{action_id}' has no actions")

        first_action = actions[0]
        action_type = first_action.get("type")

        # 3. Route to appropriate handler
        if action_type == "target_sub_action":
            async for event in self._execute_target_sub_actions(
                workflow_run_id, sub_action_id, sub_action_def, params
            ):
                yield event

        elif action_type == "self_sub_action":
            async for event in self._execute_self_sub_action(
                workflow_run_id, sub_action_id, interaction,
                sub_action_def, params
            ):
                yield event

        else:
            raise ValueError(f"Unknown action type: {action_type}")

        # 4. Apply result_mapping
        result = await self._apply_result_mapping(
            workflow_run_id, sub_action_id, sub_action_def
        )

        # 5. Store completion event

        <!--i dont like the fact that two types of these events are stored in 2
        different contexts. it will just add to confusion. is there specific
        reason to first event store happen at request level?-->

        self.db.event_repo.store_event(
            workflow_run_id=workflow_run_id,
            event_type=DbEventType.SUB_ACTION_RESPONSE,
            event_id=sub_action_id,
            data={
                "sub_action_id": sub_action_id,
                "result": result
            }
        )

        # 6. Yield completion with updated data
        yield StreamEvent(
            type=EventType.COMPLETE,
            data={"sub_action_id": sub_action_id, "updated_data": result}
        )

    async def _execute_target_sub_actions(
        self,
        workflow_run_id: str,
        sub_action_id: str,
        sub_action_def: Dict,
        params: Dict
    ) -> AsyncIterator[StreamEvent]:
        """Execute target_sub_action chain (mini-workflow)."""

        actions = sub_action_def.get("actions", [])
        workflow = self.db.workflow_repo.get_workflow(workflow_run_id)
        workflow_def = get_workflow_def(workflow, self.db)

        # Inject feedback if provided
        if params.get("feedback"):
            feedback_key = sub_action_def.get("feedback", {}).get(
                "state_key", "_retry_feedback"
            )
            self.db.state_repo.set_state_value(
                workflow_run_id, feedback_key, params["feedback"]
            )

        # Execute each action sequentially

        <!-- why are we writing custom runner here, cant we just use existing
        workflow executor?-->

        for i, action in enumerate(actions):
            yield StreamEvent(
                type=EventType.PROGRESS,
                data={
                    "action_index": i,
                    "total_actions": len(actions),
                    "message": f"Executing action {i + 1}/{len(actions)}"
                }
            )

            # Resolve module configuration
            module_config = self._resolve_action_config(
                action, workflow_def, sub_action_id
            )

            # Execute module (reuse existing executor logic)
            module_outputs = self.db.state_repo.get_module_outputs(
                workflow_run_id
            )

            result = await self.executor.execute_single_module(
                workflow_run_id=workflow_run_id,
                module_config=module_config,
                module_outputs=module_outputs,
                sub_action_id=sub_action_id
            )

            # Yield module completion event
            yield StreamEvent(
                type=EventType.PROGRESS,
                data={
                    "action_index": i,
                    "status": "complete",
                    "module_id": module_config.get("module_id")
                }
            )

    def _resolve_action_config(
        self,
        action: Dict,
        workflow_def: Dict,
        sub_action_id: str
    ) -> Dict:
        """
        Resolve action to full module configuration.

        1. If ref exists, load base config from referenced module
        2. Merge with inline config (if any)
        3. Apply overrides
        4. Replace {{sub_action_id}} placeholders
        """
        config = {}

        # Load from ref if specified
        ref = action.get("ref")
        if ref:
            ref_config = self._load_module_from_ref(workflow_def, ref)
            config = deep_merge(config, ref_config)

        # Merge inline config
        for key in ["module_id", "inputs", "outputs_to_state", "name"]:
            if key in action:
                config[key] = action[key]

        # Apply overrides
        overrides = action.get("overrides", {})
        config = deep_merge(config, overrides)

        # Replace {{sub_action_id}} placeholders
        config = replace_placeholders(config, "{{sub_action_id}}", sub_action_id)

        return config

    async def _execute_self_sub_action(
        self,
        workflow_run_id: str,
        sub_action_id: str,
        interaction: Dict,
        sub_action_def: Dict,
        params: Dict
    ) -> AsyncIterator[StreamEvent]:
        """Execute self_sub_action (module's own sub_action method)."""

        # Get module instance
        module_id = interaction.get("data", {}).get("module_id")
        module = get_module_instance(module_id)

        if not hasattr(module, "sub_action"):
            raise ValueError(
                f"Module '{module_id}' does not implement sub_action()"
            )

        # Build context
        action = sub_action_def.get("actions", [{}])[0]
        action_params = action.get("params", {})

        context = SubActionContext(
            workflow_run_id=workflow_run_id,
            sub_action_id=sub_action_id,
            interaction_id=interaction.get("data", {}).get("interaction_id"),
            db=self.db,
            params={**action_params, **params}
        )

        # Execute module's sub_action method
        async for event in module.sub_action(context):
            yield event

    async def _apply_result_mapping(
        self,
        workflow_run_id: str,
        sub_action_id: str,
        sub_action_def: Dict
    ) -> Any:
        """Apply result_mapping to merge isolated state into main state."""

        mapping = sub_action_def.get("result_mapping")
        if not mapping:
            return None

        source_path = mapping["source"].replace(
            "{{sub_action_id}}", sub_action_id
        )
        target_path = mapping["target"]
        mode = mapping.get("mode", "replace")

        # Get source value
        source_value = self.db.state_repo.get_state_by_path(
            workflow_run_id, source_path
        )

        # Apply to target based on mode
        if mode == "replace":
            self.db.state_repo.set_state_by_path(
                workflow_run_id, target_path, source_value
            )
        elif mode == "merge":
            existing = self.db.state_repo.get_state_by_path(
                workflow_run_id, target_path
            )
            merged = deep_merge(existing, source_value)
            self.db.state_repo.set_state_by_path(
                workflow_run_id, target_path, merged
            )

        return source_value
```

### 4. Module Interface Extension

```python
class BaseModule:
    """Base class for all modules."""

    # ... existing methods ...

    async def sub_action(
        self,
        context: SubActionContext
    ) -> AsyncIterator[StreamEvent]:
        """
        Execute module-specific sub-action.

        Override this method to support self_sub_action type.
        Default implementation raises NotImplementedError.

        Args:
            context: Sub-action execution context

        Yields:
            StreamEvent: Progress and completion events
        """
        raise NotImplementedError(
            f"Module {self.module_id} does not implement sub_action()"
        )


class SubActionContext:
    """Context for sub-action execution."""

    def __init__(
        self,
        workflow_run_id: str,
        sub_action_id: str,
        interaction_id: str,
        db: Database,
        params: Dict[str, Any]
    ):
        self.workflow_run_id = workflow_run_id
        self.sub_action_id = sub_action_id
        self.interaction_id = interaction_id
        self.db = db
        self.params = params

    def get_state(self, key: str) -> Any:
        """Get value from workflow state."""
        return self.db.state_repo.get_state_value(
            self.workflow_run_id, key
        )

    def set_state(self, key: str, value: Any) -> None:
        """Set value in workflow state."""
        self.db.state_repo.set_state_value(
            self.workflow_run_id, key, value
        )
```

### 5. Media Generate Module Sub-Action

```python
class MediaGenerateModule(InteractiveModule):
    """Module for media generation interactions."""

    # ... existing methods ...

    async def sub_action(
        self,
        context: SubActionContext
    ) -> AsyncIterator[StreamEvent]:
        """
        Handle media generation sub-action.

        This replaces the hardcoded routing in streaming.py.
        """
        params = context.params

        # Validate required params
        provider = params.get("provider")
        action_type = params.get("action_type")
        prompt_id = params.get("prompt_id")

        if not provider or not action_type:
            raise ValueError("provider and action_type are required")

        yield StreamEvent(
            type=EventType.STARTED,
            data={"sub_action_id": context.sub_action_id}
        )

        # Enqueue task to worker
        queue = TaskQueue()
        task_id = queue.enqueue(
            actor="media",
            payload={
                "workflow_run_id": context.workflow_run_id,
                "interaction_id": context.interaction_id,
                "sub_action_id": context.sub_action_id,
                "provider": provider,
                "action_type": action_type,
                "prompt_id": prompt_id,
                "params": params.get("generation_params", {}),
                "source_data": params.get("source_data"),
            }
        )

        # Stream task progress
        async for event in self._stream_task(task_id):
            yield event

    async def _stream_task(self, task_id: str) -> AsyncIterator[StreamEvent]:
        """Stream task progress events."""
        # Implementation similar to existing task streaming
        ...
```

## Event Types

Add to `DbEventType`:

```python
class DbEventType(Enum):
    # ... existing types ...
    SUB_ACTION_REQUESTED = "sub_action_requested"
    SUB_ACTION_RESPONSE = "sub_action_response"
```

## UI Implementation

### 1. Sub-Action Types

```typescript
// Action types within a sub-action
interface TargetSubAction {
  type: "target_sub_action";
  module_id: string;
  ref?: {
    step_id: string;
    module_name: string;
  };
  inputs?: Record<string, unknown>;
  overrides?: Record<string, unknown>;
  outputs_to_state?: Record<string, string>;
  name?: string;
}

interface SelfSubAction {
  type: "self_sub_action";
  params?: Record<string, unknown>;
}

type SubActionAction = TargetSubAction | SelfSubAction;

// Sub-action configuration from schema
interface SubActionConfig {
  id: string;
  label: string;
  loading_label?: string;
  actions: SubActionAction[];
  result_mapping?: {
    source: string;
    target: string;
    mode: "replace" | "merge";
  };
  feedback?: {
    enabled: boolean;
    prompt: string;
    state_key: string;
  };
  // Legacy (for self_sub_action media generation)
  result_key?: string;
}
```

### 2. Generic Sub-Action Execution

```typescript
async function executeSubAction(
  workflowRunId: string,
  interactionId: string,
  actionId: string,
  params: Record<string, unknown>,
  onProgress: (event: SubActionProgressEvent) => void,
  onComplete: (result: SubActionResult) => void,
  onError: (error: Error) => void
): Promise<() => void> {
  // Always streaming
  return api.streamSubAction(
    {
      workflow_run_id: workflowRunId,
      interaction_id: interactionId,
      action_id: actionId,
      params,
    },
    (eventType, data) => {
      switch (eventType) {
        case "progress":
          onProgress(data as SubActionProgressEvent);
          break;
        case "complete":
          onComplete(data as SubActionResult);
          break;
        case "error":
          onError(new Error(data.message));
          break;
      }
    },
    onError
  );
}
```

### 3. Interaction Data Update

For `target_sub_action` (scene regeneration):

```typescript
const handleSubAction = async (action: SubActionConfig) => {
  setLoading(true);

  await executeSubAction(
    workflowRunId,
    interactionId,
    action.id,
    { feedback: userFeedback },
    // onProgress
    (event) => {
      setProgress({
        message: event.message,
        current: event.action_index,
        total: event.total_actions,
      });
    },
    // onComplete
    (result) => {
      // Update local data with result from server
      // The server has already applied result_mapping to workflow state
      setData(result.updated_data);
      setLoading(false);
    },
    // onError
    (error) => {
      setError(error.message);
      setLoading(false);
    }
  );
};
```

## Migration Path

### Phase 1: Infrastructure
1. Add `DbEventType.SUB_ACTION_REQUESTED/RESPONSE`
2. Add `SubActionProcessor` class
3. Add `sub_action()` method to `BaseModule`
4. Add `SubActionContext` class

### Phase 2: Refactor Endpoint
1. Update `/sub-action` endpoint to use `SubActionProcessor`
2. Keep legacy field support in `SubActionRequest`

### Phase 3: Media Generation Migration
1. Implement `sub_action()` in `MediaGenerateModule`
2. Update step 3, 5, 7 schemas to use `self_sub_action` format
3. Remove hardcoded routing from endpoint

### Phase 4: Scene Regeneration
1. Add `sub_actions` to step 2 `select_scene` module
2. Test `target_sub_action` chain execution
3. Update UI to handle data refresh

## Files Affected

**Server:**
- `backend/server/api/routes/streaming.py` - Refactor endpoint
- `backend/server/api/models.py` - Update SubActionRequest
- `backend/server/workflow/sub_action.py` - New: SubActionProcessor
- `backend/server/engine/module_interface.py` - Add sub_action() method
- `backend/server/modules/media/generate.py` - Implement sub_action()
- `backend/db/event_types.py` - Add new event types

**Workflows:**
- `workflows/cc/steps/2_scene_generation/step.json` - Add sub_actions
- `workflows/cc/steps/3_image_prompts/step.json` - Update to new format
- `workflows/cc/steps/5_video_generation/step.json` - Update to new format
- `workflows/cc/steps/7_music/step.json` - Update to new format

**UI:**
- `ui/webui/src/core/types.ts` - Sub-action types
- `ui/webui/src/core/api.ts` - Update streamSubAction
- `ui/webui/src/interactions/` - Generic sub-action handling

**Contracts:**
- `contracts/sub_action.py` - Shared types
