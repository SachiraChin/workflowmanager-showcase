<!--I dont feel like we address the core issue here, how are we going to make module update in-place. I feel like its easier say than done. look into current ux rendering
architechture and lets rewrite this doc again with aspect of both webui and server.-->
# Media Generation Workflow Integration Architecture

## Summary

Design for how media generation (images/videos via MidAPI, Leonardo) integrates with the existing workflow system. This is NOT about the API clients themselves (covered in separate doc), but about how users interact with media generation within workflows.

---

## The Use Case

### User Flow Example

**Step 2: Prompt Generation + Image Generation**
1. User sees generated prompts from previous module 
<!--I think this is misleading. Only way I can see this happening is, replace current prompt display with new module (image generation lets say),
which has access to previously generated prompts, and then run those prompts against provider.-->
2. User clicks "Generate Images" button (with MJ or Leonardo selected)
3. 4 images appear in a grid below the prompt
4. User can:
   - Adjust parameters (aspect ratio, style, etc.)
   - Adjust the prompt itself
   - Click "Generate" again → more images added to grid
5. User selects preferred image(s)
6. User clicks "Continue" → advances to next step

**Step 4: Video Generation**
1. Selected image from Step 2 is auto-loaded
2. User clicks "Generate Video"
3. Video appears
4. User can regenerate with different params
5. Analysis runs automatically on the video

### Key Characteristics

| Aspect | Behavior |
|--------|----------|
| Trigger | Button click, not automatic |
| Advances workflow? | No - user explicitly continues |
| Results | Accumulate (grid grows with each generation) |
| State | Carries forward (selected image → next step) |
| Display | Inline with existing module output |
| Iterations | Multiple generations per interaction |

---

## The Problem

### Current Module Behavior

```
InteractiveModule.get_interaction_request()
    → Client displays interaction UI
    → User provides response
    → Client calls /respond endpoint
    → InteractiveModule.execute_with_response()
    → Module completes, workflow advances
```

Every response advances the workflow. There's no concept of "do something without advancing."

### What We Need

```
InteractiveModule.get_interaction_request()
    → Client displays interaction UI
    → User clicks "Generate Images"          ← Sub-action (doesn't advance)
    → Client calls ??? endpoint
    → Images generated, added to display
    → User clicks "Generate Images" again    ← Another sub-action
    → More images added
    → User clicks "Continue"                 ← This advances workflow
    → InteractiveModule.execute_with_response()
    → Module completes
```

---

## Design Options

### Option A: Sub-Actions System

Add a new concept to interactions: **sub-actions** that don't advance workflow state.

**Interaction Request Changes:**

```python
@dataclass
class SubAction:
    action_id: str              # "generate_images"
    label: str                  # "Generate Images"
    handler: str                # "media.txt2img"
    default_params: dict        # Default generation params
    param_schema: dict          # JSON schema for adjustable params

@dataclass
class InteractionRequest:
    # ... existing fields ...
    sub_actions: List[SubAction] = None  # NEW
```

**New Endpoint:**

```
POST /workflow/{id}/action
{
    "action_id": "generate_images",
    "params": {
        "provider": "midapi",
        "prompt": "...",
        "aspect_ratio": "16:9"
    }
}
```

**Response:**
```json
{
    "action_id": "generate_images",
    "result": {
        "urls": ["...", "...", "...", "..."],
        "metadata_id": "cgm_xxx"
    }
}
```

Workflow state doesn't change. Client adds images to display.

**Pros:**
- Clean separation of concerns
- Reusable for other sub-action use cases
- Explicit in the interaction model

**Cons:**
- New infrastructure (endpoint, handlers, client support)
- Need to define how sub-action state is stored/retrieved

---

### Option B: Streaming Sub-Interactions

Use SSE stream to handle sub-interactions within an existing interaction.

Client stays connected to stream. Special events for sub-actions:

```
Event: sub_action_available
Data: { "action_id": "generate_images", "label": "Generate Images", ... }

[User clicks button]

Client sends: POST /workflow/{id}/sub-action
Server sends through stream:
Event: sub_action_started
Event: sub_action_progress
Event: sub_action_complete
Data: { "action_id": "generate_images", "result": { "urls": [...] } }
```

**Pros:**
- Leverages existing streaming infrastructure
- Real-time progress updates

**Cons:**
- More complex client implementation
- SSE connection must stay open
- Mixing concerns in the stream

---

### Option C: Module Handles It Internally

The module that displays prompts also handles media generation internally. No new workflow concepts.

```python
class PromptReviewModule(InteractiveModule):
    def get_interaction_request(self, inputs, context):
        return InteractionRequest(
            type=InteractionType.CUSTOM,
            display={
                "component": "prompt_review_with_media",
                "prompts": inputs["prompts"],
                "media_config": {
                    "providers": ["midapi", "leonardo"],
                    "operations": ["txt2img", "img2vid"]
                }
            }
        )
```

Client-side component handles:
- Rendering prompts
- Generate button clicks
- Calling media generation API directly (not through workflow)
- Displaying results

**Pros:**
- No workflow infrastructure changes
- Flexibility in client implementation

**Cons:**
- Client needs direct API access (auth, etc.)
- Generated content not tracked in workflow state
- Harder to carry state forward to later steps
- Less reusable

---

### Option D: Separate "Media Session" Concept

Media generation happens in a parallel "session" associated with the workflow run.

```
Workflow Run
├── Step 1: ...
├── Step 2: Prompt Review
│   └── Media Session (parallel)
│       ├── Generation 1: 4 images
│       ├── Generation 2: 4 images
│       └── Selected: image_id_xxx
├── Step 3: ...
```

Media session has its own endpoints:

```
POST /workflow/{id}/media-session/generate
GET /workflow/{id}/media-session/results
POST /workflow/{id}/media-session/select
```

When workflow advances, selected items from media session are injected into module inputs.

**Pros:**
- Clean separation
- Media state is explicit and queryable
- Easy to carry forward

**Cons:**
- New concept to manage
- Need to define lifecycle (when does session end?)
- Two parallel state systems

---

### Option E: Phased Approach (MVP First)

**Phase 1 (MVP):** Media generation is a separate step

```
Step 1: Generate prompts
Step 2: Select prompts for image generation (simple select module)
Step 3: Media generation step (new module, runs generation)
Step 4: Review generated images (select module)
Step 5: Video generation step
```

Uses existing module patterns. Less integrated but works now.

**Phase 2:** Add sub-actions for inline generation

Once we understand the patterns from Phase 1, implement proper sub-action system.

**Pros:**
- Delivers value quickly
- Learn from real usage
- No infrastructure changes initially

**Cons:**
- More steps for user
- Less elegant UX

---

## State Management Questions

Regardless of which option:

### 1. Where do generated images live during iteration?

Options:
- Temporary state on the interaction (lost if user refreshes)
- Saved to DB immediately (persisted)
- Hybrid (client state + periodic save)

### 2. How does selection carry to later steps?

Options:
- Module output includes selected items
- Workflow-level state (new concept)
- Media session state (Option D)

### 3. How is content associated with source prompt?

If user generates images for Prompt A and Prompt B, how do we track which images came from which prompt?

Options:
- Prompt ID in generation metadata
- Hierarchical: Prompt → Generations → Images
- Tags/labels

### 4. What happens on page refresh?

- Are accumulated images preserved?
- Can user continue where they left off?
- Is there a "draft" state?

---

## UI Component Requirements

Whatever backend we choose, the UI needs:

1. **Generate button** - triggers generation without form submit
2. **Parameter controls** - adjustable settings (aspect ratio, style, etc.)
3. **Image grid** - displays results, grows with each generation
4. **Selection mechanism** - user picks preferred image(s)
5. **Progress indicator** - generation takes time (30s - 2min)
6. **Continue button** - advances workflow with selections

---

## My Recommendation

**Start with Option E (MVP)**, but design storage schema to support Option A later.

**Rationale:**
1. Get working feature without infrastructure changes
2. Understand real usage patterns
3. Storage schema can be designed now to support future inline integration
4. Client team can build UI components
5. Iterate toward Option A based on learnings

**Immediate next steps:**
1. Finalize storage schema (supports both approaches)
2. Build API clients (MidAPI, Leonardo)
3. Build repository
4. Build MVP module (separate step)
5. Design Option A sub-actions (parallel track)

---

## Questions for Review

1. Does Option E (MVP first) make sense, or is inline integration a hard requirement?

2. Which sub-action approach (A, B, C, D) feels right for the eventual goal?

3. For state management: should generated images persist immediately, or is client-side state acceptable during iteration?

4. Is there existing UI infrastructure for button-triggered actions within interactions?
