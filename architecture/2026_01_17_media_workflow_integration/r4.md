# Media Generation Workflow Integration Architecture - R4

## Summary

Design for sub-action system enabling iterative media generation within workflow interactions. This revision addresses:

- Provider info comes from prompts (prompts are grouped by provider)
- Sub-action handler is a router, not a direct executor
- Layout is schema-driven with styling hints
- Each prompt generates independently

---

## Key Changes from R3

| Aspect | R3 | R4 |
|--------|----|----|
| Provider in config | Single `provider` field | No provider field - comes from prompt |
| Sub-action handler | Directly calls media client | Routes to executor via `media.{operation}` |
| Form layout | Fixed ParamForm component | Schema-driven with layout hints |
| Multiple prompts | Unclear handling | Each prompt generates independently |

---

## Data Model: Prompts with Provider Info

Prompts from previous step are grouped by provider:

```json
{
    "generated_prompts": [
        {
            "prompt_id": "p_001",
            "provider": "midapi",
            "prompt_text": "A serene mountain landscape at sunset...",
            "params": {
                "aspect_ratio": "16:9",
                "version": "7"
            }
        },
        {
            "prompt_id": "p_002",
            "provider": "midapi",
            "prompt_text": "A futuristic cityscape with neon lights...",
            "params": {
                "aspect_ratio": "16:9",
                "version": "7"
            }
        },
        {
            "prompt_id": "p_003",
            "provider": "leonardo",
            "prompt_text": "Abstract digital art with flowing colors...",
            "params": {
                "model_id": "leonardo-diffusion-xl"
            }
        }
    ]
}
```

<!--
Above is wrong, following is an example

{
  "prompts": {
    "sora": {
      "sora_1": "A contemplative person nestled in a cozy armchair, seen in partial profile at eye level, positioned in the left third of the frame mid-distance, relaxed posture with shoulders softened into layered blankets. They wear a woolen sweater with intricate knit patterns and muted warm colors, hair loosely tied back with a few strands softly framing their face, illuminated gently by the nearby lamp. Their hands rest calmly on an open journal on their lap, pen poised but not writing, clearly in a stopped pose, eyes lowered toward the page as if lost in quiet thought.\n\nA snug indoor room with exposed brick walls and a lightly worn wooden floor, composed in a soft cel-shaded, hand-drawn anime style. The armchair occupies the midground left, while on the right a small table holds a warm table lamp and scattered books and art supplies, with a shelf and small pottery vase in the background, all in soft morning anime light and gentle gradient shade. Foreground includes a hint of floorboards and blanket edges; background shows textured brick and a partial window frame on the far left, establishing depth layers. The lamp glow gently pulses, subtly brightening and dimming around its shade; a few loose hair strands near the subject’s face softly flutter; dust motes float and drift, glowing in the lamp’s warm light; journal pages show a faint, almost imperceptible rustling at the bottom edge. Warm amber light from the lamp casts soft, rounded shadows, creating a calm, introspective atmosphere with a palette of warm browns, creams, and muted reds against cooler brick and wood tones, stable exposure and consistent geometry throughout.",
      "sora_2": "A contemplative person nestled in a cozy armchair, rendered in ultra-cinematic cel-shaded, hand-drawn anime realism, seen in partial profile at eye level, placed in the left third of the frame in the midground. Their relaxed posture sinks into layered blankets, woolen sweater with intricate knit patterns catching soft gradients of lamplight, hair loosely tied back with a few strands framing the face. Hands rest gently on an open journal on their lap, pen poised delicately between fingers, body clearly in a stopped pose, not walking or standing, eyes lowered toward the page in thoughtful concentration.\n\nThe environment is a snug room with warm exposed brick walls and a lightly worn wooden floor with visible grain, composed with strong depth from foreground floorboards and blanket spill, to midground armchair and table, to background brick wall, shelf, and partial window frame on the left. A small table to the right of the armchair supports a warm table lamp, whose shade emits a gentle, rhythmic pulsation of light, plus scattered books and art supplies arranged in a soft painterly sprawl; a small pottery vase rests on a nearby shelf in the background, adding a quiet focal accent. The lamp glow softly pulses, breathing with gentle intensity; dust motes glow in volumetric rays around the lamp, drifting and floating through the warm air; a few loose strands of the subject’s hair subtly flutter as if stirred by a faint indoor current; the journal pages show a slight, slow rustling at their corners, shifting delicately. Cinematic anime lighting with deep yet soft shadows, warm amber and honey tones from the lamp contrasting the muted reds and browns of brick and wood, gentle gradients modeling forms, atmospheric depth with mild haze around the lamp, all maintaining a hand-drawn, cel-shaded look with soft anime gradients and grounded, intimate mood."
    },
    "leonardo": {
      "phoenix_1_0": "Primary subject: a contemplative person nestled in a cushioned armchair, seen in partial profile at eye level, placed in the left third of the frame midground, like an anime film still. They wear a woolen sweater with intricate knit texture, soft folds, and warm, earthy colors; their hair is loosely tied back, with a few strands gently framing the face, rendered with delicate lines and painterly gradient lighting. Their relaxed posture sinks into layered blankets draped over the chair arms, hands resting on an open journal laid across their lap, pen held lightly between fingers in a paused, non-writing pose, gaze lowered toward the page in quiet reflection.\n\nEnvironment and context: a snug indoor room with exposed brick walls painted with a hand-painted background feel, each brick softly defined with varied warm reds and browns, and a lightly worn wooden floor whose planks show subtle wood grain. The composition uses a mid-distance, eye-level camera, capturing the armchair on the left, a small side table with a warm table lamp on the right, and a slice of the room behind them. Foreground includes a narrow strip of floorboards and the edge of a blanket spilling over the front of the armchair; midground holds the subject, chair, and side table; background shows the textured brick wall, a partial window frame at the far left, and a shelf with a small pottery vase.\n\nObjects and motion anchors: on the small table to the right of the armchair, books and art supplies are scattered in an organic cluster, their covers and tools painted with soft edges, contributing to the lived-in feel. The table lamp, with a simple shade, glows warmly and its light gently pulses, a soft rhythmic brightening and dimming that casts painterly gradient lighting across the subject and journal. Dust motes shimmer in this lamplight, visible as tiny glowing particles drifting through volumetric light beams. A few loose strands of the subject’s hair subtly flutter in slow motion, suggesting a faint indoor air current. The journal pages show a slight, smooth rustling at the corners, a mild shifting that hints at an almost-turned page.\n\nLighting, color, and atmosphere: painterly gradient lighting emanates from the lamp on the right, creating warm amber highlights on the subject’s sweater, hands, and journal, and soft, elongated shadows on the blankets and wooden floor. The contrast between the warm lamplight and the slightly cooler, muted tones of the brick wall and wooden floor builds depth without harshness. The palette centers on warm browns, creams, and soft oranges, accented by the more saturated colors of the knitted sweater and the covers of a few books. Atmospheric depth is emphasized with gentle falloff and a faint haze around the lamp, dust motes glowing within volumetric beams. The scene feels like a quiet anime film still with a hand-painted background, emphasizing gentle growth, introspection, and a serene, lived-in warmth.",
      "anime_xl": "Primary subject: a contemplative person nestled in a cozy armchair, drawn as an anime illustration in a hand-drawn Japanese animation style, placed in the left third of the frame at eye level in the midground. Their body sinks into soft cushions and layered blankets, posture relaxed, shoulders slightly forward as they focus on journaling. They wear a woolen sweater with vivid knit micro-details—individual yarn strands, subtle pilling, and soft fabric folds—colored in warm, rich tones. Their hair is loosely tied back, with fine individual strands visible, a few wisps framing the face. The subject’s hands rest gently on an open journal in their lap, pen poised between delicate fingers, clearly in a paused, non-writing pose, eyes lowered in quiet concentration.\n\nEnvironment and context: the room is snug and intimate, with exposed brick walls providing warm, textured backdrop, and a lightly worn wooden floor with visible grain and scuffs grounding the space. The composition is a balanced mid-distance shot: the armchair and subject occupy the left midground, a small table and table lamp sit to the right midground, and a portion of the room’s interior fills the background. Foreground includes a strip of wooden floor and the edge of blankets spilling over the side of the armchair, adding layered depth. Background reveals the brick wall receding softly, a partial window frame on the far left, and a shelf with a small pottery vase, all rendered with subtle detail.\n\nObjects and motion anchors: on the small table to the right, books and art supplies are scattered—spines with tiny text lines, pens and brushes with crisp outlines, sketchbooks with visible page edges—adding micro-detail that enhances the anime illustration feel. The warm table lamp atop the table emits a gentle glow that slowly and softly pulses, its lampshade rim highlighted with shifting halos of light. Dust motes are clearly visible in the air around the lamp, glowing as they drift through thin volumetric light rays. A few loose strands of the subject’s hair subtly flutter, suggesting the faintest ambient movement. The journal pages rest open, their edges showing a slow, slight rustling at the corners, as if breathing with the room.\n\nLighting, color, and atmosphere: balanced lighting dominated by the warm lamp glow on the right, casting soft highlights on the subject’s face, hands, sweater texture, and the surface of the journal, while leaving the rest of the room in gentle, muted shadow. Colors are expressive and vibrant but not harsh: warm ambers, browns, and creams contrast with the natural reds of the brick and the golden wood floor, with the sweater providing a slightly more saturated focal accent. The atmosphere feels gently introspective, with subtle volumetric haze around the lamp, glowing dust particles, and soft gradients that separate foreground, midground, and background, all in vivid yet non-photoreal anime realism."
    },
    "midjourney": {
      "prompt_a": {
        "subject": "contemplative person in partial profile, nestled in cozy armchair, left third midground, relaxed posture in layered blankets, woolen sweater with knit patterns, hair loosely tied back, hands resting on open journal, pen poised",
        "environment": "snug indoor room, exposed brick walls, lightly worn wooden floorboards, eye-level mid-distance framing, armchair left, side table and lamp right, partial window frame left background, clear foreground–midground–background depth",
        "objects": "small side table with warm lamp, scattered books and art supplies, small pottery vase on rear shelf, cushions and blankets draped over chair, subtle clutter on table surface",
        "motion": "lamp glow gently pulsing, loose hair strands softly fluttering, journal page corners faintly rustling, overall scene calm and still",
        "atmosphere": "warm, dim, introspective, soft painterly calm, gentle contrast between lamp glow and muted brick tones",
        "particles": "dust particles glowing in the lamp’s volumetric light, backlit specks drifting slowly through warm amber rays"
      },
      "prompt_b": {
        "subject": "quiet journaling person in armchair, partially in profile, posture relaxed and inward, sweater sleeves slightly loose, hair tied back with soft wisps, hands cradling open journal in thoughtful pause",
        "environment": "intimate, safe room mood, exposed brick cocooning the space, worn wooden floor grounding it, armchair left, lamp and side table right, soft background shelf and window frame",
        "objects": "scatter of books and art supplies on side table, pottery vase as subtle accent on shelf, blankets spilling over chair arm, textured cushions supporting the subject",
        "motion": "lamp glow breathing with gentle pulsation, stray hair strands barely swaying, journal pages giving tiny rustling movements at corners",
        "atmosphere": "warm amber dimness, soft painterly shadows, soothing and reflective",
        "particles": "dust motes glowing in backlit lamp beams, tiny illuminated specks drifting through gentle volumetric haze"
      },
      "prompt_a_prose": "A contemplative person is the focal point, nestled deeply in a cozy armchair, seen in partial profile at eye level and positioned in the left third of the frame. Their relaxed posture sinks into layered blankets and cushions, shoulders slightly forward as they focus on their lap. They wear a woolen sweater with clear knit patterns and soft folds, in warm, muted tones. Their hair is loosely tied back, with a few delicate strands framing their face. Hands rest gently on an open journal across their lap, pen poised lightly between fingers, clearly in a paused, non-writing pose.\n\nThe environment is a snug, homey room rendered in a soft painterly anime style, with exposed brick walls providing warm texture and a lightly worn wooden floor with visible grain forming the base. The mid-distance, eye-level camera shows the armchair on the left midground, a small side table with a warm table lamp on the right, and a partial view of the room in the background, including a window frame on the far left and a shelf with a small pottery vase. Foreground includes a strip of floorboards and the edge of blankets spilling over the arm of the chair, while the brick wall and shelf recede into the background, maintaining clear depth layers.\n\nThe lamp on the side table glows warmly and its light gently pulses, subtly brightening and dimming to create a soft visual rhythm across the subject and journal. Books and art supplies are scattered on the tabletop, adding lived-in character without cluttering the frame. Dust motes glow in the lamp’s volumetric light beams, drifting slowly as backlit specks in the warm air. A few loose hair strands near the subject’s face softly flutter, and the corners of the journal pages show the slightest rustling motion, almost imperceptible but present. The atmosphere is warm and dim, with amber light contrasting against muted reds and browns of brick and wood, calm shadows, and a serene, introspective mood.",
      "prompt_b_prose": "A quiet figure curled into a cozy armchair becomes the center of a gentle, introspective moment, seen in partial profile at eye level and resting securely in the left third of the frame. Their body sinks effortlessly into soft cushions and blankets, posture relaxed and still, not walking or rising, simply held by the chair. A woolen sweater with intricate knit textures wraps them in warmth, and loosely tied-back hair allows a few delicate strands to frame their face. Hands cradle an open journal on their lap, pen lightly held in a paused grip as they linger in thought rather than writing.\n\nThe atmosphere is intimate and calm, an anime-style soft painterly scene that feels like a quiet evening of personal reflection. Exposed brick walls surround the room with warm texture, and a lightly worn wooden floor with visible grain grounds the space. The composition is a mid-distance, eye-level view: the armchair and subject occupy the left midground, while to the right a small table supports a warm table lamp, flanked by scattered books and art supplies that hint at creativity and ongoing projects. In the background, a partial window frame and a small pottery vase on a shelf add structure and subtle visual anchors.\n\nThe lamp’s glow slowly breathes, its light gently pulsing in intensity and casting soft gradients across the subject’s face, sweater, and journal pages. Dust motes shimmer in the air, glowing where the lamplight forms thin volumetric beams, their tiny specks drifting lazily through the warm atmosphere. A few loose strands of the subject’s hair move with a faint, almost invisible flutter, and the edges of the journal pages show a smooth, minimal rustling, as if barely stirred by the room’s quiet air. Warm amber tones from the lamp contrast with muted brick reds and wooden browns, soft shadows and blended edges enhancing the sense of gentle growth, inner strength, and peaceful solitude."
    },
    "stable_diffusion": {
      "prompt_a": "anime/lofi quiet hearth aesthetic, soft painterly gradients, clean cel shading, gentle atmospheric bloom.\n\nInclude the journaling person in the armchair and the warm table lamp fully visible in the same frame. Keep the subject’s partial profile, seated posture, and open journal in their lap accurate. Maintain the exposed brick wall and wooden floor surfaces without distortion or reinterpretation.\n\nPrimary subject: a contemplative person nestled in a cozy armchair, seen in partial profile at eye level, positioned in the left third of the frame at mid-distance. Their body sinks into plush cushions and layered blankets, with relaxed shoulders and a stopped, seated pose. A woolen sweater with intricate knit texture, soft folds, and warm earthy hues wraps their upper body. Hair is loosely tied back, with a few fine strands framing their face, edges softened by warm light. Their hands rest gently on an open journal laid across their lap, pen lightly held between fingers, the paper surface catching a warm sheen from the lamp.\n\nSecondary objects: a small side table stands to the right of the armchair, supporting a warm table lamp with a simple shade, plus a soft scatter of books and art supplies. Book covers have muted colors and crisp edges, art tools rest naturally around them. In the background, a narrow shelf holds a small pottery vase, and a partial window frame appears on the left, all proportionally scaled and clearly separated from the subject.\n\nEnvironment: a snug interior room with exposed brick walls, each brick subtly varied in warm reds and browns, mortar lines softly defined to avoid harsh edges. The lightly worn wooden floorboards run across the foreground, with visible grain and gentle scuffs, grounding the scene. Foreground includes floorboards and the front edge of blankets spilling over the armchair; midground holds the subject, chair, and side table; background contains the brick wall, shelf, and window frame, softened by atmospheric depth.\n\nComposition: mid-distance, eye-level camera, stable framing that includes the armchair on the left, table and lamp on the right, and a slice of the room behind. Clear silhouettes for the subject, chair, and lamp, with no cropping of the main figure. Depth layering is supported by subtle overlap and scale differences, with a calm, balanced layout.\n\nLighting and atmosphere: warm, soft lamplight provides the key illumination from the right, approximately 2800–3200K, casting gentle gradients across the subject’s sweater, face, and journal. Shadows are soft-edged, with mild bounce light returning from the floor and walls. The lamp glow gently pulses in brightness, creating slight shifts in highlight intensity on nearby surfaces. Dust motes are visible in thin volumetric beams near the lamp, small glowing particles that enhance depth. Hair strands near the subject’s face show subtle, slow fluttering motion. The journal pages exhibit slight, smooth rustling at the corners, with no distortion of text or lines. Color palette centers on warm ambers, browns, and creams, accented by the sweater’s richer tones, with soft atmospheric grading and no harsh contrast.\n\nMotion and technical notes: soft drift for dust particles, gentle pulsing of lamp glow, minimal movement in hair wisps and journal page edges. Keep walls, floor, furniture, and subject geometry stable and consistent, reinforcing textures to reduce flicker for sequential processing.",
      "prompt_b": "A quiet hearth anime/lofi interior rendered in a soft painterly style, with clean cel shading and gentle gradients, frames a single contemplative figure journaling in warm lamplight. The primary subject is a person nestled into a cozy armchair, seen in partial profile at eye level and positioned in the left third of the image. Their posture is relaxed and settled, clearly seated and not walking, shoulders sinking into cushions and layered blankets. A woolen sweater with intricate knit patterns wraps them in warmth, its yarn texture and soft folds catching subtle highlights. Their hair is loosely tied back, with a few fine strands gently framing the face. Hands rest on an open journal laid across their lap, pen lightly held in a paused grip, eyes directed toward the page in quiet reflection.\n\nThe setting is a snug room with exposed brick walls that carry warm, varied reds and browns, each brick softly defined to keep a hand-painted feel. The floor is lightly worn wood, boards running across the foreground with visible grain lines and small scuffs, grounding the composition. The camera sits at eye level, in a stable mid-distance view that encompasses the armchair and subject on the left, a small side table and warm table lamp on the right, and just enough of the background to establish a lived-in interior. In the back, a narrow shelf with a small pottery vase and part of a window frame add structure and depth, receding into slightly softer focus.\n\nOn the small table beside the armchair, books and art supplies lie in gentle disarray—muted book covers, sketchbooks with visible page edges, pens and brushes resting loosely, all rendered with clear shapes and soft edges. The lamp atop the table glows warmly, its light gently pulsing in brightness to create a slow, rhythmic breathing of illumination. This lamplight serves as the key light, in a warm amber range that washes across the subject’s sweater, skin, and the surface of the journal, while letting the brick wall and wooden floor fall into softer, dimmer tones.\n\nDust motes shimmer in the air around the lamp, glowing as they drift through thin volumetric light beams, each tiny particle contributing to the sense of depth and stillness. A few loose strands of the subject’s hair show subtle, slow fluttering, as if stirred by an almost imperceptible indoor current. The edges of the journal pages display a faint, smooth rustling motion, their corners shifting slightly without distorting their rectangular shape. Foreground elements remain crisp yet gentle, midground forms are well-structured, and the background softens into painterly gradients.\n\nThe overall mood is one of gentle growth and introspection, with warm amber light contrasting the muted brick reds and weathered wood browns. Soft shadows, balanced light, and delicate atmospheric haze around the lamp unify the scene. Forms stay clear and stable, silhouettes are well-defined, and subtle motion in light, hair, dust, and paper adds life without disturbing the calm, cinematic stillness of the moment.",
      "prompt_c": "photorealistic skin texture, hyperreal materials, harsh digital sharpness, strong motion blur, lens flare, chromatic aberration, heavy film grain, oversaturated neon colors, extreme contrast, blown-out highlights, deep black crush, distorted anatomy, warped furniture, fisheye perspective, tilted horizon, cluttered chaotic background, flat white walls, empty background, hard-edged shadows, glossy plastic look, gritty realism, glitch effects, pixelation, watercolor bleed, exaggerated chibi proportions"
    }
  }
}
-->

The **provider is a property of each prompt**, not a global config value.

---

## Module Configuration (Revised)

<!--Where does subactions come here?-->
```json
{
    "module_id": "media.generation",
    "inputs": {
        "title": "Generate Images for Prompts",
        "operation": "txt2img",
        "data": "{{ state.generated_prompts }}",
        "prompt_display_schema": "{{ step.prompt_display_schema }}",
        "param_schemas": {
            "midapi": "{{ step.midapi_param_schema }}",
            "leonardo": "{{ step.leonardo_param_schema }}"
        },
        "param_defaults": {
            "midapi": {
                "aspect_ratio": "16:9",
                "speed": "fast"
            },
            "leonardo": {
                "width": 1024,
                "height": 576
            }
        }
    }
}
```

**Changes:**
- Removed single `provider` field
- `param_schemas` is per-provider (MJ != Leonardo)
- `param_defaults` is per-provider

---

## Sub-Action Routing System
<!--
this implementation looks like a lot of routing action which is really hard to understand. 
multiple types of providers to figure out different actions. someone has to go up and down
code base multiple times to figure out how data flow works. can we do something simpler like below.

mediaActionRegistry = {
} // Dict<str, Tuple<class, str>> <-- ("media.midapi.txt2img, (MijourneyProvider, "txt2img"))

class ProviderBase
    def txt2img(...)

class MijourneyProvider(ProviderBase)

    __init__
        mediaActionRegistry.add("media.mj.txt2img", (MijourneyProvider, nameof(txt2img)))
    
    async def txt2img(...)
        ...

async def execute_sub_action_stream(
    workflow_run_id: str,
    request: SubActionRequest,
    db: Database
) -> AsyncGenerator[str, None]:
    """
    Execute media generation as sub-action.
    Stores results but does NOT change workflow state.
    """
    action_id = generate_action_id()

    yield sse_event("started", {"action_id": action_id})

    providerInfo =  mediaActionRegistry.get("media.{request.provider}.{request.action}")

    exec = providerInfo[0]().get(providerInfo[1])

    result = exec(request.params)

    // store data
    // streaming stuff
-->


### The Router Pattern

Sub-actions are **not limited to media generation**. The handler routes to the correct executor based on `action_type`:

```python
# server/workflow/sub_action/router.py

SUB_ACTION_ROUTES = {
    "media.txt2img": MediaTxt2ImgExecutor,
    "media.img2img": MediaImg2ImgExecutor,
    "media.img2vid": MediaImg2VidExecutor,
    # Future non-media sub-actions
    "analysis.sentiment": SentimentAnalysisExecutor,
    "transform.resize": ImageResizeExecutor,
}

async def route_sub_action(
    action_type: str,
    workflow_run_id: str,
    request: SubActionRequest,
    db: Database
) -> AsyncGenerator[str, None]:
    """
    Route sub-action to the appropriate executor.
    """
    if action_type not in SUB_ACTION_ROUTES:
        yield sse_event("error", {"error": f"Unknown action type: {action_type}"})
        return

    executor_class = SUB_ACTION_ROUTES[action_type]
    executor = executor_class(db)

    async for event in executor.execute(workflow_run_id, request):
        yield event
```

### Media Executor Base


```python
# server/workflow/sub_action/executors/media_base.py

class MediaExecutorBase:
    """Base class for media generation executors."""

    def __init__(self, db: Database):
        self.db = db

    async def execute(
        self,
        workflow_run_id: str,
        request: SubActionRequest
    ) -> AsyncGenerator[str, None]:
        action_id = generate_action_id()
        yield sse_event("started", {"action_id": action_id})

        try:
            # 1. Get the appropriate client for this prompt's provider
            client = self.get_media_client(request.provider)

            # 2. Execute generation (streaming progress)
            urls, raw_response = await self.execute_with_progress(
                client, request.params,
                progress_callback=lambda p: (yield sse_event("progress", p))
            )

            # 3. Store in database
            metadata_id, content_ids = await self.store_results(
                workflow_run_id, request, urls, raw_response
            )

            # 4. Complete
            yield sse_event("complete", {
                "urls": urls,
                "metadata_id": metadata_id,
                "content_ids": content_ids
            })

        except Exception as e:
            yield sse_event("error", {"error": str(e)})

    async def store_results(
        self,
        workflow_run_id: str,
        request: SubActionRequest,
        urls: List[str],
        raw_response: dict
    ) -> Tuple[str, List[str]]:
        """Store generation metadata and content."""
        metadata_id = self.db.content_repo.store_generation(
            workflow_run_id=workflow_run_id,
            interaction_id=request.interaction_id,
            prompt_id=request.prompt_id,          # Track which prompt
            provider=request.provider,             # From the prompt
            operation=self.operation,
            request_params=request.params,
            source_data=request.source_data,
            response_data=raw_response
        )

        content_ids = []
        for index, url in enumerate(urls):
            content_id = self.db.content_repo.store_content(
                metadata_id=metadata_id,
                workflow_run_id=workflow_run_id,
                index=index,
                provider_url=url,
                content_type=self.content_type
            )
            content_ids.append(content_id)

        return metadata_id, content_ids
```

### Txt2Img Executor

```python
# server/workflow/sub_action/executors/media_txt2img.py

class MediaTxt2ImgExecutor(MediaExecutorBase):
    operation = "txt2img"
    content_type = "image"

    def get_media_client(self, provider: str):
        if provider == "midapi":
            return MidAPIClient()
        elif provider == "leonardo":
            return LeonardoClient()
        raise ValueError(f"Unknown provider: {provider}")

    async def execute_with_progress(
        self,
        client,
        params: dict,
        progress_callback
    ) -> Tuple[List[str], dict]:
        # Execute with polling, yielding progress
        return await run_in_executor_with_progress(
            lambda: client.txt2img(params),
            progress_callback
        )
```

---

## Revised Sub-Action Request

```python
class SubActionRequest(BaseModel):
    interaction_id: str
    prompt_id: str              # Which prompt this is for
    provider: str               # From the prompt (midapi/leonardo)
    operation: str              # txt2img, img2vid, etc.
    params: Dict[str, Any]      # Generation parameters
    source_data: Any            # The full prompt data (for storage)
```

**Key change:** `prompt_id` is now explicit - we know which prompt triggered the generation.

---

## WebUI: Per-Prompt Generation

### Component Structure

```
MediaGenerationInteraction
├── For each prompt in data:
│   └── PromptCard
│       ├── PromptDisplay (the prompt text)
│       ├── ParamForm (schema-driven, provider-specific)
│       ├── GenerateButton
│       └── ImageGrid (generations for THIS prompt)
├── GlobalSelectionSummary (selected across all prompts)
└── [Continue button via InteractionFooter]
```

### Schema-Driven Layout with Styling Hints

The param schema includes layout information:

```json
{
    "type": "object",
    "x-layout": {
        "type": "grid",
        "columns": 2,
        "className": "param-form-grid"
    },
    "properties": {
        "aspect_ratio": {
            "type": "string",
            "enum": ["1:1", "16:9", "9:16", "4:3", "3:4"],
            "title": "Aspect Ratio",
            "default": "16:9",
            "x-layout": {
                "className": "span-1"
            }
        },
        "speed": {
            "type": "string",
            "enum": ["relaxed", "fast", "turbo"],
            "title": "Speed",
            "default": "fast",
            "x-layout": {
                "className": "span-1"
            }
        },
        "stylization": {
            "type": "integer",
            "minimum": 0,
            "maximum": 1000,
            "title": "Stylization",
            "default": 100,
            "x-layout": {
                "className": "span-2",
                "component": "slider"
            }
        },
        "version": {
            "type": "string",
            "enum": ["7", "6.1", "6", "niji6"],
            "title": "Model Version",
            "default": "7",
            "x-layout": {
                "className": "span-2"
            }
        }
    }
}
```

**Schema extensions (`x-*` fields):**
- `x-layout.type`: Layout type (grid, vertical, horizontal)
- `x-layout.columns`: For grid layout
- `x-layout.className`: CSS class for the container/field
- `x-layout.component`: Override default component (slider, color-picker, etc.)

### SchemaForm Component (Enhanced)

```typescript
// components/common/SchemaForm.tsx

interface Props {
    schema: JSONSchema;
    values: object;
    onChange: (values: object) => void;
    disabled?: boolean;
}

export function SchemaForm({ schema, values, onChange, disabled }: Props) {
    const layout = schema['x-layout'] || { type: 'vertical' };

    const containerClassName = clsx(
        'schema-form',
        layout.className,
        {
            'schema-form--grid': layout.type === 'grid',
            'schema-form--vertical': layout.type === 'vertical',
        }
    );

    const containerStyle = layout.type === 'grid'
        ? { gridTemplateColumns: `repeat(${layout.columns || 2}, 1fr)` }
        : undefined;

    return (
        <div className={containerClassName} style={containerStyle}>
            {Object.entries(schema.properties || {}).map(([key, fieldSchema]) => {
                const fieldLayout = fieldSchema['x-layout'] || {};

                return (
                    <div
                        key={key}
                        className={clsx('schema-form__field', fieldLayout.className)}
                    >
                        <SchemaField
                            name={key}
                            schema={fieldSchema}
                            value={values[key]}
                            onChange={(v) => onChange({ ...values, [key]: v })}
                            disabled={disabled}
                            component={fieldLayout.component}
                        />
                    </div>
                );
            })}
        </div>
    );
}
```

### MediaGenerationInteraction (Revised)

```typescript
// components/workflow/interactions/media-generation/MediaGenerationInteraction.tsx

interface Props {
    request: InteractionRequest;
    mode: InteractionMode;
}

export function MediaGenerationInteraction({ request, mode }: Props) {
    const { display_data } = request;
    const prompts = display_data.data; // Array of prompts with provider info

    // Generations grouped by prompt_id
    const [generationsByPrompt, setGenerationsByPrompt] = useState<
        Record<string, GenerationResult[]>
    >({});

    // Selected content IDs across all prompts
    const [selectedIds, setSelectedIds] = useState<string[]>([]);

    // Load existing generations on mount
    useEffect(() => {
        loadExistingGenerations(request.interaction_id);
    }, [request.interaction_id]);

    // Response builder
    const { updateProvider } = useInteractionProvider();
    useEffect(() => {
        updateProvider({
            getResponse: () => ({
                selected_content_ids: selectedIds,
                all_generations: Object.values(generationsByPrompt).flat()
                    .map(g => g.metadata_id)
            }),
            getState: () => ({ isValid: selectedIds.length > 0 })
        });
    }, [selectedIds, generationsByPrompt]);

    const handleGenerate = async (prompt: Prompt, params: object) => {
        // Get provider-specific param schema
        const paramSchema = display_data.param_schemas[prompt.provider];

        const stream = streamSubAction(workflowRunId, {
            interaction_id: request.interaction_id,
            prompt_id: prompt.prompt_id,
            provider: prompt.provider,
            operation: display_data.operation,
            params: { ...prompt.params, ...params }, // Merge prompt defaults + user params
            source_data: prompt
        });

        for await (const event of stream) {
            if (event.type === 'complete') {
                setGenerationsByPrompt(prev => ({
                    ...prev,
                    [prompt.prompt_id]: [
                        ...(prev[prompt.prompt_id] || []),
                        {
                            urls: event.data.urls,
                            metadata_id: event.data.metadata_id,
                            content_ids: event.data.content_ids,
                            params,
                            timestamp: Date.now()
                        }
                    ]
                }));
            }
            // Handle progress, errors...
        }
    };

    return (
        <div className="media-generation">
            {prompts.map(prompt => (
                <PromptCard
                    key={prompt.prompt_id}
                    prompt={prompt}
                    paramSchema={display_data.param_schemas[prompt.provider]}
                    paramDefaults={display_data.param_defaults[prompt.provider]}
                    generations={generationsByPrompt[prompt.prompt_id] || []}
                    selectedIds={selectedIds}
                    onSelectionChange={setSelectedIds}
                    onGenerate={(params) => handleGenerate(prompt, params)}
                />
            ))}

            {selectedIds.length > 0 && (
                <SelectionSummary
                    count={selectedIds.length}
                    prompts={prompts}
                    generationsByPrompt={generationsByPrompt}
                    selectedIds={selectedIds}
                />
            )}
        </div>
    );
}
```

### PromptCard Component

<!--i dont understand following, whole reason we wanted to add classes to input schema was to avoid something like this. whay are we doing this?-->
```typescript
// components/workflow/interactions/media-generation/PromptCard.tsx

interface Props {
    prompt: Prompt;
    paramSchema: JSONSchema;
    paramDefaults: object;
    generations: GenerationResult[];
    selectedIds: string[];
    onSelectionChange: (ids: string[]) => void;
    onGenerate: (params: object) => void;
}

export function PromptCard({
    prompt,
    paramSchema,
    paramDefaults,
    generations,
    selectedIds,
    onSelectionChange,
    onGenerate
}: Props) {
    const [params, setParams] = useState(paramDefaults);
    const [isGenerating, setIsGenerating] = useState(false);
    const [progress, setProgress] = useState<ProgressInfo | null>(null);

    const handleGenerate = async () => {
        setIsGenerating(true);
        try {
            await onGenerate(params);
        } finally {
            setIsGenerating(false);
            setProgress(null);
        }
    };

    return (
        <div className="prompt-card">
            {/* Provider badge */}
            <div className="prompt-card__provider">
                <ProviderBadge provider={prompt.provider} />
            </div>

            {/* Prompt display */}
            <div className="prompt-card__text">
                {prompt.prompt_text}
            </div>

            {/* Generation params - schema-driven */}
            <SchemaForm
                schema={paramSchema}
                values={params}
                onChange={setParams}
                disabled={isGenerating}
            />

            {/* Generate button */}
            <Button
                onClick={handleGenerate}
                disabled={isGenerating}
                className="prompt-card__generate"
            >
                {isGenerating
                    ? `Generating... ${progress?.message || ''}`
                    : 'Generate Images'
                }
            </Button>

            {/* Progress */}
            {isGenerating && progress && (
                <ProgressBar elapsed={progress.elapsed_ms} />
            )}

            {/* Generated images for this prompt */}
            {generations.length > 0 && (
                <MediaGrid
                    generations={generations}
                    selectedIds={selectedIds}
                    onSelectionChange={onSelectionChange}
                />
            )}
        </div>
    );
}
```

---

## Data Flow Summary (Revised)

```
┌─────────────────────────────────────────────────────────────────┐
│ Previous Module Output (state.generated_prompts)                 │
│                                                                 │
│ [                                                               │
│   { prompt_id: "p_001", provider: "midapi", prompt_text: "..." },│
│   { prompt_id: "p_002", provider: "midapi", prompt_text: "..." },│
│   { prompt_id: "p_003", provider: "leonardo", prompt_text: "..."}│
│ ]                                                               │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│ WebUI: MediaGenerationInteraction                               │
│                                                                 │
│ ┌─────────────────────────────────────────────────────────────┐ │
│ │ PromptCard (p_001, midapi)                                  │ │
│ │ ├── prompt_text                                             │ │
│ │ ├── SchemaForm (midapi_param_schema)                        │ │
│ │ ├── [Generate] button                                       │ │
│ │ └── ImageGrid (generations for p_001)                       │ │
│ └─────────────────────────────────────────────────────────────┘ │
│ ┌─────────────────────────────────────────────────────────────┐ │
│ │ PromptCard (p_002, midapi)                                  │ │
│ │ └── ... same structure ...                                  │ │
│ └─────────────────────────────────────────────────────────────┘ │
│ ┌─────────────────────────────────────────────────────────────┐ │
│ │ PromptCard (p_003, leonardo)                                │ │
│ │ ├── SchemaForm (leonardo_param_schema) ← Different schema   │ │
│ │ └── ... same structure ...                                  │ │
│ └─────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────┘
                              │
              [User clicks Generate on p_001]
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│ POST /workflow/{id}/sub-action/stream                           │
│                                                                 │
│ {                                                               │
│     "interaction_id": "int_xxx",                                │
│     "prompt_id": "p_001",        ← Which prompt                 │
│     "provider": "midapi",        ← From prompt                  │
│     "operation": "txt2img",                                     │
│     "params": { aspect_ratio: "16:9", ... },                    │
│     "source_data": { full prompt object }                       │
│ }                                                               │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│ Server: Sub-Action Router                                       │
│                                                                 │
│ route_sub_action("media.txt2img", ...)                          │
│     → MediaTxt2ImgExecutor.execute()                            │
│         → MidAPIClient.txt2img(params)                          │
│         → Store in content_generation_metadata                  │
│         → Store in generated_content                            │
│         → SSE: complete { urls, metadata_id, content_ids }      │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│ WebUI: Update generationsByPrompt["p_001"]                      │
│                                                                 │
│ ImageGrid for p_001 now shows the generated images              │
│ User can select images, generate more, or continue              │
└─────────────────────────────────────────────────────────────────┘
```

---

## Database Storage (Updated)

```
content_generation_metadata
├── content_generation_metadata_id: "cgm_{uuid7}"
├── workflow_run_id: str
├── interaction_id: str
├── prompt_id: str               ← NEW: Which prompt triggered this
├── provider: "midapi" | "leonardo"
├── operation: "txt2img" | "img2img" | ...
├── request_params: jsonb
├── source_data: jsonb           ← Full prompt data
├── response_data: jsonb
├── created_at, completed_at, status, error_message, credits_used

generated_content
├── generated_content_id: "gc_{uuid7}"
├── workflow_run_id: str
├── content_generation_metadata_id: str (FK)
├── index: int
├── content_type: "image" | "video"
├── provider_url: str
├── local_path: str (nullable)
```

---

## Questions for Review

1. **Schema extensions (`x-layout`):** Is the `x-*` pattern acceptable for layout hints in JSON Schema, or should we use a separate layout definition?
<!--as long this works without forther work, its fine. if we have to write custom engine to read this data and conver it to
what ever lib we use now, then its wrong.-->

2. **PromptCard expansion:** Should the param form be collapsed by default and expand on click, or always visible?
<!--this is wrong-->

3. **Concurrent generations:** Can user generate for multiple prompts simultaneously, or should we queue them?
<!--we probably need queue system. but it can be separate design-->

4. **Selection across prompts:** When user selects images from multiple prompts, how should this be displayed/summarized before continuing?
<!--no, user can only select 1 image across all prompts atm, multi selection of images not allowed.-->
