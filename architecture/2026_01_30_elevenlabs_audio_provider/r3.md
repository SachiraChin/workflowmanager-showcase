# ElevenLabs Integration - Revision 3: Step 7 Workflow Restructure

## Summary

Restructure CC workflow Step 7 (Music) to simplify the flow from 4 modules
to 2 modules, combining prompt generation with actual music generation via
the ElevenLabs provider.

## Current Flow (4 Modules)

```
[Module 1: api.llm]
    Generate 5 music "concepts" (name, bpm, key, instruments, mood, energy)
         ↓
[Module 2: user.select]
    User selects 1 concept
         ↓
[Module 3: api.llm]
    Convert concept → 3 prompt variations (precise, evocative, voiceover)
         ↓
[Module 4: user.select (review mode)]
    User reviews prompts (NO actual music generation)
```

**Issues:**
- Two LLM calls when one would suffice
- Intermediate selection step adds friction
- Three prompt "types" (precise/evocative/voiceover) are arbitrary distinctions
- No actual music generation happens

## Proposed Flow (2 Modules)

```
[Module 1: api.llm]
    Generate 3 complete, ready-to-use music prompts
    Each prompt includes: instruments, mood, energy, style description
         ↓
[Module 2: media.generate]
    - 3 tabs (one per prompt option)
    - Editable prompt text + adjustable params (BPM, duration, format)
    - Generate button → ElevenLabs txt2audio
    - Audio player for preview
    - Select final track
```

## Technical Specification

### 1. LLM Output Schema

**File:** `schemas/cc_music_prompts_schema.json`

```json
{
  "type": "object",
  "properties": {
    "prompts": {
      "type": "array",
      "minItems": 3,
      "maxItems": 3,
      "items": {
        "type": "object",
        "properties": {
          "name": {
            "type": "string",
            "description": "Short evocative name (2-4 words)"
          },
          "prompt": {
            "type": "string",
            "description": "ElevenLabs-ready prompt (150-250 chars)"
          },
          "suggested_bpm": {
            "type": "integer",
            "description": "Suggested BPM (user can adjust)",
            "minimum": 50,
            "maximum": 120
          },
          "instruments": {
            "type": "string",
            "description": "Comma-separated instruments for display"
          },
          "mood": {
            "type": "string",
            "description": "Mood description for display"
          }
        },
        "required": ["name", "prompt", "suggested_bpm", "instruments", "mood"]
      }
    }
  },
  "required": ["prompts"]
}
```

### 2. LLM System Prompt

**File:** `prompts/cc_music_prompts_system.txt`

Combines current `cc_music_system.txt` and `cc_elevenlabs_system.txt`:
- Role: Pet video music director
- ElevenLabs prompt best practices
- Generate 3 distinct style options directly as prompts
- Include all musical elements inline (instruments, texture, mood)
- Suggest appropriate BPM based on scene energy

### 3. Display Schema for media.generate

**File:** `schemas/cc_audio_generation_display_schema.json`

```json
{
  "type": "object",
  "_ux.display": "passthrough",
  "properties": {
    "prompts": {
      "type": "array",
      "_ux": {
        "render_as": "tabs",
        "tab_key": "name"
      },
      "items": {
        "type": "object",
        "_ux": {
          "render_as": "tab.media[input_schema,audio_generation]",
          "provider": "elevenlabs",
          "prompt_id_field": "name",
          "input_schema": {
            "type": "object",
            "_ux": {
              "layout": "grid",
              "layout_columns": 3
            },
            "properties": {
              "_text": {
                "type": "string",
                "title": "Prompt",
                "destination_field": "prompt",
                "_ux": {
                  "input_type": "textarea",
                  "col_span": "full",
                  "rows": 4,
                  "source_field": "prompt"
                }
              },
              <!--note that user select duration in step 6, we must set that as default value here-->
              "duration_ms": {
                "type": "integer",
                "title": "Duration",
                "minimum": 10000,
                "maximum": 120000,
                "step": 5000,
                "_ux": {
                  "input_type": "slider",
                  "format": "duration_seconds",
                  "source_data": "{{ state.duration_selection.sound_track_duration * 1000 }}"
                }
              },
              "bpm": {
                "type": "integer",
                "title": "BPM",
                "minimum": 50,
                "maximum": 120,
                "step": 1,
                "_ux": {
                  "input_type": "slider",
                  "source_field": "suggested_bpm"
                }
              },
              "force_instrumental": {
                "type": "boolean",
                "title": "Instrumental Only",
                "default": true,
                "_ux": {
                  "input_type": "checkbox"
                }
              },
              "output_format": {
                "type": "string",
                "title": "Quality",
                "enum": ["mp3_44100_64", "mp3_44100_128"],
                "default": "mp3_44100_128",
                "enum_labels": {
                  "mp3_44100_64": "64kbps (Smaller)",
                  "mp3_44100_128": "128kbps (Standard)"
                },
                "_ux": {
                  "input_type": "select"
                }
              }
            }
          }
        },
        "properties": {
          "name": {
            "type": "string",
            "_ux.display": false
          },
          "prompt": {
            "type": "string",
            "_ux.display": false
          },
          "suggested_bpm": {
            "type": "integer",
            "_ux.display": false
          },
          "instruments": {
            "type": "string",
            "_ux": {
              "display": true,
              "display_label": "Instruments",
              "highlight": true,
              "highlight_color": "#9B59B6"
            }
          },
          "mood": {
            "type": "string",
            "_ux": {
              "display": true,
              "display_label": "Mood",
              "highlight": true,
              "highlight_color": "#3498DB"
            }
          }
        }
      }
    }
  }
}
```

### 4. Step JSON Structure

**File:** `step.json` (restructured)

```json
{
  "step_id": "music",
  "name": "Step {step_number}: Music Generation",
  "description": "Generate and select background music for your pet video",
  "modules": [
    {
      "module_id": "api.llm",
      "inputs": {
        "input": { "$ref": "prompts/cc_music_prompts_user.txt" },
        "system": [
          { "$ref": "prompts/cc_role_pet_music_director.txt" },
          { "$ref": "prompts/cc_music_prompts_system.txt" }
        ],
        "output_schema": { "$ref": "schemas/cc_music_prompts_schema.json" }
      },
      "outputs_to_state": {
        "response": "music_prompts"
      },
      "name": "generate_music_prompts"
    },
    {
      "module_id": "media.generate",
      "inputs": {
        "prompts": "{{ state.music_prompts.prompts }}",
        "schema": { "$ref": "schemas/cc_audio_generation_display_schema.json" },
        "title": "Generate and Select Music"
      },
      "outputs_to_state": {
        "selected_content_id": "selected_audio_id",
        "selected_content": "selected_audio_data",
        "generations": "audio_generations"
      },
      "sub_actions": [
        {
          "id": "generate_music",
          "label": "Generate Music",
          "action_type": "txt2audio",
          "loading_label": "Generating music..."
        }
      ],
      "retryable": {
        "default_option": "continue",
        "options": [
          { "id": "continue", "mode": "continue", "label": "Accept and continue" },
          {
            "id": "retry",
            "mode": "retry",
            "label": "Regenerate music prompts",
            "target_module": "generate_music_prompts",
            "feedback": { "enabled": true }
          }
        ]
      },
      "name": "generate_and_select_music"
    }
  ]
}
```

## Backend Changes Required

### 1. MediaActor (worker)

Add `txt2audio` handling in `backend/worker/actors/media.py`:

```python
# In action_type dispatch (around line 186)
elif action_type == "txt2audio":
    result = method(prompt, method_params, progress_callback=progress_callback)

# Content type determination (around line 213)
elif action_type == "txt2audio":
    content_type = "audio"
```

### 2. Download Utility

Verify `backend/providers/media/download.py` handles audio MIME types:
- `audio/mpeg` → `.mp3`
- Data URI handling for base64 audio

## WebUI Changes Required

### 1. New Component: AudioGeneration.tsx

Location: `ui/webui/src/interactions/types/media-generation/AudioGeneration.tsx`

Similar structure to `ImageGeneration.tsx` but with:
- Audio player instead of image grid
- Duration/cost preview instead of resolution
- Play/pause controls
- Track list (not thumbnail grid)

### 2. Waveform Library (Optional Enhancement)

If adding waveform visualization, consider:
- `wavesurfer.js` - Popular, well-maintained
- `react-audio-visualize` - Lightweight React wrapper

For MVP, simple `<audio>` element with custom controls is sufficient.

<!--I think we can start with react-audio-visualize as it adds significant
value to ux-->

### 3. MediaGenerationHost Integration

Add detection for `audio_generation` render type:

```tsx
// In PropertyRenderer or equivalent
if (ux.render_as?.includes('audio_generation')) {
  return <AudioGeneration ... />;
}
```

## Files to Create/Modify

### Create:
- `workflows/cc/steps/7_music/schemas/cc_music_prompts_schema.json`
- `workflows/cc/steps/7_music/schemas/cc_audio_generation_display_schema.json`
- `workflows/cc/steps/7_music/prompts/cc_music_prompts_system.txt`
- `workflows/cc/steps/7_music/prompts/cc_music_prompts_user.txt`
- `ui/webui/src/interactions/types/media-generation/AudioGeneration.tsx`

### Modify:
- `workflows/cc/steps/7_music/step.json` (restructure)
- `backend/worker/actors/media.py` (add txt2audio)
- `ui/webui/src/interactions/types/media-generation/MediaGenerationHost.tsx`
- `ui/webui/src/interactions/types/media-generation/types.ts`

### Delete (no longer needed):
- `workflows/cc/steps/7_music/schemas/cc_music_options_schema.json`
- `workflows/cc/steps/7_music/schemas/cc_music_options_display_schema.json`
- `workflows/cc/steps/7_music/schemas/cc_elevenlabs_schema.json`
- `workflows/cc/steps/7_music/prompts/cc_music_system.txt`
- `workflows/cc/steps/7_music/prompts/cc_music_user.txt`
- `workflows/cc/steps/7_music/prompts/cc_elevenlabs_system.txt`
- `workflows/cc/steps/7_music/prompts/cc_elevenlabs_user.txt`

## Questions for Review

1. For the BPM input: Should this be appended to the prompt text before sending
   to ElevenLabs (e.g., "... 72 BPM"), or is it a separate API parameter?
   The ElevenLabs API doesn't seem to have a BPM field - it's prompt-driven.

<!-- we can append this to prompt in server side. something like "Target BPM:
xxx", in ui, this can be number input with range, same goes for other options
like intruments and mood-->

2. Should the 3 prompt options have distinct "styles" (like Cozy Acoustic,
   Playful Bounce, etc.) or be more similar variations of the same concept?

   <!--we can use same rules defined in current options prompt to determine
   different options-->

3. Audio selection UX: Should we require the user to generate at least one
   track before they can proceed, or allow skipping music generation entirely?

   <!--in both video and audio sections doesnt need user to make selection.
   they can just proceed. we can address video later, we can add it to audio
   now-->

## Implementation Order

1. Backend: Add `txt2audio` to MediaActor
2. Workflow: Create new schemas and prompts
3. Workflow: Restructure step.json
4. WebUI: Create AudioGeneration component
5. WebUI: Integrate in MediaGenerationHost
6. Test end-to-end
7. Clean up old files
