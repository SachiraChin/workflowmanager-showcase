# ElevenLabs Audio Provider Architecture

## Summary

Design for integrating ElevenLabs audio generation APIs into the media provider
system. This provider handles music generation initially, with architecture
prepared for future Text-to-Speech (TTS) and Sound Effects (SFX) capabilities.

ElevenLabs is an audio-focused AI provider offering:
- **Music Generation** (Eleven Music) — Full songs from text prompts
- **Text-to-Speech** — High-quality voice synthesis (future)
- **Sound Effects** — AI-generated sound effects (future)

This document covers the server-side provider implementation only.

---

## Design Decisions

### 1. Extend MediaProviderBase with `txt2audio` Method

**Decision**: Add a new abstract method `txt2audio` to `MediaProviderBase` rather
than creating a separate `AudioProviderBase`.

**Rationale**:
- Keeps all generation providers in one registry
- Allows mixed-media workflows (image + audio in same workflow)
- Follows existing pattern where providers implement what they support and raise
  `NotImplementedError` for unsupported operations
- Simpler architecture than maintaining parallel registries

**Trade-off**: Image-focused providers will have a stub method they don't use,
but this is consistent with how `img2vid` works for providers that don't support
video.

### 2. Single `txt2audio` Method with `audio_type` Parameter

**Decision**: One method handles all audio types (music, TTS, SFX) via an
`audio_type` parameter rather than separate `txt2music`, `txt2speech`, etc.

**Rationale**:
- Simpler base class interface (one method vs three)
- Audio types share common patterns (prompt → audio file)
- Internal dispatch to type-specific implementations is cleaner
- Easier to add new audio types without changing base class

```python
def txt2audio(self, prompt, params, progress_callback=None):
    audio_type = params.get("audio_type", "music")
    if audio_type == "music":
        return self._generate_music(prompt, params, progress_callback)
    elif audio_type == "tts":
        return self._generate_tts(prompt, params, progress_callback)
    # ...
```

### 3. Reuse `GenerationResult` for Audio

**Decision**: Audio generation returns the same `GenerationResult` dataclass used
by image/video generation.

**Rationale**:
- Existing download infrastructure works unchanged
- Storage patterns remain consistent
- Worker processing logic is reusable
- `ContentItem.url` can hold data URIs or URLs (already proven with OpenAI)

**Audio-specific metadata** (duration, sample rate, song_id) goes in
`raw_response` rather than new fields on `ContentItem`.

### 4. Credit-Based Preview Info

**Decision**: `get_preview_info()` returns cost estimates using ElevenLabs'
credit/minute pricing model, converted to USD.

**Rationale**:
- Consistent with existing `PreviewInfo` structure
- Users care about cost, not internal credit units
- `CreditInfo` already has `total_cost_usd` field

**Note**: ElevenLabs' pricing varies by tier. We'll use Creator tier rates as
the default, with the option to configure tier in environment variables.

### 5. Synchronous Streaming Response (No Polling)

**Decision**: The Music API returns audio as a streaming response. We'll
accumulate the full response rather than implementing chunked delivery.

**Rationale**:
- Simpler implementation
- Consistent with other providers' patterns
- Progress callback can report "generating..." without percentage
- Chunked streaming would require significant infrastructure changes

**Trade-off**: User won't see partial audio during generation, but music
generation is typically fast (< 60 seconds for most tracks).

---

## Technical Specification

### Base Class Changes

**File**: `backend/providers/media/base.py`

Add new abstract method:

```python
@abstractmethod
def txt2audio(
    self,
    prompt: str,
    params: Dict[str, Any],
    progress_callback: Optional[ProgressCallback] = None
) -> GenerationResult:
    """
    Generate audio from a text prompt.

    Args:
        prompt: Text description (for music/SFX) or text content (for TTS)
        params: Provider-specific parameters including:
            - audio_type: str ("music", "tts", "sfx")
            - Additional type-specific params
        progress_callback: Optional callback for progress updates

    Returns:
        GenerationResult with audio URLs/data URIs in content list

    Raises:
        NotImplementedError: If provider doesn't support audio generation
        ProviderError: On API errors
    """
    pass
```

Update `get_preview_info` docstring to include `"txt2audio"` as valid
`action_type`.

### Existing Provider Updates

All existing providers get a stub implementation:

```python
def txt2audio(
    self,
    prompt: str,
    params: Dict[str, Any],
    progress_callback: Optional[ProgressCallback] = None
) -> GenerationResult:
    """Audio generation not supported by this provider."""
    raise NotImplementedError(
        f"{self.provider_id} does not support audio generation"
    )
```

**Files to update**:
- `backend/providers/media/leonardo/provider.py`
- `backend/providers/media/midapi/provider.py`
- `backend/providers/media/stable_diffusion/provider.py`
- `backend/providers/media/openai/provider.py`

---

## ElevenLabs Provider Implementation

### File Structure

```
backend/providers/media/elevenlabs/
├── __init__.py
└── provider.py
```

### API Reference

- **Base URL**: `https://api.elevenlabs.io/v1`
- **Auth**: `xi-api-key: {ELEVENLABS_API_KEY}` header
- **Docs**: https://elevenlabs.io/docs/api-reference

### Endpoints Used (Initial Implementation)

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/music` | POST | Music generation |
| `/music/stream` | POST | Streaming music generation |
| `/music/plan` | POST | Create composition plan (free) |

### Music API Parameters

**Request Body** (`POST /v1/music`):

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `prompt` | string | Yes* | Text description (≤4100 chars) |
| `composition_plan` | object | Yes* | Detailed structure (mutually exclusive with prompt) |
| `music_length_ms` | integer | No | Duration: 3,000–600,000 ms |
| `model_id` | string | No | Default: `music_v1` |
| `force_instrumental` | boolean | No | Guarantees no vocals |
| `respect_sections_durations` | boolean | No | Enforce section timing |
| `output_format` | string | No | Query param: `mp3_44100_128`, etc. |

*One of `prompt` or `composition_plan` required.

**Response**:
- Binary audio stream (`application/octet-stream`)
- Header `song-id`: Unique identifier for the track

### Pricing (Creator Tier)

| Feature | Included | Overage |
|---------|----------|---------|
| Music | 31 minutes | $0.80/minute |
| TTS (Multilingual) | ~100 minutes | $0.30/minute |
| TTS (Flash) | ~200 minutes | $0.15/minute |
| Sound Effects | 500 generations | $0.06/generation |

All features share a 100k credit pool. Credit consumption varies by feature.

### Provider Pseudo Code

```python
"""
ElevenLabs Audio Generation Provider.

Supports:
- Music generation (Eleven Music API)
- [Future] Text-to-Speech (TTS)
- [Future] Sound Effects (SFX)

Requires ELEVENLABS_API_KEY environment variable.
"""

import os
import logging
import requests
from typing import Any, Dict, Optional

from ..base import (
    MediaProviderBase,
    ContentItem,
    GenerationResult,
    ProgressCallback,
    AuthenticationError,
    RateLimitError,
    GenerationError,
    InsufficientCreditsError,
    ResolutionInfo,
    CreditInfo,
    PreviewInfo,
)
from ..registry import register

logger = logging.getLogger(__name__)

# API Configuration
ELEVENLABS_BASE_URL = "https://api.elevenlabs.io/v1"
REQUEST_TIMEOUT_SECONDS = 300  # 5 min for long tracks

# Pricing constants (Creator tier)
MUSIC_COST_PER_MINUTE_USD = 0.80
TTS_MULTILINGUAL_COST_PER_MINUTE_USD = 0.30
TTS_FLASH_COST_PER_MINUTE_USD = 0.15
SFX_COST_PER_GENERATION_USD = 0.06

# Supported output formats
MUSIC_OUTPUT_FORMATS = [
    "mp3_22050_32",
    "mp3_44100_64",
    "mp3_44100_128",
    "mp3_44100_192",  # Creator+ only
]

DEFAULT_MUSIC_OUTPUT_FORMAT = "mp3_44100_128"


@register("elevenlabs", concurrency=2)
class ElevenLabsProvider(MediaProviderBase):
    """
    ElevenLabs provider for audio generation.

    Currently supports:
    - Music generation via Eleven Music API

    Future support planned:
    - Text-to-Speech (TTS)
    - Sound Effects (SFX)
    """

    def __init__(self):
        self.api_key = os.environ.get("ELEVENLABS_API_KEY")
        if not self.api_key:
            logger.warning(
                "[ElevenLabs] ELEVENLABS_API_KEY not set in environment"
            )

    @property
    def provider_id(self) -> str:
        return "elevenlabs"

    # =========================================================================
    # Authentication & Request Helpers
    # =========================================================================

    def _get_headers(self) -> Dict[str, str]:
        """Get authorization headers for API requests."""
        if not self.api_key:
            raise AuthenticationError("ELEVENLABS_API_KEY not configured")
        return {
            "xi-api-key": self.api_key,
            "Content-Type": "application/json",
        }

    def _handle_response_error(self, response: requests.Response) -> None:
        """Handle HTTP error responses from ElevenLabs API."""
        if response.status_code == 200:
            return

        try:
            error_data = response.json()
            error_msg = error_data.get("detail", {})
            if isinstance(error_msg, dict):
                error_msg = error_msg.get("message", str(error_data))
            else:
                error_msg = str(error_msg)
        except Exception:
            error_msg = response.text

        if response.status_code == 401:
            raise AuthenticationError(f"Invalid API key: {error_msg}")
        elif response.status_code == 429:
            raise RateLimitError(f"Rate limited: {error_msg}", retry_after=60)
        elif response.status_code == 402:
            raise InsufficientCreditsError(f"Insufficient credits: {error_msg}")
        elif response.status_code == 422:
            raise GenerationError(f"Validation error: {error_msg}")
        else:
            raise GenerationError(
                f"API error ({response.status_code}): {error_msg}"
            )

    # =========================================================================
    # Image/Video Methods (Not Supported)
    # =========================================================================

    def txt2img(
        self,
        prompt: str,
        params: Dict[str, Any],
        progress_callback: Optional[ProgressCallback] = None
    ) -> GenerationResult:
        """Image generation not supported by ElevenLabs."""
        raise NotImplementedError(
            "ElevenLabs does not support image generation"
        )

    def img2img(
        self,
        source_image: str,
        prompt: str,
        params: Dict[str, Any],
        progress_callback: Optional[ProgressCallback] = None
    ) -> GenerationResult:
        """Image-to-image not supported by ElevenLabs."""
        raise NotImplementedError(
            "ElevenLabs does not support image generation"
        )

    def img2vid(
        self,
        source_image: str,
        prompt: str,
        params: Dict[str, Any],
        progress_callback: Optional[ProgressCallback] = None
    ) -> GenerationResult:
        """Video generation not supported by ElevenLabs."""
        raise NotImplementedError(
            "ElevenLabs does not support video generation"
        )

    # =========================================================================
    # Audio Generation
    # =========================================================================

    def txt2audio(
        self,
        prompt: str,
        params: Dict[str, Any],
        progress_callback: Optional[ProgressCallback] = None
    ) -> GenerationResult:
        """
        Generate audio from text prompt.

        Args:
            prompt: Text description (music/SFX) or content (TTS)
            params: Generation parameters:
                - audio_type: str ("music", "tts", "sfx") default "music"

                For music:
                - duration_ms: int (3000-600000)
                - force_instrumental: bool
                - output_format: str
                - composition_plan: dict (alternative to prompt)

                For TTS (future):
                - voice_id: str
                - model_id: str
                - voice_settings: dict

                For SFX (future):
                - duration_seconds: float
                - prompt_influence: float
                - loop: bool

        Returns:
            GenerationResult with audio data URI
        """
        audio_type = params.get("audio_type", "music")

        if audio_type == "music":
            return self._generate_music(prompt, params, progress_callback)
        elif audio_type == "tts":
            raise NotImplementedError("TTS generation not yet implemented")
        elif audio_type == "sfx":
            raise NotImplementedError("SFX generation not yet implemented")
        else:
            raise GenerationError(f"Unknown audio_type: {audio_type}")

    def _generate_music(
        self,
        prompt: str,
        params: Dict[str, Any],
        progress_callback: Optional[ProgressCallback] = None
    ) -> GenerationResult:
        """
        Generate music using Eleven Music API.

        The API returns a streaming binary response. We accumulate the full
        audio and return it as a data URI.
        """
        # Build request payload
        payload = {}

        # Use composition_plan if provided, otherwise use prompt
        composition_plan = params.get("composition_plan")
        if composition_plan:
            payload["composition_plan"] = composition_plan
        else:
            payload["prompt"] = prompt[:4100]  # Max prompt length

        # Optional parameters
        if "duration_ms" in params:
            duration_ms = params["duration_ms"]
            # Clamp to valid range
            duration_ms = max(3000, min(600000, int(duration_ms)))
            payload["music_length_ms"] = duration_ms

        if params.get("force_instrumental"):
            payload["force_instrumental"] = True

        if "model_id" in params:
            payload["model_id"] = params["model_id"]

        # Output format as query parameter
        output_format = params.get("output_format", DEFAULT_MUSIC_OUTPUT_FORMAT)
        if output_format not in MUSIC_OUTPUT_FORMATS:
            output_format = DEFAULT_MUSIC_OUTPUT_FORMAT

        logger.info(
            f"[ElevenLabs] Starting music generation: "
            f"duration={payload.get('music_length_ms', 'auto')}ms, "
            f"format={output_format}"
        )

        if progress_callback:
            progress_callback(0, "Generating music with ElevenLabs...")

        # Make request
        try:
            response = requests.post(
                f"{ELEVENLABS_BASE_URL}/music",
                json=payload,
                headers=self._get_headers(),
                params={"output_format": output_format},
                timeout=REQUEST_TIMEOUT_SECONDS,
                stream=True  # Stream for potentially large audio files
            )
        except requests.RequestException as e:
            raise GenerationError(f"Request failed: {e}")

        self._handle_response_error(response)

        # Get song ID from response header
        song_id = response.headers.get("song-id")

        # Accumulate streaming response
        audio_chunks = []
        for chunk in response.iter_content(chunk_size=8192):
            if chunk:
                audio_chunks.append(chunk)

        audio_data = b"".join(audio_chunks)

        if progress_callback:
            progress_callback(100, "Complete!")

        # Convert to data URI
        import base64
        audio_b64 = base64.b64encode(audio_data).decode("utf-8")

        # Determine MIME type from format
        mime_type = "audio/mpeg"  # MP3 is the primary format
        data_uri = f"data:{mime_type};base64,{audio_b64}"

        logger.info(
            f"[ElevenLabs] Music generation complete: "
            f"song_id={song_id}, size={len(audio_data)} bytes"
        )

        return GenerationResult(
            content=[ContentItem(url=data_uri, seed=-1)],
            raw_response={
                "song_id": song_id,
                "format": output_format,
                "size_bytes": len(audio_data),
                "audio_type": "music",
            },
            provider_task_id=song_id
        )

    # =========================================================================
    # Preview Info (Cost Estimation)
    # =========================================================================

    def get_preview_info(
        self,
        action_type: str,
        params: Dict[str, Any]
    ) -> PreviewInfo:
        """
        Get preview information for audio generation.

        Returns cost estimates based on Creator tier pricing.
        """
        if action_type != "txt2audio":
            raise NotImplementedError(
                f"Preview not available for {action_type}"
            )

        audio_type = params.get("audio_type", "music")

        if audio_type == "music":
            return self._get_music_preview_info(params)
        elif audio_type == "tts":
            return self._get_tts_preview_info(params)
        elif audio_type == "sfx":
            return self._get_sfx_preview_info(params)
        else:
            raise GenerationError(f"Unknown audio_type: {audio_type}")

    def _get_music_preview_info(self, params: Dict[str, Any]) -> PreviewInfo:
        """Calculate cost estimate for music generation."""
        # Get duration (default to 60 seconds if not specified)
        duration_ms = params.get("duration_ms", 60000)
        duration_minutes = duration_ms / 60000

        total_cost = duration_minutes * MUSIC_COST_PER_MINUTE_USD

        # Resolution doesn't apply to audio - use placeholder values
        resolution = ResolutionInfo(width=0, height=0, megapixels=0)

        # Approximate credit calculation (100k credits / 31 min included)
        credits_per_minute = 100000 / 31  # ~3225 credits/min

        credits = CreditInfo(
            credits=round(duration_minutes * credits_per_minute),
            cost_per_credit=MUSIC_COST_PER_MINUTE_USD / credits_per_minute,
            total_cost_usd=round(total_cost, 2),
            num_images=1,  # 1 audio file
            credits_per_image=round(duration_minutes * credits_per_minute),
            cost_per_image_usd=round(total_cost, 2)
        )

        return PreviewInfo(resolution=resolution, credits=credits)

    def _get_tts_preview_info(self, params: Dict[str, Any]) -> PreviewInfo:
        """Calculate cost estimate for TTS generation (placeholder)."""
        raise NotImplementedError("TTS preview not yet implemented")

    def _get_sfx_preview_info(self, params: Dict[str, Any]) -> PreviewInfo:
        """Calculate cost estimate for SFX generation (placeholder)."""
        raise NotImplementedError("SFX preview not yet implemented")
```

---

## Package Updates

**File**: `backend/providers/media/__init__.py`

```python
# Add import
from .elevenlabs.provider import ElevenLabsProvider

# Add to __all__
__all__ = [
    # ... existing exports ...
    'ElevenLabsProvider',
]
```

---

## File Change Summary

| File | Action | Description |
|------|--------|-------------|
| `backend/providers/media/base.py` | Modify | Add `txt2audio` abstract method |
| `backend/providers/media/leonardo/provider.py` | Modify | Add `txt2audio` stub |
| `backend/providers/media/midapi/provider.py` | Modify | Add `txt2audio` stub |
| `backend/providers/media/stable_diffusion/provider.py` | Modify | Add `txt2audio` stub |
| `backend/providers/media/openai/provider.py` | Modify | Add `txt2audio` stub |
| `backend/providers/media/elevenlabs/__init__.py` | Create | Package init |
| `backend/providers/media/elevenlabs/provider.py` | Create | Full implementation |
| `backend/providers/media/__init__.py` | Modify | Export ElevenLabsProvider |

---

## Future Extensions

### Text-to-Speech (TTS)

When implementing TTS, add to `_generate_tts`:

```python
def _generate_tts(self, text, params, progress_callback):
    """
    params:
        voice_id: str (required)
        model_id: str ("eleven_multilingual_v2", "eleven_flash_v2_5", etc.)
        voice_settings: dict {stability, similarity_boost, style, speed}
        output_format: str
    """
    # POST /v1/text-to-speech/{voice_id}
```

### Sound Effects (SFX)

When implementing SFX, add to `_generate_sfx`:

```python
def _generate_sfx(self, prompt, params, progress_callback):
    """
    params:
        duration_seconds: float (0.5-30, or None for auto)
        prompt_influence: float (0-1, default 0.3)
        loop: bool
        model_id: str (default "eleven_text_to_sound_v2")
    """
    # POST /v1/sound-generation
```

---

## Questions for Review

1. **Concurrency limit**: Set to 2 for ElevenLabs. Should this be higher/lower
   based on API rate limits?
   <!--Need to test actual rate limits. 2 seems conservative but safe.-->

2. **Data URI vs file save**: Music files can be large (5+ MB for long tracks).
   Should we save to temp file instead of returning data URI?
   <!--Data URI matches OpenAI pattern, but could cause memory issues for very
   long tracks. May need threshold-based approach.-->
   <!--not sure what you meant here, files are always saved in filesystem, and access via api. also this comment synctx is for me to add, not for you to add in files. change this in next rev-->

3. **Streaming endpoint**: ElevenLabs has `/music/stream` which returns chunks.
   Should we use this for real-time feedback?
   <!--Probably overkill for initial implementation. Can add later if users
   want progress feedback during generation.-->
   <!--again, what  are you trying to say here, arent we streaming data already?-->

4. **Composition plan support**: The API supports detailed composition plans
   with sections, styles, and lyrics. Should we expose this in `params` or
   create a separate method?
   <!--Keeping in params for now. Can add helper methods if workflows need
   complex composition planning.-->
   <!--we add these to params-->

5. **Voice management for TTS**: When TTS is implemented, how should voice
   selection work? Voice IDs are provider-specific.
   <!--Defer to TTS implementation phase. Probably just voice_id in params.-->
   <!--we are not doing tts, so this is not a problem is it not?-->

6. **Audio metadata in GenerationResult**: Should we add audio-specific fields
   (duration_ms, sample_rate) to `ContentItem` or keep in `raw_response`?
   <!--raw_response for now to avoid base class changes. Can revisit if audio
   becomes common across providers.-->
   <!--lets use current format, if i feel like we need to extend, we will do so later-->
