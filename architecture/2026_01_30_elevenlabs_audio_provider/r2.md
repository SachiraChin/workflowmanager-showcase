# ElevenLabs Audio Provider Architecture

## Summary

Design for integrating ElevenLabs audio generation APIs into the media provider
system. This provider handles music generation initially, with architecture
prepared for future Text-to-Speech (TTS) and Sound Effects (SFX) capabilities.

ElevenLabs is an audio-focused AI provider offering:
- **Music Generation** (Eleven Music) — Full songs from text prompts
- **Text-to-Speech** — High-quality voice synthesis (future)
- **Sound Effects** — AI-generated sound effects (future)

This document covers the server-side provider implementation only.

---

## Changes from r1

- Removed pre-filled answers from Questions for Review (that's for operator)
- Clarified confusing questions about data handling
- Removed premature TTS question (not in scope)
- Resolved questions based on operator feedback

---

## Design Decisions

### 1. Extend MediaProviderBase with `txt2audio` Method

**Decision**: Add a new abstract method `txt2audio` to `MediaProviderBase` rather
than creating a separate `AudioProviderBase`.

**Rationale**:
- Keeps all generation providers in one registry
- Allows mixed-media workflows (image + audio in same workflow)
- Follows existing pattern where providers implement what they support and raise
  `NotImplementedError` for unsupported operations
- Simpler architecture than maintaining parallel registries

**Trade-off**: Image-focused providers will have a stub method they don't use,
but this is consistent with how `img2vid` works for providers that don't support
video.

### 2. Single `txt2audio` Method with `audio_type` Parameter

**Decision**: One method handles all audio types (music, TTS, SFX) via an
`audio_type` parameter rather than separate `txt2music`, `txt2speech`, etc.

**Rationale**:
- Simpler base class interface (one method vs three)
- Audio types share common patterns (prompt → audio file)
- Internal dispatch to type-specific implementations is cleaner
- Easier to add new audio types without changing base class

```python
def txt2audio(self, prompt, params, progress_callback=None):
    audio_type = params.get("audio_type", "music")
    if audio_type == "music":
        return self._generate_music(prompt, params, progress_callback)
    elif audio_type == "tts":
        return self._generate_tts(prompt, params, progress_callback)
    # ...
```

### 3. Reuse `GenerationResult` for Audio

**Decision**: Audio generation returns the same `GenerationResult` dataclass used
by image/video generation.

**Rationale**:
- Existing download infrastructure works unchanged
- Storage patterns remain consistent
- Worker processing logic is reusable
- `ContentItem.url` can hold data URIs or URLs (already proven with OpenAI)

**Audio-specific metadata** (duration, sample rate, song_id) goes in
`raw_response`. We'll extend if needed later.

### 4. Credit-Based Preview Info

**Decision**: `get_preview_info()` returns cost estimates using ElevenLabs'
credit/minute pricing model, converted to USD.

**Rationale**:
- Consistent with existing `PreviewInfo` structure
- Users care about cost, not internal credit units
- `CreditInfo` already has `total_cost_usd` field

**Note**: ElevenLabs' pricing varies by tier. We'll use Creator tier rates as
the default, with the option to configure tier in environment variables.

### 5. Composition Plan Support via Params

**Decision**: The `composition_plan` parameter is passed directly in `params`,
allowing detailed control over song structure when needed.

**Rationale**:
- Keeps the interface simple (no separate methods)
- Workflows can use simple prompts OR detailed plans
- Plan structure matches ElevenLabs API directly

---

## Technical Specification

### Base Class Changes

**File**: `backend/providers/media/base.py`

Add new abstract method:

```python
@abstractmethod
def txt2audio(
    self,
    prompt: str,
    params: Dict[str, Any],
    progress_callback: Optional[ProgressCallback] = None
) -> GenerationResult:
    """
    Generate audio from a text prompt.

    Args:
        prompt: Text description (for music/SFX) or text content (for TTS)
        params: Provider-specific parameters including:
            - audio_type: str ("music", "tts", "sfx")
            - Additional type-specific params
        progress_callback: Optional callback for progress updates

    Returns:
        GenerationResult with audio URLs/data URIs in content list

    Raises:
        NotImplementedError: If provider doesn't support audio generation
        ProviderError: On API errors
    """
    pass
```

Update `get_preview_info` docstring to include `"txt2audio"` as valid
`action_type`.

### Existing Provider Updates

All existing providers get a stub implementation:

```python
def txt2audio(
    self,
    prompt: str,
    params: Dict[str, Any],
    progress_callback: Optional[ProgressCallback] = None
) -> GenerationResult:
    """Audio generation not supported by this provider."""
    raise NotImplementedError(
        f"{self.provider_id} does not support audio generation"
    )
```

**Files to update**:
- `backend/providers/media/leonardo/provider.py`
- `backend/providers/media/midapi/provider.py`
- `backend/providers/media/stable_diffusion/provider.py`
- `backend/providers/media/openai/provider.py`

---

## ElevenLabs Provider Implementation

### File Structure

```
backend/providers/media/elevenlabs/
├── __init__.py
└── provider.py
```

### API Reference

- **Base URL**: `https://api.elevenlabs.io/v1`
- **Auth**: `xi-api-key: {ELEVENLABS_API_KEY}` header
- **Docs**: https://elevenlabs.io/docs/api-reference

### Endpoints Used (Initial Implementation)

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/music` | POST | Music generation (returns streaming audio) |

### Music API Parameters

**Request Body** (`POST /v1/music`):

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `prompt` | string | Yes* | Text description (≤4100 chars) |
| `composition_plan` | object | Yes* | Detailed structure (mutually exclusive with prompt) |
| `music_length_ms` | integer | No | Duration: 3,000–600,000 ms |
| `model_id` | string | No | Default: `music_v1` |
| `force_instrumental` | boolean | No | Guarantees no vocals |
| `respect_sections_durations` | boolean | No | Enforce section timing |
| `output_format` | string | No | Query param: `mp3_44100_128`, etc. |

*One of `prompt` or `composition_plan` required.

**Response**:
- Binary audio stream (`application/octet-stream`)
- Header `song-id`: Unique identifier for the track

### Pricing (Creator Tier)

| Feature | Included | Overage |
|---------|----------|---------|
| Music | 31 minutes | $0.80/minute |
| TTS (Multilingual) | ~100 minutes | $0.30/minute |
| TTS (Flash) | ~200 minutes | $0.15/minute |
| Sound Effects | 500 generations | $0.06/generation |

All features share a 100k credit pool. Credit consumption varies by feature.

### Provider Pseudo Code

```python
"""
ElevenLabs Audio Generation Provider.

Supports:
- Music generation (Eleven Music API)
- [Future] Text-to-Speech (TTS)
- [Future] Sound Effects (SFX)

Requires ELEVENLABS_API_KEY environment variable.
"""

import os
import base64
import logging
import requests
from typing import Any, Dict, Optional

from ..base import (
    MediaProviderBase,
    ContentItem,
    GenerationResult,
    ProgressCallback,
    AuthenticationError,
    RateLimitError,
    GenerationError,
    InsufficientCreditsError,
    ResolutionInfo,
    CreditInfo,
    PreviewInfo,
)
from ..registry import register

logger = logging.getLogger(__name__)

# API Configuration
ELEVENLABS_BASE_URL = "https://api.elevenlabs.io/v1"
REQUEST_TIMEOUT_SECONDS = 300  # 5 min for long tracks

# Pricing constants (Creator tier)
MUSIC_COST_PER_MINUTE_USD = 0.80

# Supported output formats
MUSIC_OUTPUT_FORMATS = [
    "mp3_22050_32",
    "mp3_44100_64",
    "mp3_44100_128",
    "mp3_44100_192",  # Creator+ only
]

DEFAULT_MUSIC_OUTPUT_FORMAT = "mp3_44100_128"


@register("elevenlabs", concurrency=2)
class ElevenLabsProvider(MediaProviderBase):
    """
    ElevenLabs provider for audio generation.

    Currently supports:
    - Music generation via Eleven Music API

    Future support planned:
    - Text-to-Speech (TTS)
    - Sound Effects (SFX)
    """

    def __init__(self):
        self.api_key = os.environ.get("ELEVENLABS_API_KEY")
        if not self.api_key:
            logger.warning(
                "[ElevenLabs] ELEVENLABS_API_KEY not set in environment"
            )

    @property
    def provider_id(self) -> str:
        return "elevenlabs"

    # =========================================================================
    # Authentication & Request Helpers
    # =========================================================================

    def _get_headers(self) -> Dict[str, str]:
        """Get authorization headers for API requests."""
        if not self.api_key:
            raise AuthenticationError("ELEVENLABS_API_KEY not configured")
        return {
            "xi-api-key": self.api_key,
            "Content-Type": "application/json",
        }

    def _handle_response_error(self, response: requests.Response) -> None:
        """Handle HTTP error responses from ElevenLabs API."""
        if response.status_code == 200:
            return

        try:
            error_data = response.json()
            error_msg = error_data.get("detail", {})
            if isinstance(error_msg, dict):
                error_msg = error_msg.get("message", str(error_data))
            else:
                error_msg = str(error_msg)
        except Exception:
            error_msg = response.text

        if response.status_code == 401:
            raise AuthenticationError(f"Invalid API key: {error_msg}")
        elif response.status_code == 429:
            raise RateLimitError(f"Rate limited: {error_msg}", retry_after=60)
        elif response.status_code == 402:
            raise InsufficientCreditsError(f"Insufficient credits: {error_msg}")
        elif response.status_code == 422:
            raise GenerationError(f"Validation error: {error_msg}")
        else:
            raise GenerationError(
                f"API error ({response.status_code}): {error_msg}"
            )

    # =========================================================================
    # Image/Video Methods (Not Supported)
    # =========================================================================

    def txt2img(
        self,
        prompt: str,
        params: Dict[str, Any],
        progress_callback: Optional[ProgressCallback] = None
    ) -> GenerationResult:
        """Image generation not supported by ElevenLabs."""
        raise NotImplementedError(
            "ElevenLabs does not support image generation"
        )

    def img2img(
        self,
        source_image: str,
        prompt: str,
        params: Dict[str, Any],
        progress_callback: Optional[ProgressCallback] = None
    ) -> GenerationResult:
        """Image-to-image not supported by ElevenLabs."""
        raise NotImplementedError(
            "ElevenLabs does not support image generation"
        )

    def img2vid(
        self,
        source_image: str,
        prompt: str,
        params: Dict[str, Any],
        progress_callback: Optional[ProgressCallback] = None
    ) -> GenerationResult:
        """Video generation not supported by ElevenLabs."""
        raise NotImplementedError(
            "ElevenLabs does not support video generation"
        )

    # =========================================================================
    # Audio Generation
    # =========================================================================

    def txt2audio(
        self,
        prompt: str,
        params: Dict[str, Any],
        progress_callback: Optional[ProgressCallback] = None
    ) -> GenerationResult:
        """
        Generate audio from text prompt.

        Args:
            prompt: Text description for music generation
            params: Generation parameters:
                - audio_type: str ("music") - default "music"
                - duration_ms: int (3000-600000)
                - force_instrumental: bool
                - output_format: str
                - composition_plan: dict (alternative to prompt)
                - model_id: str (default "music_v1")
                - respect_sections_durations: bool

        Returns:
            GenerationResult with audio data URI
        """
        audio_type = params.get("audio_type", "music")

        if audio_type == "music":
            return self._generate_music(prompt, params, progress_callback)
        elif audio_type == "tts":
            raise NotImplementedError("TTS generation not yet implemented")
        elif audio_type == "sfx":
            raise NotImplementedError("SFX generation not yet implemented")
        else:
            raise GenerationError(f"Unknown audio_type: {audio_type}")

    def _generate_music(
        self,
        prompt: str,
        params: Dict[str, Any],
        progress_callback: Optional[ProgressCallback] = None
    ) -> GenerationResult:
        """
        Generate music using Eleven Music API.

        The API returns a streaming binary response. We read the full audio
        and return it as a data URI for the download utility to save.
        """
        # Build request payload
        payload = {}

        # Use composition_plan if provided, otherwise use prompt
        composition_plan = params.get("composition_plan")
        if composition_plan:
            payload["composition_plan"] = composition_plan
        else:
            payload["prompt"] = prompt[:4100]  # Max prompt length

        # Optional parameters
        if "duration_ms" in params:
            duration_ms = params["duration_ms"]
            # Clamp to valid range
            duration_ms = max(3000, min(600000, int(duration_ms)))
            payload["music_length_ms"] = duration_ms

        if params.get("force_instrumental"):
            payload["force_instrumental"] = True

        if "model_id" in params:
            payload["model_id"] = params["model_id"]

        if "respect_sections_durations" in params:
            payload["respect_sections_durations"] = params[
                "respect_sections_durations"
            ]

        # Output format as query parameter
        output_format = params.get("output_format", DEFAULT_MUSIC_OUTPUT_FORMAT)
        if output_format not in MUSIC_OUTPUT_FORMATS:
            output_format = DEFAULT_MUSIC_OUTPUT_FORMAT

        logger.info(
            f"[ElevenLabs] Starting music generation: "
            f"duration={payload.get('music_length_ms', 'auto')}ms, "
            f"format={output_format}"
        )

        if progress_callback:
            progress_callback(0, "Generating music with ElevenLabs...")

        # Make request with streaming to handle large audio files
        try:
            response = requests.post(
                f"{ELEVENLABS_BASE_URL}/music",
                json=payload,
                headers=self._get_headers(),
                params={"output_format": output_format},
                timeout=REQUEST_TIMEOUT_SECONDS,
                stream=True
            )
        except requests.RequestException as e:
            raise GenerationError(f"Request failed: {e}")

        self._handle_response_error(response)

        # Get song ID from response header
        song_id = response.headers.get("song-id")

        # Read streaming response
        audio_chunks = []
        for chunk in response.iter_content(chunk_size=8192):
            if chunk:
                audio_chunks.append(chunk)

        audio_data = b"".join(audio_chunks)

        if progress_callback:
            progress_callback(100, "Complete!")

        # Convert to data URI (download utility will save to filesystem)
        audio_b64 = base64.b64encode(audio_data).decode("utf-8")
        mime_type = "audio/mpeg"
        data_uri = f"data:{mime_type};base64,{audio_b64}"

        logger.info(
            f"[ElevenLabs] Music generation complete: "
            f"song_id={song_id}, size={len(audio_data)} bytes"
        )

        return GenerationResult(
            content=[ContentItem(url=data_uri, seed=-1)],
            raw_response={
                "song_id": song_id,
                "format": output_format,
                "size_bytes": len(audio_data),
                "audio_type": "music",
            },
            provider_task_id=song_id
        )

    # =========================================================================
    # Preview Info (Cost Estimation)
    # =========================================================================

    def get_preview_info(
        self,
        action_type: str,
        params: Dict[str, Any]
    ) -> PreviewInfo:
        """
        Get preview information for audio generation.

        Returns cost estimates based on Creator tier pricing.
        """
        if action_type != "txt2audio":
            raise NotImplementedError(
                f"Preview not available for {action_type}"
            )

        audio_type = params.get("audio_type", "music")

        if audio_type == "music":
            return self._get_music_preview_info(params)
        else:
            raise NotImplementedError(
                f"Preview not available for audio_type: {audio_type}"
            )

    def _get_music_preview_info(self, params: Dict[str, Any]) -> PreviewInfo:
        """Calculate cost estimate for music generation."""
        # Get duration (default to 60 seconds if not specified)
        duration_ms = params.get("duration_ms", 60000)
        duration_minutes = duration_ms / 60000

        total_cost = duration_minutes * MUSIC_COST_PER_MINUTE_USD

        # Resolution doesn't apply to audio - use placeholder values
        resolution = ResolutionInfo(width=0, height=0, megapixels=0)

        # Approximate credit calculation (100k credits / 31 min included)
        credits_per_minute = 100000 / 31  # ~3225 credits/min

        credits = CreditInfo(
            credits=round(duration_minutes * credits_per_minute),
            cost_per_credit=MUSIC_COST_PER_MINUTE_USD / credits_per_minute,
            total_cost_usd=round(total_cost, 2),
            num_images=1,  # 1 audio file
            credits_per_image=round(duration_minutes * credits_per_minute),
            cost_per_image_usd=round(total_cost, 2)
        )

        return PreviewInfo(resolution=resolution, credits=credits)
```

---

## Package Updates

**File**: `backend/providers/media/__init__.py`

```python
# Add import
from .elevenlabs.provider import ElevenLabsProvider

# Add to __all__
__all__ = [
    # ... existing exports ...
    'ElevenLabsProvider',
]
```

---

## File Change Summary

| File | Action | Description |
|------|--------|-------------|
| `backend/providers/media/base.py` | Modify | Add `txt2audio` abstract method |
| `backend/providers/media/leonardo/provider.py` | Modify | Add `txt2audio` stub |
| `backend/providers/media/midapi/provider.py` | Modify | Add `txt2audio` stub |
| `backend/providers/media/stable_diffusion/provider.py` | Modify | Add `txt2audio` stub |
| `backend/providers/media/openai/provider.py` | Modify | Add `txt2audio` stub |
| `backend/providers/media/elevenlabs/__init__.py` | Create | Package init |
| `backend/providers/media/elevenlabs/provider.py` | Create | Full implementation |
| `backend/providers/media/__init__.py` | Modify | Export ElevenLabsProvider |

---

## Future Extensions

### Text-to-Speech (TTS)

When implementing TTS, add to `_generate_tts`:

```python
def _generate_tts(self, text, params, progress_callback):
    """
    params:
        voice_id: str (required)
        model_id: str ("eleven_multilingual_v2", "eleven_flash_v2_5", etc.)
        voice_settings: dict {stability, similarity_boost, style, speed}
        output_format: str
    """
    # POST /v1/text-to-speech/{voice_id}
```

### Sound Effects (SFX)

When implementing SFX, add to `_generate_sfx`:

```python
def _generate_sfx(self, prompt, params, progress_callback):
    """
    params:
        duration_seconds: float (0.5-30, or None for auto)
        prompt_influence: float (0-1, default 0.3)
        loop: bool
        model_id: str (default "eleven_text_to_sound_v2")
    """
    # POST /v1/sound-generation
```

---

## Questions for Review

1. **Concurrency limit**: Set to 2 for ElevenLabs. Should this be higher/lower
   based on API rate limits?
   <!--2 works for now-->

2. **Error response format**: I've assumed ElevenLabs returns errors in
   `{"detail": {"message": "..."}}` format. Need to verify actual error
   response structure during implementation.
   <!--
elven labs error format can be either

{
  "detail": {
    "status": "error_status_code",
    "message": "A human-readable description of the error."
  }
}

or 

{
  "error": "Error description",
  "message": "Details about the error."
}
   need to handle both
   -->
