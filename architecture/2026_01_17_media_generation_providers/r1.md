# Media Generation Providers Architecture

## Summary

Design for integrating image/video generation APIs (MidAPI/Midjourney and Leonardo AI) into the workflow system. These providers handle text-to-image, image-to-image, text-to-video, image-to-video, upscaling, and variations.

## Design Decisions

### 1. No Abstract Base Class / Interface Normalization

**Decision**: Each provider is a standalone client. No shared base class, no forced interface conformity.

**Rationale**:
- MidAPI and Leonardo have fundamentally different APIs, parameters, and capabilities
- Forcing a unified interface leads to:
  - Lowest common denominator (lose provider features)
  - Complex union types
  - Leaky abstractions
- Workflows that use MidAPI expect MidAPI behavior. Swapping providers requires workflow changes anyway.

### 2. Return Pattern: `Tuple[List[str], dict]`

**Decision**: All generation methods return `(result_urls, raw_response)`

- `result_urls`: `List[str]` - Always an array, even for single outputs
- `raw_response`: `dict` - Full provider response for provider-specific data

**Rationale**:
- Primary output (URLs) is universal and what callers need 90% of time
- Array is consistent - no checking `str` vs `List[str]`
- Future-proof for batch operations
- Raw response preserves all provider-specific metadata without normalization
- Clean usage: `images, _ = client.txt2img(params)` or `images, raw = client.txt2img(params)`

### 3. End-to-End Methods

**Decision**: Methods handle the full flow: submit → poll → return results

**Rationale**:
- Caller doesn't manage async complexity
- Polling logic is provider-specific (different status values, endpoints)
- Simpler API surface

### 4. Input as `Dict[str, Any]`

**Decision**: Generation parameters passed as dict, not typed dataclasses

**Rationale**:
- Workflow system is JSON-configured, inputs are dicts anyway
- Provider parameters are very different - unified typing is false precision
- Flexibility for provider-specific params without interface changes
- Validation happens in each client with clear error messages

### 5. Separate Clients, Shared Location

**Decision**: Clients live in `server/modules/api/providers/{provider}/client.py`

**Rationale**:
- Organizational convenience (one place for media generation)
- Each client is independent
- No pretense of interchangeability

---



## MidAPI Client

### API Reference
- Base URL: `https://api.midapi.ai`
- Auth: `Authorization: Bearer {MIDAPI_API_KEY}`
- Docs: https://docs.midapi.ai/

### Endpoints Used

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/v1/mj/generate` | POST | Image/video generation |
| `/api/v1/mj/record-info` | GET | Task status polling |
| `/api/v1/mj/generateUpscale` | POST | Upscale image |
| `/api/v1/mj/generateVary` | POST | Create variation |
| `/api/v1/mj/generateVideoExtend` | POST | Extend video |
| `/api/v1/common/credit` | GET | Check credits |
| `/api/v1/common/download-url` | POST | Get temp download URL |

### Task Status Values
- `0` = Generating (pending)
- `1` = Success (complete)
- `2` = Failed
- `3` = Generation Failed

### Pseudo Code

```python
class MidAPIClient:
    BASE_URL = "https://api.midapi.ai"

    def __init__(self, api_key=None, timeout=300, poll_interval=5.0):
        self._api_key = api_key or os.getenv("MIDAPI_API_KEY")
        self._timeout = timeout
        self._poll_interval = poll_interval

    # === Core Request ===

    def _request(self, method, endpoint, params=None, json_data=None) -> dict:
        """
        Make authenticated request.
        Returns: {"code": 200, "msg": "success", "data": {...}}
        Raises RuntimeError on non-200.
        """
        response = requests.request(
            method,
            f"{BASE_URL}{endpoint}",
            headers={"Authorization": f"Bearer {api_key}"},
            params=params,
            json=json_data
        )
        data = response.json()
        if data["code"] != 200:
            raise RuntimeError(f"{data['msg']} (code={data['code']})")
        return data

    # === Polling ===

    def _poll_until_complete(self, task_id) -> dict:
        """
        Poll /api/v1/mj/record-info until status != 0.
        Returns task data on success.
        Raises TimeoutError or RuntimeError on failure.
        """
        start = time.time()
        while time.time() - start < self._timeout:
            data = self._request("GET", "/api/v1/mj/record-info", params={"taskId": task_id})
            task = data["data"]

            if task["successFlag"] == 1:  # Success
                return task
            if task["successFlag"] in (2, 3):  # Failed
                raise RuntimeError(task.get("errorMessage", "Failed"))

            time.sleep(self._poll_interval)

        raise TimeoutError(f"Task {task_id} timed out")

    def _extract_urls(self, task_data) -> List[str]:
        """Extract resultUrls from task response."""
        urls = []
        result_info = task_data.get("resultInfoJson", {})
        for item in result_info.get("resultUrls", []):
            if isinstance(item, dict):
                urls.append(item["resultUrl"])
            else:
                urls.append(item)
        return urls

    # === Generation Methods ===

    def txt2img(self, params: dict) -> Tuple[List[str], dict]:
        """
        params:
            prompt (str, required)
            speed: "relaxed" | "fast" | "turbo"
            aspect_ratio: "1:1" | "16:9" | "9:16" | etc
            version: "7" | "6.1" | "6" | "5.2" | "5.1" | "niji6"
            variety: int 0-100
            stylization: int 0-1000
            weirdness: int 0-3000
            water_mark: str
            enable_translation: bool
            callback_url: str
        """
        payload = {"taskType": "mj_txt2img", "prompt": params["prompt"]}
        # Map params to payload (snake_case -> camelCase)

        data = self._request("POST", "/api/v1/mj/generate", json_data=payload)
        task_id = data["data"]["taskId"]

        result = self._poll_until_complete(task_id)
        return self._extract_urls(result), result

    def img2img(self, params: dict) -> Tuple[List[str], dict]:
        """
        params:
            prompt (str, required)
            image_url (str, required)
            + same optional params as txt2img
        """
        payload = {
            "taskType": "mj_img2img",
            "prompt": params["prompt"],
            "fileUrl": params["image_url"]
        }
        # ... same pattern

    <!--what does this method do exactly? is it going to create new style reference, if so, 
        where are we going to use it? i dont see it as a param for txt2img. I read that --sref
        can be used in midapi, does that mean --ref can be used as part of prompt. if so, 
        can i use style references I created in my mj account here?-->
    def style_reference(self, params: dict) -> Tuple[List[str], dict]:
        """
        params:
            prompt (str, required)
            image_urls (List[str], required)
            + optional params
        """
        payload = {
            "taskType": "mj_style_reference",
            "prompt": params["prompt"],
            "fileUrls": params["image_urls"]
        }
        # ... same pattern
    
    <!--same as above -->
    def omni_reference(self, params: dict) -> Tuple[List[str], dict]:
        """
        params:
            prompt (str, required)
            image_urls (List[str], required)
            ow: int 1-1000 (omni strength)
            # Note: speed not supported
        """
        payload = {
            "taskType": "mj_omni_reference",
            "prompt": params["prompt"],
            "fileUrls": params["image_urls"]
        }
        # ... same pattern

    def txt2vid(self, params: dict) -> Tuple[List[str], dict]:
        """
        params:
            prompt (str, required)
            hd: bool (use mj_video_hd vs mj_video)
            batch_size: 1 | 2 | 4
            motion: "high" | "low"
            aspect_ratio: str
            # Note: speed not supported
        """
        task_type = "mj_video_hd" if params.get("hd") else "mj_video"
        payload = {"taskType": task_type, "prompt": params["prompt"]}
        # ... same pattern

    def img2vid(self, params: dict) -> Tuple[List[str], dict]:
        """
        params:
            prompt (str, required)
            image_url (str, required)
            + same as txt2vid
        """
        # ... same pattern with fileUrl

    # === Post-Processing ===

    <!--all post processing require task_id which is result of main request, but we dont extract it as main response,
        but (it seems like) stored as part of json body, looking at overall data from leonardo response,
        it seems to be using type of task id, wonder if we extract it separately as we do for urls. there's
        later discussion about data storage-->

    def upscale(self, task_id: str, index: int = 0, **kwargs) -> Tuple[List[str], dict]:
        """
        Upscale image from previous generation.
        index: 0-3 (which of 4 generated images)
        kwargs: water_mark, callback_url
        """
        payload = {"taskId": task_id, "imageIndex": index}
        data = self._request("POST", "/api/v1/mj/generateUpscale", json_data=payload)
        result = self._poll_until_complete(data["data"]["taskId"])
        return self._extract_urls(result), result

    def vary(self, task_id: str, index: int = 0, **kwargs) -> Tuple[List[str], dict]:
        """Create variation. Same signature as upscale."""
        # Uses /api/v1/mj/generateVary

    def extend_video(self, task_id: str, index: int, params: dict) -> Tuple[List[str], dict]:
        """
        params:
            prompt (str, required): continuation prompt
            auto: bool (mj_video_extend_auto vs mj_video_extend_manual)
        """
        # Uses /api/v1/mj/generateVideoExtend

    # === Utility ===

    def get_credits(self) -> int:
        """Returns remaining credits."""
        data = self._request("GET", "/api/v1/common/credit")
        return int(data["data"])

    def get_download_url(self, url: str) -> str:
        """Get temp download URL (valid 20 min)."""
        data = self._request("POST", "/api/v1/common/download-url", json_data={"url": url})
        return data["data"]

    def get_task_status(self, task_id: str) -> dict:
        """Get status without polling. For manual status checks."""
        data = self._request("GET", "/api/v1/mj/record-info", params={"taskId": task_id})
        return data["data"]
```

---

## Leonardo Client

### API Reference
- Base URL: `https://cloud.leonardo.ai/api/rest/v1`
- Auth: `Authorization: Bearer {LEONARDO_API_KEY}`
- Docs: https://docs.leonardo.ai/reference

### Endpoints Used

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/generations` | POST | Image generation |
| `/generations/{id}` | GET | Generation status |
| `/generations-image-to-video` | POST | Image to video |
| `/variations/upscale` | POST | Upscale image |
| `/variations/{id}` | GET | Variation status |
| `/me` | GET | User info + credits |

### Task Status Values
- `PENDING` = In progress
- `COMPLETE` = Done
- `FAILED` = Error

### Pseudo Code

```python
class LeonardoClient:
    BASE_URL = "https://cloud.leonardo.ai/api/rest/v1"

    def __init__(self, api_key=None, timeout=300, poll_interval=5.0):
        self._api_key = api_key or os.getenv("LEONARDO_API_KEY")
        self._timeout = timeout
        self._poll_interval = poll_interval

    # === Core Request ===

    def _request(self, method, endpoint, params=None, json_data=None) -> dict:
        """Make authenticated request. Returns response JSON."""
        response = requests.request(
            method,
            f"{BASE_URL}{endpoint}",
            headers={"Authorization": f"Bearer {api_key}"},
            params=params,
            json=json_data
        )
        if not response.ok:
            raise RuntimeError(f"Leonardo API error: {response.status_code}")
        return response.json()

    # === Polling ===

    def _poll_generation(self, generation_id: str) -> dict:
        """Poll /generations/{id} until complete."""
        start = time.time()
        while time.time() - start < self._timeout:
            data = self._request("GET", f"/generations/{generation_id}")
            gen = data.get("generations_by_pk", {})
            status = gen.get("status")

            if status == "COMPLETE":
                return gen
            if status == "FAILED":
                raise RuntimeError("Generation failed")

            time.sleep(self._poll_interval)

        raise TimeoutError(f"Generation {generation_id} timed out")

    def _poll_variation(self, variation_id: str) -> dict:
        """Poll /variations/{id} until complete."""
        start = time.time()
        while time.time() - start < self._timeout:
            data = self._request("GET", f"/variations/{variation_id}")
            variations = data.get("generated_image_variation_generic", [])
            if not variations:
                time.sleep(self._poll_interval)
                continue

            var = variations[0]
            status = var.get("status")

            if status == "COMPLETE":
                return var
            if status == "FAILED":
                raise RuntimeError("Variation failed")

            time.sleep(self._poll_interval)

        raise TimeoutError(f"Variation {variation_id} timed out")

    def _extract_image_urls(self, generation: dict) -> List[str]:
        """Extract URLs from generated_images array."""
        return [img["url"] for img in generation.get("generated_images", [])]

    # === Generation Methods ===

    def txt2img(self, params: dict) -> Tuple[List[str], dict]:
        """
        params:
            prompt (str, required)
            width: int 32-1536 (multiple of 8)
            height: int 32-1536 (multiple of 8)
            num_images: int 1-8
            model_id: str (UUID)
            guidance_scale: int 1-20
            num_inference_steps: int 10-60
            seed: int
            negative_prompt: str
            preset_style: "ANIME" | "CINEMATIC" | "DYNAMIC" | etc
            alchemy: bool
            photo_real: bool
            ultra: bool
            public: bool
            elements: List[{"akUUID": str, "weight": float}]
        """
        payload = {"prompt": params["prompt"]}
        # Map params to API format

        data = self._request("POST", "/generations", json_data=payload)
        gen_id = data["sdGenerationJob"]["generationId"]

        result = self._poll_generation(gen_id)
        return self._extract_image_urls(result), result

    def img2img(self, params: dict) -> Tuple[List[str], dict]:
        """
        params:
            prompt (str, required)
            init_image_id (str, required): ID from uploaded/generated image
            init_strength: float 0.1-0.9
            + same optional params as txt2img
        """
        payload = {
            "prompt": params["prompt"],
            "init_image_id": params["init_image_id"],
            "init_strength": params.get("init_strength", 0.5)
        }
        # ... same pattern

    def img2vid(self, params: dict) -> Tuple[List[str], dict]:
        """
        params:
            prompt (str, required)
            image_id (str, required)
            image_type: "GENERATED" | "UPLOADED"
            model: "MOTION2" | "VEO3" | "MOTION2FAST" | "VEO3FAST" | "KLING2_1" | "KLING2_5"
            resolution: "RESOLUTION_480" | "RESOLUTION_720" | "RESOLUTION_1080"
            duration: int (4, 6, 8 for VEO3; 5, 10 for KLING2_5)
            frame_interpolation: bool
            seed: int
            negative_prompt: str
        """
        payload = {
            "prompt": params["prompt"],
            "imageId": params["image_id"],
            "imageType": params.get("image_type", "GENERATED")
        }
        # Map other params

        data = self._request("POST", "/generations-image-to-video", json_data=payload)
        gen_id = data["motionVideoGenerationJob"]["generationId"]

        result = self._poll_generation(gen_id)
        # Video URL extraction differs from images
        urls = self._extract_video_urls(result)
        return urls, result

    # === Post-Processing ===

    <!--here on other hand compared to task_id+index, uses image_id for refrence. may be its 
    useless store task_id/generation_id direcly as field in db at all, we just leave it inside
    metadata and extract as needed. question is, now we may have to maintain some kind of image id-->
    def upscale(self, image_id: str, **kwargs) -> Tuple[List[str], dict]:
        """
        Upscale an image.
        image_id: ID of generated image (from generated_images[].id)

        Note: Unlike MidAPI, Leonardo uses image ID directly, not task_id + index.
        """
        payload = {"id": image_id}
        data = self._request("POST", "/variations/upscale", json_data=payload)
        var_id = data["sdUpscaleJob"]["id"]

        result = self._poll_variation(var_id)
        return [result["url"]], result

    # === Utility ===

    def get_credits(self) -> int:
        """Returns remaining API tokens."""
        data = self._request("GET", "/me")
        user = data.get("user_details", [{}])[0]
        # Could be apiSubscriptionTokens or apiPaidTokens depending on plan
        return user.get("apiSubscriptionTokens", 0) + user.get("apiPaidTokens", 0)

    def get_generation_status(self, generation_id: str) -> dict:
        """Get status without polling."""
        data = self._request("GET", f"/generations/{generation_id}")
        return data.get("generations_by_pk", {})
```

---

## Key Differences Summary

| Aspect | MidAPI | Leonardo |
|--------|--------|----------|
| Generation endpoint | Single `/generate` with `taskType` | Separate endpoints per type |
| Status polling | `/record-info?taskId=` | `/generations/{id}` |
| Status values | `0,1,2,3` (int) | `PENDING,COMPLETE,FAILED` (str) |
| Upscale input | `taskId` + `imageIndex` (0-3) | `imageId` directly |
| Upscale polling | Same as generation | `/variations/{id}` |
| Results location | `resultInfoJson.resultUrls[]` | `generated_images[].url` |
| Video endpoint | Same as images | Separate `/generations-image-to-video` |
| Credits | Dedicated endpoint | Part of `/me` response |

---

## File Structure

```
server/modules/api/providers/
├── midapi/
│   ├── __init__.py
│   └── client.py
└── leonardo/
    ├── __init__.py
    └── client.py
```

---

<!--I want to discuss idea of storing data we recieve from APIs in this doc as well. At end of the day
    we need to store these responses in our db, probably with local storage of images. We can safely assume
    that image retrieval will be part of workflow run, what i imagine this would as follows,

    content_generation_metadata
        content_generation_metadata_id str
        workflow_run_id str
        provider enum(midjourney, leonardo)
        created_date datetime
        completed_data datetime
        request_data str
        response_data str
        generation_id str

    generated_content
        generated_content_id str
        workflow_run_id str <-- added for direct reference
        content_generation_metadata_id str
        external_id str <-- image_id for leonardo, {task_id}_{index} for mj?
        provider_url str
        local_path str

    feel free to change table names, field names
    -->

## Questions for Review

1. Should there be a router class that dispatches to these clients, or is direct client usage preferred?
<!--i think we should still have router, simply for the fact that workflow steps needs to be agnostic about what each provider do internally-->

2. For Leonardo's img2img, you need an `init_image_id`. Should we add a helper method to upload images, or assume the workflow handles this separately?
<!--lets not add anything for this right now, i know that mj supports this in a differnt way, but not sure if mjapi does support it.-->

3. Error handling: Should we wrap provider-specific errors into a common exception type, or let provider exceptions bubble up?
<!--I think we can have base set of errors, all these erros will have error data provided by provider. we can have one other exception type to catch
all errors not recognized by us.-->

4. Logging: Should clients log API calls, or is that handled at a higher level?
<!--clients can log what they want. make sure to handle log levels carefully. we alreay have issue of too many logs in server.-->
