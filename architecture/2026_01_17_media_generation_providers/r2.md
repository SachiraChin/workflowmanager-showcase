# Media Generation Providers Architecture - R2

## Summary

Design for integrating image/video generation APIs (MidAPI/Midjourney and Leonardo AI) into the workflow system. These providers handle text-to-image, image-to-image, text-to-video, image-to-video, upscaling, and variations.

---

## Design Decisions

### 1. No Abstract Base Class / Interface Normalization

**Decision**: Each provider is a standalone client. No shared base class, no forced interface conformity.

**Rationale**:
- MidAPI and Leonardo have fundamentally different APIs, parameters, and capabilities
- Forcing a unified interface leads to lowest common denominator, complex union types, leaky abstractions
- Workflows that use MidAPI expect MidAPI behavior. Swapping providers requires workflow changes anyway.

### 2. Return Pattern: `Tuple[List[str], dict]`

**Decision**: All generation methods return `(result_urls, raw_response)`

- `result_urls`: `List[str]` - Always an array, even for single outputs
- `raw_response`: `dict` - Full provider response for provider-specific data

**Note on IDs for post-processing**:
- MidAPI needs `task_id` + `index` for upscale/vary
- Leonardo needs `image_id` for upscale

Both are available in `raw_response`:
- MidAPI: `raw["taskId"]`
- Leonardo: `raw["generated_images"][index]["id"]`

We don't extract these separately since:
- The caller knows which provider they used
- The structure differs between providers
- Keeping it in raw_response avoids yet another return value

### 3. End-to-End Methods

**Decision**: Methods handle the full flow: submit → poll → return results

**Rationale**:
- Caller doesn't manage async complexity
- Polling logic is provider-specific
- Simpler API surface

### 4. Input as `Dict[str, Any]`

**Decision**: Generation parameters passed as dict, not typed dataclasses

**Rationale**:
- Workflow system is JSON-configured, inputs are dicts anyway
- Provider parameters are very different
- Validation happens in each client with clear error messages

### 5. Router Class

**Decision**: A router class dispatches to provider clients.

**Rationale**:
- Workflow steps should be agnostic about provider internals
- Single entry point for all media generation
- Provider selection via string identifier

### 6. Error Handling

**Decision**: Define base exception types that wrap provider-specific errors.

```python
class MediaGenerationError(Exception):
    """Base exception for all media generation errors."""
    def __init__(self, message: str, provider: str, provider_error: Any = None):
        self.provider = provider
        self.provider_error = provider_error  # Original error data from provider
        super().__init__(message)

class GenerationFailedError(MediaGenerationError):
    """Generation task failed (provider reported failure)."""
    pass

class GenerationTimeoutError(MediaGenerationError):
    """Polling timed out before completion."""
    pass

class AuthenticationError(MediaGenerationError):
    """Invalid or missing API key."""
    pass

class InsufficientCreditsError(MediaGenerationError):
    """Not enough credits/tokens for operation."""
    pass

class InvalidParameterError(MediaGenerationError):
    """Invalid input parameters."""
    pass

class ProviderError(MediaGenerationError):
    """Catch-all for unrecognized provider errors."""
    pass
```

### 7. Logging

**Decision**: Clients log at appropriate levels, minimizing noise.

- `DEBUG`: Full request/response payloads (only when debugging)
- `INFO`: Task started, task completed, credits used
- `WARNING`: Retries, rate limits, deprecation notices
- `ERROR`: Failures, timeouts, auth errors

Avoid logging at INFO level for routine polling iterations.

---

## Clarifications

### style_reference vs omni_reference (MidAPI)

These methods **use images as style references** for generation. They do NOT create/save style references.

**style_reference (`mj_style_reference`)**:
- You provide image URLs that influence the **style** of the output
- Similar to using `--sref <url>` in Midjourney prompt
- The images define the aesthetic/style, not the content

**omni_reference (`mj_omni_reference`)**:
- More comprehensive reference - influences both style AND content
- Has `ow` parameter (1-1000) to control reference strength
- Does not support `speed` parameter

**Can you use `--sref` in prompt instead?**
- Possibly, but the dedicated `taskType` is cleaner
- MidAPI may or may not pass through raw MJ parameters in prompt
- Would need testing to confirm

**Can you use saved MJ account style references?**
- Unknown - MidAPI is a proxy, unclear if it can access user's saved styles
- The documented approach uses image URLs directly

**Recommendation**: Keep these methods. They provide explicit, documented ways to use style/omni references. Remove if testing shows they're redundant with prompt parameters.

---

## Database Schema

### Tables

```
content_generation_metadata
├── id: str (UUID) <-- we should use same id name format we use in other places
├── workflow_run_id: str (FK)
├── provider: enum("midapi", "leonardo")
├── operation: enum("txt2img", "img2img", "txt2vid", "img2vid", "upscale", "vary", "extend")
├── created_at: datetime
├── completed_at: datetime (nullable)
├── status: enum("pending", "complete", "failed")
├── request_params: jsonb  -- Input parameters sent to API
├── response_data: jsonb   -- Full raw response from API
├── provider_task_id: str  -- taskId (MidAPI) or generationId (Leonardo)
├── error_message: str (nullable)
└── credits_used: int (nullable)

generated_content
├── id: str (UUID) <-- we should use same id name format we use in other places
├── workflow_run_id: str (FK)
├── metadata_id: str (FK -> content_generation_metadata.id)
├── index: int  -- Position in result array (0, 1, 2, 3)
├── provider_content_id: str (nullable)  -- image_id for Leonardo, null for MidAPI
├── content_type: enum("image", "video")
├── provider_url: str  -- Original URL from provider
├── local_path: str (nullable)  -- Local storage path after download
├── downloaded_at: datetime (nullable)
└── file_size_bytes: int (nullable)
```

<!--are we going to ask response fully somewhere? it seems like leonardo provides lots of details
in task response, wonder how valuable it is, or are we storing this data in response_data in
first table?-->

<!--next question is, where does this storage happens. most of fields here are provider specific
and i dont want to do a custom extraction to store data somewhere else. but in the same time,
data storage doesnt feel right inside the provider. can roter do this, that also doesnt feel
right-->

### Notes

1. **provider_task_id vs provider_content_id**:
   - `provider_task_id`: The generation job ID (for status polling)
   - `provider_content_id`: Individual content ID (for post-processing)
   - MidAPI uses task_id + index, so `provider_content_id` can be null
   - Leonardo has actual image IDs

2. **For MidAPI upscale/vary**: Use `metadata.provider_task_id` + `generated_content.index`

3. **For Leonardo upscale**: Use `generated_content.provider_content_id`

4. **Local storage**: `local_path` populated when content is downloaded. Provider URLs may expire.

---

## Router Class

```python
class MediaRouter:
    """
    Router for media generation providers.
    Dispatches to provider-specific clients based on provider string.
    """

    def __init__(self):
        self._clients = {
            "midapi": MidAPIClient(),
            "leonardo": LeonardoClient(),
        }

    def _get_client(self, provider: str):
        client = self._clients.get(provider)
        if not client:
            raise ValueError(f"Unknown provider: {provider}. Available: {list(self._clients.keys())}")
        return client

    # === Generation ===

    def txt2img(self, provider: str, params: dict) -> Tuple[List[str], dict]:
        return self._get_client(provider).txt2img(params)

    def img2img(self, provider: str, params: dict) -> Tuple[List[str], dict]:
        return self._get_client(provider).img2img(params)

    def txt2vid(self, provider: str, params: dict) -> Tuple[List[str], dict]:
        return self._get_client(provider).txt2vid(params)

    def img2vid(self, provider: str, params: dict) -> Tuple[List[str], dict]:
        return self._get_client(provider).img2vid(params)

    # === Post-Processing ===
    # These have different signatures per provider, so we pass through

    def upscale(self, provider: str, **kwargs) -> Tuple[List[str], dict]:
        """
        MidAPI: upscale(provider="midapi", task_id="...", index=0)
        Leonardo: upscale(provider="leonardo", image_id="...")
        """
        return self._get_client(provider).upscale(**kwargs)

    def vary(self, provider: str, **kwargs) -> Tuple[List[str], dict]:
        """MidAPI only: vary(provider="midapi", task_id="...", index=0)"""
        return self._get_client(provider).vary(**kwargs)

    # === Provider-Specific ===
    # Exposed for operations that don't have cross-provider equivalents

    def style_reference(self, params: dict) -> Tuple[List[str], dict]:
        """MidAPI only."""
        return self._clients["midapi"].style_reference(params)

    def omni_reference(self, params: dict) -> Tuple[List[str], dict]:
        """MidAPI only."""
        return self._clients["midapi"].omni_reference(params)

    def extend_video(self, task_id: str, index: int, params: dict) -> Tuple[List[str], dict]:
        """MidAPI only."""
        return self._clients["midapi"].extend_video(task_id, index, params)

    # === Utility ===

    def get_credits(self, provider: str) -> int:
        return self._get_client(provider).get_credits()

    def get_download_url(self, url: str) -> str:
        """MidAPI only - get temp download URL."""
        return self._clients["midapi"].get_download_url(url)
```

---

## MidAPI Client

### API Reference
- Base URL: `https://api.midapi.ai`
- Auth: `Authorization: Bearer {MIDAPI_API_KEY}`
- Docs: https://docs.midapi.ai/

### Endpoints

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/v1/mj/generate` | POST | Image/video generation |
| `/api/v1/mj/record-info` | GET | Task status polling |
| `/api/v1/mj/generateUpscale` | POST | Upscale image |
| `/api/v1/mj/generateVary` | POST | Create variation |
| `/api/v1/mj/generateVideoExtend` | POST | Extend video |
| `/api/v1/common/credit` | GET | Check credits |
| `/api/v1/common/download-url` | POST | Get temp download URL |

### Task Status Values
- `0` = Generating (pending)
- `1` = Success (complete)
- `2` = Failed
- `3` = Generation Failed

### Pseudo Code

```python
class MidAPIClient:
    BASE_URL = "https://api.midapi.ai"
    ENV_KEY = "MIDAPI_API_KEY"

    def __init__(self, api_key=None, timeout=300, poll_interval=5.0):
        self._api_key = api_key
        self._timeout = timeout
        self._poll_interval = poll_interval

    def _get_api_key(self) -> str:
        key = self._api_key or os.getenv(self.ENV_KEY)
        if not key:
            raise AuthenticationError("API key not provided", provider="midapi")
        return key

    def _request(self, method, endpoint, params=None, json_data=None) -> dict:
        response = requests.request(...)
        data = response.json()

        if data["code"] == 401:
            raise AuthenticationError(data["msg"], "midapi", data)
        if data["code"] == 402:
            raise InsufficientCreditsError(data["msg"], "midapi", data)
        if data["code"] != 200:
            raise ProviderError(data["msg"], "midapi", data)

        return data

    def _poll_until_complete(self, task_id) -> dict:
        start = time.time()
        while time.time() - start < self._timeout:
            data = self._request("GET", "/api/v1/mj/record-info", params={"taskId": task_id})
            task = data["data"]

            if task["successFlag"] == 1:
                return task
            if task["successFlag"] in (2, 3):
                raise GenerationFailedError(
                    task.get("errorMessage", "Generation failed"),
                    "midapi",
                    task
                )

            time.sleep(self._poll_interval)

        raise GenerationTimeoutError(f"Task {task_id} timed out", "midapi")

    def _extract_urls(self, task_data) -> List[str]:
        urls = []
        result_info = task_data.get("resultInfoJson", {})
        for item in result_info.get("resultUrls", []):
            if isinstance(item, dict):
                urls.append(item["resultUrl"])
            else:
                urls.append(item)
        return urls

    # === Generation Methods ===

    def txt2img(self, params: dict) -> Tuple[List[str], dict]:
        """
        params:
            prompt (str, required)
            speed: "relaxed" | "fast" | "turbo"
            aspect_ratio: "1:1" | "16:9" | "9:16" | etc
            version: "7" | "6.1" | "6" | "5.2" | "5.1" | "niji6"
            variety: int 0-100 (increment by 5)
            stylization: int 0-1000 (multiples of 50)
            weirdness: int 0-3000 (multiples of 100)
            water_mark: str
            enable_translation: bool
            callback_url: str
        """
        if "prompt" not in params:
            raise InvalidParameterError("prompt is required", "midapi")

        payload = {
            "taskType": "mj_txt2img",
            "prompt": params["prompt"][:2000]
        }
        self._map_optional_params(payload, params)

        data = self._request("POST", "/api/v1/mj/generate", json_data=payload)
        task_id = data["data"]["taskId"]

        result = self._poll_until_complete(task_id)
        return self._extract_urls(result), result

    def img2img(self, params: dict) -> Tuple[List[str], dict]:
        """
        params:
            prompt (str, required)
            image_url (str, required)
            + optional params from txt2img
        """
        # taskType = "mj_img2img", fileUrl = params["image_url"]
        ...

    def style_reference(self, params: dict) -> Tuple[List[str], dict]:
        """
        Generate images using provided images as STYLE reference.
        The reference images influence the aesthetic/style of output.

        params:
            prompt (str, required)
            image_urls (List[str], required): URLs of style reference images
            + optional params (no speed for this type)
        """
        # taskType = "mj_style_reference", fileUrls = params["image_urls"]
        ...

    def omni_reference(self, params: dict) -> Tuple[List[str], dict]:
        """
        Generate images using provided images as OMNI reference.
        Influences both style AND content of output.

        params:
            prompt (str, required)
            image_urls (List[str], required): URLs of reference images
            ow (int): Reference strength 1-1000
            + optional params (no speed for this type)
        """
        # taskType = "mj_omni_reference", fileUrls, ow
        ...

    def txt2vid(self, params: dict) -> Tuple[List[str], dict]:
        """
        params:
            prompt (str, required)
            hd: bool (mj_video_hd vs mj_video)
            batch_size: 1 | 2 | 4
            motion: "high" | "low"
            aspect_ratio: str
        """
        # taskType = "mj_video" or "mj_video_hd"
        ...

    def img2vid(self, params: dict) -> Tuple[List[str], dict]:
        """
        params:
            prompt (str, required)
            image_url (str, required)
            + txt2vid params
        """
        ...

    # === Post-Processing ===

    def upscale(self, task_id: str, index: int = 0, **kwargs) -> Tuple[List[str], dict]:
        """
        Upscale image from previous generation.

        Args:
            task_id: From previous generation's raw["taskId"]
            index: 0-3 (which of 4 generated images)
            **kwargs: water_mark, callback_url
        """
        if not 0 <= index <= 3:
            raise InvalidParameterError("index must be 0-3", "midapi")

        payload = {"taskId": task_id, "imageIndex": index}
        # Add optional kwargs

        data = self._request("POST", "/api/v1/mj/generateUpscale", json_data=payload)
        result = self._poll_until_complete(data["data"]["taskId"])
        return self._extract_urls(result), result

    def vary(self, task_id: str, index: int = 0, **kwargs) -> Tuple[List[str], dict]:
        """Create variation. Same signature as upscale."""
        # POST /api/v1/mj/generateVary
        ...

    def extend_video(self, task_id: str, index: int, params: dict) -> Tuple[List[str], dict]:
        """
        Extend existing video.

        Args:
            task_id: From previous video generation
            index: Which video from batch
            params:
                prompt (str, required): Continuation description
                auto: bool (auto vs manual mode)
        """
        # POST /api/v1/mj/generateVideoExtend
        ...

    # === Utility ===

    def get_credits(self) -> int:
        data = self._request("GET", "/api/v1/common/credit")
        return int(data["data"])

    def get_download_url(self, url: str) -> str:
        """Get temp download URL (valid 20 min)."""
        data = self._request("POST", "/api/v1/common/download-url", json_data={"url": url})
        return data["data"]

    def get_task_status(self, task_id: str) -> dict:
        """Get status without polling."""
        data = self._request("GET", "/api/v1/mj/record-info", params={"taskId": task_id})
        return data["data"]
```

---

## Leonardo Client

### API Reference
- Base URL: `https://cloud.leonardo.ai/api/rest/v1`
- Auth: `Authorization: Bearer {LEONARDO_API_KEY}`
- Docs: https://docs.leonardo.ai/reference

### Endpoints

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/generations` | POST | Image generation |
| `/generations/{id}` | GET | Generation status |
| `/generations-image-to-video` | POST | Image to video |
| `/variations/upscale` | POST | Upscale image |
| `/variations/{id}` | GET | Variation status |
| `/me` | GET | User info + credits |

### Task Status Values
- `PENDING` = In progress
- `COMPLETE` = Done
- `FAILED` = Error

### Pseudo Code

```python
class LeonardoClient:
    BASE_URL = "https://cloud.leonardo.ai/api/rest/v1"
    ENV_KEY = "LEONARDO_API_KEY"

    def __init__(self, api_key=None, timeout=300, poll_interval=5.0):
        self._api_key = api_key
        self._timeout = timeout
        self._poll_interval = poll_interval

    def _get_api_key(self) -> str:
        key = self._api_key or os.getenv(self.ENV_KEY)
        if not key:
            raise AuthenticationError("API key not provided", provider="leonardo")
        return key

    def _request(self, method, endpoint, params=None, json_data=None) -> dict:
        response = requests.request(...)

        if response.status_code == 401:
            raise AuthenticationError("Invalid API key", "leonardo")
        if response.status_code == 402:
            raise InsufficientCreditsError("Insufficient credits", "leonardo")
        if not response.ok:
            raise ProviderError(f"API error: {response.status_code}", "leonardo", response.text)

        return response.json()

    def _poll_generation(self, generation_id: str) -> dict:
        start = time.time()
        while time.time() - start < self._timeout:
            data = self._request("GET", f"/generations/{generation_id}")
            gen = data.get("generations_by_pk", {})
            status = gen.get("status")

            if status == "COMPLETE":
                return gen
            if status == "FAILED":
                raise GenerationFailedError("Generation failed", "leonardo", gen)

            time.sleep(self._poll_interval)

        raise GenerationTimeoutError(f"Generation {generation_id} timed out", "leonardo")

    def _poll_variation(self, variation_id: str) -> dict:
        start = time.time()
        while time.time() - start < self._timeout:
            data = self._request("GET", f"/variations/{variation_id}")
            variations = data.get("generated_image_variation_generic", [])

            if variations:
                var = variations[0]
                if var.get("status") == "COMPLETE":
                    return var
                if var.get("status") == "FAILED":
                    raise GenerationFailedError("Variation failed", "leonardo", var)

            time.sleep(self._poll_interval)

        raise GenerationTimeoutError(f"Variation {variation_id} timed out", "leonardo")

    def _extract_image_urls(self, generation: dict) -> List[str]:
        return [img["url"] for img in generation.get("generated_images", [])]

    def _extract_video_urls(self, generation: dict) -> List[str]:
        # Video URLs location may differ - need to verify
        images = generation.get("generated_images", [])
        urls = []
        for img in images:
            if img.get("motionMP4URL"):
                urls.append(img["motionMP4URL"])
            elif img.get("url"):
                urls.append(img["url"])
        return urls

    # === Generation Methods ===

    def txt2img(self, params: dict) -> Tuple[List[str], dict]:
        """
        params:
            prompt (str, required)
            width: int 32-1536 (multiple of 8), default 1024
            height: int 32-1536 (multiple of 8), default 768
            num_images: int 1-8, default 4
            model_id: str (UUID)
            guidance_scale: int 1-20, default 7
            num_inference_steps: int 10-60, default 15
            seed: int
            negative_prompt: str
            preset_style: "ANIME" | "CINEMATIC" | "DYNAMIC" | etc
            alchemy: bool, default true
            photo_real: bool
            ultra: bool
            public: bool
            elements: List[{"akUUID": str, "weight": float}]
        """
        if "prompt" not in params:
            raise InvalidParameterError("prompt is required", "leonardo")

        payload = {"prompt": params["prompt"]}
        self._map_optional_params(payload, params)

        data = self._request("POST", "/generations", json_data=payload)
        gen_id = data["sdGenerationJob"]["generationId"]

        result = self._poll_generation(gen_id)
        return self._extract_image_urls(result), result

    def img2img(self, params: dict) -> Tuple[List[str], dict]:
        """
        params:
            prompt (str, required)
            init_image_id (str, required): ID from uploaded/generated image
            init_strength: float 0.1-0.9, default 0.5
            + txt2img params
        """
        ...

    def img2vid(self, params: dict) -> Tuple[List[str], dict]:
        """
        params:
            prompt (str, required)
            image_id (str, required): ID of source image
            image_type: "GENERATED" | "UPLOADED", default "GENERATED"
            model: "MOTION2" | "VEO3" | "MOTION2FAST" | "VEO3FAST" | "KLING2_1" | "KLING2_5"
            resolution: "RESOLUTION_480" | "RESOLUTION_720" | "RESOLUTION_1080"
            duration: int (4, 6, 8 for VEO3; 5, 10 for KLING2_5)
            frame_interpolation: bool
            seed: int
            negative_prompt: str
        """
        if "prompt" not in params:
            raise InvalidParameterError("prompt is required", "leonardo")
        if "image_id" not in params:
            raise InvalidParameterError("image_id is required", "leonardo")

        payload = {
            "prompt": params["prompt"],
            "imageId": params["image_id"],
            "imageType": params.get("image_type", "GENERATED")
        }
        # Map other params

        data = self._request("POST", "/generations-image-to-video", json_data=payload)
        gen_id = data["motionVideoGenerationJob"]["generationId"]

        result = self._poll_generation(gen_id)
        return self._extract_video_urls(result), result

    # === Post-Processing ===

    def upscale(self, image_id: str, **kwargs) -> Tuple[List[str], dict]:
        """
        Upscale an image.

        Args:
            image_id: From previous generation's raw["generated_images"][index]["id"]
        """
        payload = {"id": image_id}

        data = self._request("POST", "/variations/upscale", json_data=payload)
        var_id = data["sdUpscaleJob"]["id"]

        result = self._poll_variation(var_id)
        return [result["url"]], result

    # === Utility ===

    def get_credits(self) -> int:
        data = self._request("GET", "/me")
        user = data.get("user_details", [{}])[0]
        return user.get("apiSubscriptionTokens", 0) + user.get("apiPaidTokens", 0)

    def get_generation_status(self, generation_id: str) -> dict:
        """Get status without polling."""
        data = self._request("GET", f"/generations/{generation_id}")
        return data.get("generations_by_pk", {})
```

---

## Key Differences Summary

| Aspect | MidAPI | Leonardo |
|--------|--------|----------|
| Generation endpoint | Single `/generate` with `taskType` | Separate endpoints per type |
| Status polling | `/record-info?taskId=` | `/generations/{id}` |
| Status values | `0,1,2,3` (int) | `PENDING,COMPLETE,FAILED` (str) |
| Upscale input | `taskId` + `imageIndex` (0-3) | `imageId` directly |
| Upscale polling | Same as generation | `/variations/{id}` |
| Results location | `resultInfoJson.resultUrls[]` | `generated_images[].url` |
| Video endpoint | Same as images | `/generations-image-to-video` |
| Credits | Dedicated endpoint | Part of `/me` response |
| Style reference | Dedicated taskType | Via elements/LoRA |

---

## File Structure

```
server/modules/api/providers/
├── __init__.py           # Exports router, exceptions
<!--we already have 2 other provider here, not sure following 2 belongs here. I wonder we we should
have these 2 inside providers anyways, current 2 providers are purely used to work across workflow
tasks while these two are meant to be used in specific steps as needed.-->
├── exceptions.py         # Shared exception types
├── router.py             # MediaRouter class
├── midapi/
│   ├── __init__.py
│   └── client.py
└── leonardo/
    ├── __init__.py
    └── client.py
```

---

## Questions for Review

1. **txt2vid for Leonardo**: Leonardo doesn't seem to have a direct text-to-video endpoint (only image-to-video). Should we:
   - Omit `txt2vid` from Leonardo client
   - Or chain txt2img + img2vid internally?
   <!--we can only support img2vid for now and its more stonger way to generate videos-->

2. **Database schema**: Does the proposed schema look correct? Any fields to add/remove?
<!--added comments on the section-->

3. **Style/omni reference**: Keep these methods, or wait to see if they're needed?
<!--keep them, I want to test them.-->
