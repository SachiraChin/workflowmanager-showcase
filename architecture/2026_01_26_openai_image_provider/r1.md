# OpenAI Image Generation Provider Architecture

## Summary

Design for integrating OpenAI's image generation API into the existing media provider system. This provider will support GPT Image models (gpt-image-1.5, gpt-image-1, gpt-image-1-mini) for text-to-image generation, image editing (inpainting), and image variations.

## Design Decisions

### 1. Follow Existing Provider Pattern

**Decision**: Implement as a new provider under `backend/providers/media/openai/` following the established `MediaProviderBase` interface.

**Rationale**:
- Consistency with existing Leonardo, MidAPI, and Stable Diffusion providers
- Automatic registration via `@register` decorator
- Works with existing task queue and workflow integration
- Standardized return types (`GenerationResult`, `ContentItem`, `PreviewInfo`)

### 2. Synchronous API (No Polling Required)

<!--just to clarify, even if there no polling, image generation will be done by
worker. so for ui, there's no difference from other apis-->

**Decision**: OpenAI's image API returns results directly in the response, unlike Leonardo/MidAPI which require polling.

**Rationale**:
- OpenAI API is synchronous - submit request, get image back immediately
- No `_poll_for_result` method needed
- Simplifies implementation
- May need longer HTTP timeout (generation can take 30-60 seconds)

### 3. Local Cost Calculation (No Pricing API)

**Decision**: Implement cost calculation using a static lookup table based on published pricing.

**Rationale**:
- OpenAI has no pre-request pricing calculator API (unlike Leonardo)
- Pricing is deterministic based on: model + quality + size + n
- Published rates are stable and rarely change
- Similar approach to MidAPI provider's `CREDIT_COSTS` table

### 4. Model Selection as Primary Parameter

**Decision**: Expose `model` as the primary configuration parameter with values: `gpt-image-1.5`, `gpt-image-1`, `gpt-image-1-mini`.

**Rationale**:
- Each model has different capabilities, speed, and cost
- User should explicitly choose based on their needs:
  - `gpt-image-1.5`: Best quality, fastest, recommended
  - `gpt-image-1`: Original model, good balance
  - `gpt-image-1-mini`: Budget option for high volume/drafts
- DALL-E models are deprecated (EOL May 2026), not included

### 5. Base64 Response Handling

<!--again, we are following existing pattern in worker-->

**Decision**: Request images as base64, upload to storage, return storage URLs.

**Rationale**:
- OpenAI returns images as base64 (`b64_json`) or temporary URLs
- Temporary URLs expire quickly (not suitable for storage)
- Base64 allows immediate local processing and upload to permanent storage
- Consistent with how other providers' images are handled downstream

---

## API Reference

- **Base URL**: `https://api.openai.com/v1`
- **Auth**: `Authorization: Bearer {OPENAI_API_KEY}`
- **Docs**: https://platform.openai.com/docs/api-reference/images

### Endpoints

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/images/generations` | POST | Text-to-image generation |
| `/images/edits` | POST | Image editing (inpainting) |
| `/images/variations` | POST | Image variations (DALL-E 2 only) |

### Response Format

```json
{
  "created": 1234567890,
  "data": [
    {
      "b64_json": "base64_encoded_image_data...",
      "revised_prompt": "The prompt as interpreted by the model"
    }
  ],
  "usage": {
    "input_tokens": 100,
    "output_tokens": 4096,
    "total_tokens": 4196
  }
}
```

---

## Technical Specification

### Supported Parameters

#### Generation (`/images/generations`)

| Parameter | Type | Values | Default | Notes |
|-----------|------|--------|---------|-------|
| `model` | string | `gpt-image-1.5`, `gpt-image-1`, `gpt-image-1-mini` | `gpt-image-1` | Required |
| `prompt` | string | max 32,000 chars | - | Required |
| `n` | integer | 1-10 | 1 | Number of images |
| `size` | string | `1024x1024`, `1024x1536`, `1536x1024` | `1024x1024` | Square is faster |
| `quality` | string | `low`, `medium`, `high` | `high` | Affects detail and cost |
| `background` | string | `transparent`, `opaque`, `auto` | `auto` | GPT models only |
| `output_format` | string | `png`, `jpeg`, `webp` | `png` | PNG/WebP for transparency |
| `output_compression` | integer | 0-100 | 100 | JPEG/WebP only |
| `moderation` | string | `auto`, `low` | `auto` | Content filtering |

#### Editing/Inpainting (`/images/edits`)

| Parameter | Type | Notes |
|-----------|------|-------|
| `image` | file/base64 | Source image (supports multiple for reference) |
| `mask` | file/base64 | Transparent = edit, colored = preserve |
| `prompt` | string | Description of desired edit |
| `input_fidelity` | string | `high`, `low` (gpt-image-1 only, not mini) |
| + all generation params | | |

### Provider Parameter Mapping

Map workflow params to OpenAI API format:

```python
PARAM_MAPPING = {
    # Workflow param -> OpenAI param
    "num_images": "n",
    "output_format": "response_format",  # We always use b64_json internally
}
```

### Size/Aspect Ratio Handling

OpenAI uses explicit size strings, not aspect ratios. Map common ratios:

```python
ASPECT_RATIO_TO_SIZE = {
    "1:1": "1024x1024",
    "2:3": "1024x1536",  # Portrait
    "3:2": "1536x1024",  # Landscape
}
```

---

## Pricing Table

Costs are per-image in USD. Based on published OpenAI pricing (January 2026).

```python
# (model, quality, size) -> cost_per_image_usd
OPENAI_IMAGE_COSTS = {
    # gpt-image-1.5 (~20% cheaper than gpt-image-1)
    ("gpt-image-1.5", "low", "1024x1024"): 0.008,
    ("gpt-image-1.5", "low", "1024x1536"): 0.010,
    ("gpt-image-1.5", "low", "1536x1024"): 0.010,
    ("gpt-image-1.5", "medium", "1024x1024"): 0.032,
    ("gpt-image-1.5", "medium", "1024x1536"): 0.040,
    ("gpt-image-1.5", "medium", "1536x1024"): 0.040,
    ("gpt-image-1.5", "high", "1024x1024"): 0.136,
    ("gpt-image-1.5", "high", "1024x1536"): 0.170,
    ("gpt-image-1.5", "high", "1536x1024"): 0.170,

    # gpt-image-1
    ("gpt-image-1", "low", "1024x1024"): 0.011,
    ("gpt-image-1", "low", "1024x1536"): 0.016,
    ("gpt-image-1", "low", "1536x1024"): 0.016,
    ("gpt-image-1", "medium", "1024x1024"): 0.042,
    ("gpt-image-1", "medium", "1024x1536"): 0.063,
    ("gpt-image-1", "medium", "1536x1024"): 0.063,
    ("gpt-image-1", "high", "1024x1024"): 0.167,
    ("gpt-image-1", "high", "1024x1536"): 0.250,
    ("gpt-image-1", "high", "1536x1024"): 0.250,

    # gpt-image-1-mini (budget option)
    ("gpt-image-1-mini", "low", "1024x1024"): 0.005,
    ("gpt-image-1-mini", "low", "1024x1536"): 0.007,
    ("gpt-image-1-mini", "low", "1536x1024"): 0.007,
    ("gpt-image-1-mini", "medium", "1024x1024"): 0.020,
    ("gpt-image-1-mini", "medium", "1024x1536"): 0.030,
    ("gpt-image-1-mini", "medium", "1536x1024"): 0.030,
    ("gpt-image-1-mini", "high", "1024x1024"): 0.080,
    ("gpt-image-1-mini", "high", "1024x1536"): 0.120,
    ("gpt-image-1-mini", "high", "1536x1024"): 0.120,
}
```

**Note**: These values are approximations based on published pricing. Verify against current OpenAI pricing page before implementation.

---

## Pseudo Code

```python
import os
import base64
import logging
import requests
from typing import Any, Dict, List, Optional

from ..base import (
    MediaProviderBase,
    ContentItem,
    GenerationResult,
    ProgressCallback,
    AuthenticationError,
    RateLimitError,
    GenerationError,
    ResolutionInfo,
    CreditInfo,
    PreviewInfo,
)
from ..registry import register

logger = logging.getLogger(__name__)

# API Configuration
OPENAI_BASE_URL = "https://api.openai.com/v1"
REQUEST_TIMEOUT_SECONDS = 120  # Long timeout for generation

# Available models
SUPPORTED_MODELS = [
    "gpt-image-1.5",  # Latest, fastest, best quality
    "gpt-image-1",     # Original model
    "gpt-image-1-mini", # Budget option
]

# Available sizes
SUPPORTED_SIZES = [
    "1024x1024",  # Square (fastest)
    "1024x1536",  # Portrait
    "1536x1024",  # Landscape
]

# Quality levels
QUALITY_LEVELS = ["low", "medium", "high"]

<!--question: these are the options we show in ui right, not ones above?-->
# Aspect ratio to size mapping
ASPECT_RATIO_TO_SIZE = {
    "1:1": "1024x1024",
    "2:3": "1024x1536",
    "3:2": "1536x1024",
    "9:16": "1024x1536",  # Alias for portrait
    "16:9": "1536x1024",  # Alias for landscape
}

# Pricing lookup table (model, quality, size) -> USD per image
OPENAI_IMAGE_COSTS = {
    # ... (as defined above)
}


@register("openai", concurrency=3)
class OpenAIProvider(MediaProviderBase):
    """
    OpenAI provider for image generation using GPT Image models.

    Requires OPENAI_API_KEY environment variable.

    Model Selection:
    - gpt-image-1.5: Latest flagship, 4x faster, best quality (recommended)
    - gpt-image-1: Original model, good balance
    - gpt-image-1-mini: Budget option for high volume
    """

    def __init__(self):
        self.api_key = os.environ.get("OPENAI_API_KEY")
        if not self.api_key:
            logger.warning("OPENAI_API_KEY not set in environment")

    @property
    def provider_id(self) -> str:
        return "openai"

    def _get_headers(self) -> Dict[str, str]:
        """Get authorization headers for API requests."""
        if not self.api_key:
            raise AuthenticationError("OPENAI_API_KEY not configured")
        return {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

    def _handle_response_error(self, response: requests.Response) -> None:
        """Handle HTTP error responses from OpenAI API."""
        if response.status_code == 200:
            return

        try:
            error_data = response.json()
            error_msg = error_data.get("error", {}).get("message", response.text)
        except Exception:
            error_msg = response.text

        if response.status_code == 401:
            raise AuthenticationError(f"Invalid API key: {error_msg}")
        elif response.status_code == 429:
            raise RateLimitError(f"Rate limited: {error_msg}", retry_after=60)
        elif response.status_code == 400:
            raise GenerationError(f"Bad request: {error_msg}")
        else:
            raise GenerationError(f"API error ({response.status_code}): {error_msg}")

    def _resolve_size(self, params: Dict[str, Any]) -> str:
        """
        Resolve image size from params.

        Supports:
        - Direct size: "1024x1024"
        - Aspect ratio mapping: "1:1" -> "1024x1024"
        """
        if "size" in params and params["size"] in SUPPORTED_SIZES:
            return params["size"]

        aspect_ratio = params.get("aspect_ratio", "1:1")
        return ASPECT_RATIO_TO_SIZE.get(aspect_ratio, "1024x1024")

    def _upload_to_storage(self, b64_data: str, filename: str) -> str:
        """
        Upload base64 image data to storage and return URL.

        TODO: Integrate with existing download/storage system.
        For now, this is a placeholder that should use the same
        storage mechanism as other providers.
        """
        # This should integrate with backend/providers/media/download.py
        # or wherever persistent storage is handled
        raise NotImplementedError("Storage integration needed")

    def txt2img(
        self,
        prompt: str,
        params: Dict[str, Any],
        progress_callback: Optional[ProgressCallback] = None
    ) -> GenerationResult:
        """
        Generate images from a text prompt using OpenAI GPT Image models.

        Args:
            prompt: Text description (max 32,000 chars)
            params: Generation parameters:
                - model: str ("gpt-image-1.5", "gpt-image-1", "gpt-image-1-mini")
                - size: str ("1024x1024", "1024x1536", "1536x1024")
                - aspect_ratio: str (alternative to size: "1:1", "2:3", "3:2")
                - quality: str ("low", "medium", "high")
                - n / num_images: int (1-10)
                - background: str ("transparent", "opaque", "auto")
                - output_format: str ("png", "jpeg", "webp")
                - output_compression: int (0-100, for jpeg/webp)
                - moderation: str ("auto", "low")
            progress_callback: Optional callback (called once before request)

        Returns:
            GenerationResult with image URLs
        """
        # Resolve parameters
        model = params.get("model", "gpt-image-1")
        size = self._resolve_size(params)
        quality = params.get("quality", "high")
        n = params.get("n") or params.get("num_images", 1)
        if isinstance(n, str):
            n = int(n)

        # Build request payload
        payload = {
            "model": model,
            "prompt": prompt[:32000],  # Max prompt length
            "n": n,
            "size": size,
            "quality": quality,
            "response_format": "b64_json",  # Always request base64
        }

        # Optional parameters
        if "background" in params:
            payload["background"] = params["background"]
        if "output_format" in params:
            # Note: This affects the image format, not response_format
            payload["output_format"] = params["output_format"]
        if "output_compression" in params:
            payload["output_compression"] = params["output_compression"]
        if "moderation" in params:
            payload["moderation"] = params["moderation"]

        logger.info(
            f"[OpenAI] Starting txt2img: model={model}, size={size}, "
            f"quality={quality}, n={n}"
        )

        # Call progress callback before request
        if progress_callback:
            progress_callback(0, "Generating with OpenAI...")

        # Make generation request (synchronous - no polling needed)
        response = requests.post(
            f"{OPENAI_BASE_URL}/images/generations",
            json=payload,
            headers=self._get_headers(),
            timeout=REQUEST_TIMEOUT_SECONDS
        )

        self._handle_response_error(response)
        result = response.json()

        # Extract images from response
        content = []
        for i, img_data in enumerate(result.get("data", [])):
            b64_json = img_data.get("b64_json")
            if b64_json:
                # TODO: Upload to storage and get permanent URL
                # For now, create a data URI (temporary solution)
                url = f"data:image/png;base64,{b64_json}"
                content.append(ContentItem(url=url, seed=-1))

        if progress_callback:
            elapsed_ms = 0  # We don't track actual time in sync API
            progress_callback(elapsed_ms, "Complete!")

        logger.info(f"[OpenAI] Generation complete: {len(content)} images")

        return GenerationResult(
            content=content,
            raw_response=result,
            provider_task_id=None  # No task ID for sync API
        )

    def img2img(
        self,
        source_image: str,
        prompt: str,
        params: Dict[str, Any],
        progress_callback: Optional[ProgressCallback] = None
    ) -> GenerationResult:
        """
        Edit an image using OpenAI's image edit endpoint (inpainting).

        Args:
            source_image: URL or base64 of source image
            prompt: Description of desired edit
            params: Edit parameters:
                - mask: str (URL or base64 of mask image)
                - input_fidelity: str ("high", "low") - gpt-image-1 only
                - + all txt2img parameters
            progress_callback: Optional callback

        Returns:
            GenerationResult with edited image URLs
        """
        # Get image as base64
        if source_image.startswith("data:"):
            image_b64 = source_image.split(",")[1]
        elif source_image.startswith(("http://", "https://")):
            # Download and convert to base64
            resp = requests.get(source_image, timeout=60)
            resp.raise_for_status()
            image_b64 = base64.b64encode(resp.content).decode("utf-8")
        else:
            image_b64 = source_image  # Assume already base64

        model = params.get("model", "gpt-image-1")
        size = self._resolve_size(params)
        quality = params.get("quality", "high")
        n = params.get("n") or params.get("num_images", 1)

        # Build multipart form data for edit endpoint
        # Note: Edit endpoint requires multipart/form-data, not JSON
        files = {
            "image": ("image.png", base64.b64decode(image_b64), "image/png"),
        }

        data = {
            "model": model,
            "prompt": prompt[:32000],
            "n": n,
            "size": size,
            "quality": quality,
            "response_format": "b64_json",
        }

        # Add mask if provided
        if "mask" in params and params["mask"]:
            mask = params["mask"]
            if mask.startswith("data:"):
                mask_b64 = mask.split(",")[1]
            elif mask.startswith(("http://", "https://")):
                resp = requests.get(mask, timeout=60)
                resp.raise_for_status()
                mask_b64 = base64.b64encode(resp.content).decode("utf-8")
            else:
                mask_b64 = mask
            files["mask"] = ("mask.png", base64.b64decode(mask_b64), "image/png")

        # input_fidelity for gpt-image-1 only
        if "input_fidelity" in params and model == "gpt-image-1":
            data["input_fidelity"] = params["input_fidelity"]

        logger.info(f"[OpenAI] Starting img2img edit: model={model}, size={size}")

        if progress_callback:
            progress_callback(0, "Editing with OpenAI...")

        # Make edit request
        headers = {"Authorization": f"Bearer {self.api_key}"}  # No Content-Type for multipart
        response = requests.post(
            f"{OPENAI_BASE_URL}/images/edits",
            data=data,
            files=files,
            headers=headers,
            timeout=REQUEST_TIMEOUT_SECONDS
        )

        self._handle_response_error(response)
        result = response.json()

        # Extract images
        content = []
        for img_data in result.get("data", []):
            b64_json = img_data.get("b64_json")
            if b64_json:
                url = f"data:image/png;base64,{b64_json}"
                content.append(ContentItem(url=url, seed=-1))

        if progress_callback:
            progress_callback(0, "Complete!")

        logger.info(f"[OpenAI] Edit complete: {len(content)} images")

        return GenerationResult(
            content=content,
            raw_response=result,
            provider_task_id=None
        )

    def img2vid(
        self,
        source_image: str,
        prompt: str,
        params: Dict[str, Any],
        progress_callback: Optional[ProgressCallback] = None
    ) -> GenerationResult:
        """
        Not supported by OpenAI Image API.

        Note: OpenAI has Sora for video generation, but it's a separate API.

        Raises:
            NotImplementedError: Always
        """
        raise NotImplementedError(
            "OpenAI Image API does not support image-to-video generation. "
            "Use Leonardo or MidJourney for video generation."
        )

    def get_preview_info(
        self,
        action_type: str,
        params: Dict[str, Any]
    ) -> PreviewInfo:
        """
        Get preview information (resolution and cost) for generation config.

        Uses static pricing table - no API call needed.
        """
        # Resolve parameters
        model = params.get("model", "gpt-image-1")
        size = self._resolve_size(params)
        quality = params.get("quality", "high")
        n = params.get("n") or params.get("num_images", 1)
        if isinstance(n, str):
            n = int(n)

        # Parse size for resolution
        parts = size.split("x")
        width = int(parts[0])
        height = int(parts[1])
        megapixels = round((width * height) / 1_000_000, 2)

        resolution = ResolutionInfo(
            width=width,
            height=height,
            megapixels=megapixels
        )

        # Look up cost from pricing table
        cost_per_image = OPENAI_IMAGE_COSTS.get(
            (model, quality, size),
            0.10  # Fallback if not found
        )
        total_cost = cost_per_image * n

        credits = CreditInfo(
            credits=0,  # OpenAI uses USD, not credits
            cost_per_credit=0,
            total_cost_usd=round(total_cost, 4),
            num_images=n,
            credits_per_image=0,
            cost_per_image_usd=round(cost_per_image, 4)
        )

        return PreviewInfo(resolution=resolution, credits=credits)
```

---

## File Structure

```
backend/providers/media/openai/
├── __init__.py          # Export OpenAIProvider
└── provider.py          # Main provider implementation
```

---

## Integration Points

### 1. Storage Integration

The provider returns base64 images that need to be uploaded to permanent storage. This should integrate with the existing `backend/providers/media/download.py` mechanism.

**TODO**: Determine how other providers handle this. Leonardo/MidAPI return URLs that are downloaded separately. OpenAI returns base64 directly.

### 2. Environment Variable

Add `OPENAI_API_KEY` to:
- `.env.example`
- Server configuration documentation

### 3. Provider Registration

The `@register("openai", concurrency=3)` decorator auto-registers the provider. Import in `backend/providers/media/__init__.py` to ensure registration at startup.

---

## Questions for Review

<!--please read how backend/worker works, i forgot to mention it earlier. after you read it, we'll do another iteration-->

1. **Base64 vs URL handling**: OpenAI returns base64 directly. Should we:
   - (a) Store base64 temporarily and process later (like we do with URLs)?
   - (b) Upload to storage immediately within the provider?
   - (c) Return data URIs and let the caller handle storage?

2. **Concurrency limit**: I set `concurrency=3` similar to Leonardo. OpenAI has rate limits but they're per-minute based. Should this be higher/lower?

3. **Model default**: I defaulted to `gpt-image-1` for safety. Should we default to `gpt-image-1.5` (better but newer) or `gpt-image-1-mini` (cheaper)?

4. **Pricing accuracy**: The pricing table values are approximations from web research. Should we verify against current OpenAI pricing before implementation?

5. **Edit endpoint complexity**: The `/images/edits` endpoint uses multipart form data, not JSON. This is more complex than other providers. Is full edit support needed for v1, or can we start with txt2img only?

6. **Seed handling**: OpenAI doesn't expose seeds in the API. I'm returning `seed=-1` for all images. Is this acceptable, or should we track something else?
