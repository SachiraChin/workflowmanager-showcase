# Keyword History Module Refactor - Revision 4

**Date:** 2026-01-10
**Status:** Draft - Awaiting Review
**Changes from r3:** Simplified scoping, sandboxed MongoDB pipeline for filters

---

## 1. Summary

Create a new `io.weighted_keywords` module that stores and retrieves weighted keywords scoped by `workflow_template_id` only. Users can provide MongoDB pipelines for flexible filtering, sandboxed to their workflow.

---

## 2. Design Principles

1. **Workflow-scoped storage** - Keywords belong to a workflow template, nothing more
2. **Weight accumulation by default** - Controlled by `accumulate_weight` parameter
3. **Flexible filtering** - User provides MongoDB pipeline, sandboxed within workflow_template_id
4. **Pass-through fields** - Module stores whatever fields are provided (keyword, weight, category, source, expires, etc.)

---

## 3. Database Schema

### 3.1 Collection: `weighted_keywords`

Minimal required fields:
```json
{
  "workflow_template_id": "tpl_abc123",   // Enforced by module
  "keyword": "sunny window",               // Required
  "weight": 240,                           // Required, accumulated
  // Everything below is optional, provided by workflow:
  "category": "setting",
  "source": "selected",
  "last_used": ISODate("2026-01-10T15:30:00Z"),
  "expires": ISODate("2026-01-20T15:30:00Z")
}
```

### 3.2 Indexes

```javascript
db.weighted_keywords.createIndex({
  "workflow_template_id": 1,
  "keyword": 1
}, { unique: true })
```

---

## 4. Module: `io.weighted_keywords`

### 4.1 Inputs

```python
@property
def inputs(self) -> List[ModuleInput]:
    return [
        ModuleInput(
            name="mode",
            type="string",
            required=True,
            description="Operation: 'save' or 'load'"
        ),

        # === SAVE MODE ===
        ModuleInput(
            name="weighted_keywords",
            type="array",
            required=False,
            description="Array of keyword objects. Required: keyword, weight. Optional: any other fields."
        ),
        ModuleInput(
            name="accumulate_weight",
            type="boolean",
            required=False,
            default=True,
            description="If true (default), weight adds to existing. If false, weight replaces."
        ),

        # === LOAD MODE ===
        ModuleInput(
            name="pipeline",
            type="array",
            required=False,
            default=[],
            description="MongoDB aggregation pipeline stages. Executed after workflow_template_id filter."
        ),
        ModuleInput(
            name="limit",
            type="number",
            required=False,
            default=100,
            description="Maximum keywords to return"
        )
    ]
```

### 4.2 Outputs

```python
@property
def outputs(self) -> List[ModuleOutput]:
    return [
        # Load mode
        ModuleOutput(
            name="weighted_keywords",
            type="array",
            description="Array of keyword objects matching pipeline"
        ),
        ModuleOutput(
            name="count",
            type="number",
            description="Number of keywords returned"
        ),

        # Save mode
        ModuleOutput(
            name="saved_count",
            type="number",
            description="Number of keywords saved/updated"
        )
    ]
```

---

## 5. Sandboxed MongoDB Pipeline

### 5.1 How It Works

The module enforces `workflow_template_id` as a mandatory first stage, then appends user's pipeline:

```python
def _execute_load(self, inputs, context):
    user_pipeline = inputs.get('pipeline', [])
    limit = inputs.get('limit', 100)

    # Enforce workflow scoping - user cannot bypass this
    enforced_match = {
        "$match": {
            "workflow_template_id": context.workflow_template_id
        }
    }

    # Build final pipeline
    <!--I just want to stress this out, user pipeline should NOT be 
        able override enforced part, you have to make sure user provided
        query is sandboxed.-->
    pipeline = [enforced_match] + user_pipeline + [{"$limit": limit}]

    # Execute
    results = list(db.weighted_keywords.aggregate(pipeline))
    return {"weighted_keywords": results, "count": len(results)}
```

### 5.2 Example Pipelines

**Simple category filter:**
```json
{
  "pipeline": [
    {"$match": {"category": {"$in": ["setting", "object"]}}}
  ]
}
```

**Filter by source and sort by weight:**
```json
{
  "pipeline": [
    {"$match": {"source": "selected"}},
    {"$sort": {"weight": -1}}
  ]
}
```

**Exclude expired and filter by date:**
```json
{
  "pipeline": [
    {"$match": {
      "expires": {"$gt": "$$NOW"},
      "last_used": {"$gte": {"$dateSubtract": {"startDate": "$$NOW", "unit": "day", "amount": 7}}}
    }},
    {"$sort": {"weight": -1}}
  ]
}
```

**Two-tier exclusion (OMS style) - get all, let prompt template filter:**
```json
{
  "pipeline": [
    {"$match": {"category": {"$in": ["setting", "object"]}}},
    {"$sort": {"weight": -1}}
  ]
}
```

Then in prompt:
```jinja2
### Critically Prohibited
{% for kw in state.all_keywords | selectattr('source', 'equalto', 'selected') %}
{{ kw.keyword }}:{{ kw.weight }}{% if not loop.last %}, {% endif %}
{% endfor %}

### Optionally Prohibited
{% for kw in state.all_keywords | selectattr('source', 'equalto', 'generated') %}
{{ kw.keyword }}:{{ kw.weight }}{% if not loop.last %}, {% endif %}
{% endfor %}
```

---

## 6. Usage Examples

### 6.1 Save Keywords (Accumulate Weight)

```json
{
  "module_id": "io.weighted_keywords",
  "inputs": {
    "mode": "save",
    "weighted_keywords": "{{ state.flattened_keywords }}"
  },
  "name": "save_keywords"
}
```

Input data example:
```json
[
  {"keyword": "sunny window", "weight": 80, "category": "setting", "source": "generated"},
  {"keyword": "morning light", "weight": 60, "category": "atmosphere", "source": "generated"}
]
```

### 6.2 Save Keywords (Replace Weight)

```json
{
  "module_id": "io.weighted_keywords",
  "inputs": {
    "mode": "save",
    "weighted_keywords": "{{ state.selected_keywords }}",
    "accumulate_weight": false
  },
  "name": "update_selected"
}
```

### 6.3 Load Keywords with Filter

```json
{
  "module_id": "io.weighted_keywords",
  "inputs": {
    "mode": "load",
    "pipeline": [
      {"$match": {"category": {"$in": ["setting", "object"]}}},
      {"$sort": {"weight": -1}}
    ],
    "limit": 50
  },
  "outputs_to_state": {
    "weighted_keywords": "keyword_exclusion_data"
  },
  "name": "load_keywords"
}
```

---

## 7. Flattening Nested Data

Since we're not adding a `flatten` filter, use `transform.query` module:

```json
<!--why cant we do this in single query and make it return data in the format we need?-->
{
  "module_id": "transform.query",
  "inputs": {
    "data": "{{ state.aesthetic_concepts_response }}",
    "query": "$.aesthetic_concepts[*].aesthetic_keywords[*]"
  },
  "outputs_to_state": {
    "result": "aesthetic_level_keywords"
  }
},
{
  "module_id": "transform.query",
  "inputs": {
    "data": "{{ state.aesthetic_concepts_response }}",
    "query": "$.aesthetic_concepts[*].ideas[*].idea_keywords[*]"
  },
  "outputs_to_state": {
    "result": "idea_level_keywords"
  }
},
{
  "module_id": "transform.concat_arrays",
  "inputs": {
    "arrays": ["{{ state.aesthetic_level_keywords }}", "{{ state.idea_level_keywords }}"]
  },
  "outputs_to_state": {
    "result": "flattened_keywords"
  }
}
```

Or use `transform.extract` with Jinja2 set operations (existing capability).

---

## 8. Migration Plan

### Step 1: Create New Module
1. Create `server/modules/io/weighted_keywords.py`
2. Implement save with accumulate_weight option
3. Implement load with sandboxed pipeline

### Step 2: Create New Collection
1. Create `weighted_keywords` collection
2. Add indexes

### Step 3: Update CC Workflow
1. Replace `history.keyword_history` with `io.weighted_keywords`
2. Remove Jinja2 hacks
3. Add keyword preparation steps if needed

### Step 4: Update OMS Workflow
1. Add keyword flattening steps (transform.query + concat)
2. Replace `db.query` with `io.weighted_keywords` load
3. Replace `history.keyword_history` with `io.weighted_keywords`

### Step 5: Cleanup
1. Remove `config.keyword_history` from workflow configs
2. Remove old `history.keyword_history` module
3. Update TECHNICAL_DEBT.md

---

## 9. Files to Modify/Create

| File | Action |
|------|--------|
| `server/modules/io/weighted_keywords.py` | **CREATE** |
| `server/api/database_history.py` | Add weighted_keywords methods |
| `workflows/cc/steps/2_scene_generation/step.json` | Use new module |
| `workflows/cc/workflow_v3.json` | Remove `config.keyword_history` |
| `workflows/oms/steps/1_user_input/step.json` | Use new module, add flattening |
| `workflows/oms/workflow_v3.json` | Remove `config.keyword_history` |
| `TECHNICAL_DEBT.md` | Close item #9 |
| `server/modules/history/keyword_history.py` | Remove |

---

## 10. Summary of Key Decisions

| Decision | Resolution |
|----------|------------|
| Scoping | workflow_template_id only |
| Weight behavior | Accumulate by default, `accumulate_weight=false` to replace |
| Filtering | User provides MongoDB pipeline, sandboxed |
| Flatten filter | Not adding - use transform.query |
| Collection name | `weighted_keywords` (new) |
| Extra fields | Pass-through (category, source, expires, etc.) |
