# Keyword History Module Refactor - Revision 5

**Date:** 2026-01-10
**Status:** Draft - Awaiting Review
**Changes from r4:** Stage whitelist approach for sandboxing (instead of in-memory)

---

## 1. Summary

Create a new `io.weighted_keywords` module that stores and retrieves weighted keywords scoped by `workflow_template_id`. User pipelines run directly on the database but are **sandboxed via stage whitelisting** - only safe stages are allowed, and dangerous stages that could access other collections are blocked.

---

## 2. Design Principles

1. **Workflow-scoped storage** - Keywords belong to a workflow template only
2. **Weight accumulation by default** - Controlled by `accumulate_weight` parameter
3. **Stage whitelist sandboxing** - Block dangerous stages, enforce workflow_template_id
4. **Pass-through fields** - Module stores whatever fields are provided

---

## 3. Security: Stage Whitelist Approach

### 3.1 Why Whitelist?

MongoDB aggregation pipelines cannot be sandboxed through syntax alone. Dangerous stages like `$lookup` and `$unionWith` can **inject documents from other collections**, bypassing any earlier `$match` filter.

Reference: [MongoDB NoSQL Injection with Aggregation Pipelines](https://soroush.me/blog/2024/06/mongodb-nosql-injection-with-aggregation-pipelines/)

### 3.2 Dangerous Stages (BLOCKED)

| Stage | Risk |
|-------|------|
| `$lookup` | Access other collections via joins |
| `$unionWith` | Merge data from other collections |
| `$merge` | Write to other collections |
| `$out` | Write results to a collection |
| `$function` | Execute arbitrary JavaScript |
| `$accumulator` | Execute JavaScript |
| `$graphLookup` | Recursive lookup across collections |

### 3.3 Safe Stages (ALLOWED)

```python
ALLOWED_STAGES = {
    '$match',      # Filter documents
    '$sort',       # Order results
    '$project',    # Shape output fields
    '$limit',      # Cap result count
    '$skip',       # Pagination
    '$group',      # Aggregate values
    '$unwind',     # Flatten arrays
    '$addFields',  # Add computed fields
    '$set',        # Alias for $addFields
    '$count',      # Count documents
    '$replaceRoot', # Reshape document root
    '$sample',     # Random sample
    '$bucket',     # Bucket by ranges
    '$bucketAuto', # Auto-bucket
    '$sortByCount', # Group and count
    '$facet',      # ONLY if nested stages are also whitelisted
}
```

### 3.4 Additional Validation

```python
def _validate_pipeline(self, pipeline: list) -> None:
    """Validate user pipeline for security."""
    for stage in pipeline:
        stage_name = list(stage.keys())[0]

        # Check stage is allowed
        if stage_name not in ALLOWED_STAGES:
            raise ModuleExecutionError(
                self.module_id,
                f"Pipeline stage '{stage_name}' is not allowed"
            )

        # Block workflow_template_id override in $match
        if stage_name == '$match':
            match_doc = stage['$match']
            if 'workflow_template_id' in match_doc:
                raise ModuleExecutionError(
                    self.module_id,
                    "Cannot override workflow_template_id in $match"
                )

        # Recursively validate $facet sub-pipelines
        if stage_name == '$facet':
            for facet_name, sub_pipeline in stage['$facet'].items():
                self._validate_pipeline(sub_pipeline)
```

---

## 4. Database Schema

### 4.1 Collection: `weighted_keywords`

```json
{
  "workflow_template_id": "tpl_abc123",   // Enforced by module
  "keyword": "sunny window",               // Required
  "weight": 240,                           // Required
  // Optional pass-through fields:
  "category": "setting",
  "source": "selected",
  "last_used": ISODate("2026-01-10T15:30:00Z"),
  "expires": ISODate("2026-01-20T15:30:00Z")
}
```

### 4.2 Indexes

```javascript
db.weighted_keywords.createIndex({
  "workflow_template_id": 1,
  "keyword": 1
}, { unique: true })

// For common query patterns
db.weighted_keywords.createIndex({
  "workflow_template_id": 1,
  "category": 1,
  "weight": -1
})
```

---

## 5. Module: `io.weighted_keywords`

### 5.1 Inputs

```python
@property
def inputs(self) -> List[ModuleInput]:
    return [
        ModuleInput(
            name="mode",
            type="string",
            required=True,
            description="Operation: 'save' or 'load'"
        ),

        # === SAVE MODE ===
        ModuleInput(
            name="weighted_keywords",
            type="array",
            required=False,
            description="Array of keyword objects. Required: keyword, weight."
        ),
        ModuleInput(
            name="accumulate_weight",
            type="boolean",
            required=False,
            default=True,
            description="If true (default), weight adds to existing. If false, replaces."
        ),

        # === LOAD MODE ===
        ModuleInput(
            name="pipeline",
            type="array",
            required=False,
            default=[],
            description="MongoDB aggregation pipeline. Only safe stages allowed."
        )
    ]
```

### 5.2 Outputs

```python
@property
def outputs(self) -> List[ModuleOutput]:
    return [
        # Load mode
        ModuleOutput(
            name="weighted_keywords",
            type="array",
            description="Array of keyword objects after pipeline"
        ),
        ModuleOutput(
            name="count",
            type="number",
            description="Number of keywords returned"
        ),

        # Save mode
        ModuleOutput(
            name="saved_count",
            type="number",
            description="Number of keywords saved/updated"
        )
    ]
```

---

## 6. Load Mode Implementation

```python
def _execute_load(self, inputs, context):
    user_pipeline = inputs.get('pipeline', [])

    # Step 1: Validate user pipeline (whitelist check)
    self._validate_pipeline(user_pipeline)

    # Step 2: Build final pipeline with enforced scope
    enforced_match = {
        "$match": {
            "workflow_template_id": context.workflow_template_id
        }
    }

    # Enforced match is ALWAYS first - user cannot bypass
    full_pipeline = [enforced_match] + user_pipeline

    # Step 3: Execute on database
    results = list(db.weighted_keywords.aggregate(full_pipeline))

    # Remove MongoDB _id from results
    for doc in results:
        doc.pop('_id', None)

    return {
        "weighted_keywords": results,
        "count": len(results)
    }
```

---

## 7. Save Mode Implementation

```python
def _execute_save(self, inputs, context):
    keywords = inputs.get('weighted_keywords', [])
    accumulate = inputs.get('accumulate_weight', True)

    if not keywords:
        return {"saved_count": 0}

    saved_count = 0
    now = datetime.utcnow()

    for kw in keywords:
        keyword_str = kw.get('keyword')
        weight = kw.get('weight', 0)

        if not keyword_str:
            continue

        # Normalize keyword
        keyword_normalized = keyword_str.lower().strip()

        # Build filter (unique key)
        filter_doc = {
            "workflow_template_id": context.workflow_template_id,
            "keyword": keyword_normalized
        }

        # Build update based on accumulate flag
        if accumulate:
            update_doc = {
                "$inc": {"weight": weight},
                "$set": {
                    "last_used": now,
                    **{k: v for k, v in kw.items() if k not in ['keyword', 'weight']}
                },
                "$setOnInsert": {"keyword": keyword_normalized}
            }
        else:
            update_doc = {
                "$set": {
                    "keyword": keyword_normalized,
                    "weight": weight,
                    "last_used": now,
                    **{k: v for k, v in kw.items() if k not in ['keyword', 'weight']}
                }
            }

        db.weighted_keywords.update_one(filter_doc, update_doc, upsert=True)
        saved_count += 1

    return {"saved_count": saved_count}
```

---

## 8. Usage Examples

### 8.1 Save Keywords

```json
{
  "module_id": "io.weighted_keywords",
  "inputs": {
    "mode": "save",
    "weighted_keywords": "{{ state.flattened_keywords }}"
  },
  "name": "save_keywords"
}
```

### 8.2 Load with Filter and Sort

```json
{
  "module_id": "io.weighted_keywords",
  "inputs": {
    "mode": "load",
    "pipeline": [
      {"$match": {"category": {"$in": ["setting", "object"]}}},
      {"$sort": {"weight": -1}},
      {"$limit": 50}
    ]
  },
  "outputs_to_state": {
    "weighted_keywords": "keyword_data"
  },
  "name": "load_keywords"
}
```

### 8.3 Load with Date Filter

```json
{
  "module_id": "io.weighted_keywords",
  "inputs": {
    "mode": "load",
    "pipeline": [
      {"$match": {
        "last_used": {"$gte": {"$dateSubtract": {"startDate": "$$NOW", "unit": "day", "amount": 7}}}
      }},
      {"$sort": {"weight": -1}}
    ]
  },
  "outputs_to_state": {
    "weighted_keywords": "recent_keywords"
  }
}
```

### 8.4 Two-Tier Exclusion (OMS)

```json
{
  "module_id": "io.weighted_keywords",
  "inputs": {
    "mode": "load",
    "pipeline": [
      {"$match": {"category": {"$in": ["setting", "object"]}}},
      {"$sort": {"weight": -1}},
      {"$limit": 100}
    ]
  },
  "outputs_to_state": {
    "weighted_keywords": "all_keywords"
  }
}
```

Then in prompt template:
```jinja2
### Critically Prohibited
{% for kw in state.all_keywords | selectattr('source', 'equalto', 'selected') %}
{{ kw.keyword }}:{{ kw.weight }}{% if not loop.last %}, {% endif %}
{% endfor %}

### Optionally Prohibited
{% for kw in state.all_keywords | selectattr('source', 'equalto', 'generated') %}
{{ kw.keyword }}:{{ kw.weight }}{% if not loop.last %}, {% endif %}
{% endfor %}
```

---

## 9. Flattening Nested Keywords

Single `transform.query` call for OMS:

```json
{
  "module_id": "transform.query",
  "inputs": {
    "data": [{"root": "{{ state.aesthetic_concepts_response }}"}],
    "pipeline": [
      {"$project": {
        "all_keywords": {
          "$concatArrays": [
            {"$reduce": {
              "input": "$root.aesthetic_concepts",
              "initialValue": [],
              "in": {"$concatArrays": ["$$value", "$$this.aesthetic_keywords"]}
            }},
            {"$reduce": {
              "input": "$root.aesthetic_concepts",
              "initialValue": [],
              "in": {"$concatArrays": [
                "$$value",
                {"$reduce": {
                  "input": "$$this.ideas",
                  "initialValue": [],
                  "in": {"$concatArrays": ["$$value", "$$this.idea_keywords"]}
                }}
              ]}
            }}
          ]
        }
      }},
      {"$unwind": "$all_keywords"},
      {"$replaceRoot": {"newRoot": "$all_keywords"}}
    ]
  },
  "outputs_to_state": {
    "result": "flattened_keywords"
  }
}
```

For CC (simpler structure):
```json
{
  "module_id": "transform.query",
  "inputs": {
    "data": "{{ state.scene_concepts.scenes }}",
    "pipeline": [
      {"$unwind": "$scene_keywords"},
      {"$replaceRoot": {"newRoot": "$scene_keywords"}}
    ]
  },
  "outputs_to_state": {
    "result": "flattened_keywords"
  }
}
```

---

## 10. Migration Plan

### Step 1: Create New Module
1. Create `server/modules/io/weighted_keywords.py`
2. Implement save with accumulate_weight
3. Implement load with stage whitelist validation

### Step 2: Database Setup
1. Create `weighted_keywords` collection
2. Add indexes
3. Migrate data from `keyword_history` if needed

### Step 3: Update CC Workflow
1. Add keyword flattening step
2. Replace `history.keyword_history` with `io.weighted_keywords`
3. Remove Jinja2 structure hacks

### Step 4: Update OMS Workflow
1. Add keyword flattening step
2. Replace `db.query` modules with `io.weighted_keywords` load
3. Replace `history.keyword_history` with `io.weighted_keywords`

### Step 5: Cleanup
1. Remove `config.keyword_history` from workflows
2. Remove `history.keyword_history` module
3. Close TECHNICAL_DEBT.md item #9

---

## 11. Files to Modify/Create

| File | Action |
|------|--------|
| `server/modules/io/weighted_keywords.py` | **CREATE** |
| `server/api/database_provider.py` | Add collection reference |
| `workflows/cc/steps/2_scene_generation/step.json` | Use new module |
| `workflows/cc/workflow_v3.json` | Remove `config.keyword_history` |
| `workflows/oms/steps/1_user_input/step.json` | Use new module |
| `workflows/oms/workflow_v3.json` | Remove `config.keyword_history` |
| `TECHNICAL_DEBT.md` | Close item #9 |
| `server/modules/history/keyword_history.py` | Remove |

---

## 12. Summary

| Aspect | Decision |
|--------|----------|
| Scoping | `workflow_template_id` only |
| Weight | Accumulate by default, `accumulate_weight=false` to replace |
| Security | Stage whitelist + block workflow_template_id override |
| Performance | Direct DB query (handles 10K+ keywords efficiently) |
| Extra fields | Pass-through (category, source, expires, etc.) |
| Collection | `weighted_keywords` (new) |
