# media.generateV2

## Summary

Current prompt-media flow is split across two modules:

1. `api.llm` builds provider prompt payloads.
2. `media.generate` renders prompts and executes generation sub-actions.

This creates contract drift between schema generation and media UX rendering.
Users also need to maintain two module configs to make one feature work.

`media.generateV2` combines prompt generation and media generation into one
editor-grid module, with one authoritative contract for provider selection,
prompt schema, display schema, and selection outputs.

## Design Decisions

### 1) Additive module id

Introduce `media.generateV2` without changing existing `media.generate`.

- keep existing workflows stable
- allow side-by-side validation

### 2) Reuse `api.llm` logic directly

V2 invokes `LLMCallModule` with constructed inputs and existing context.
V2 does not re-implement provider/model/message resolution rules.

This preserves `api.llm` behavior for:

- provider/model precedence and `ai_config`
- output-schema structured generation
- mock mode semantics

### 3) Prompt generation is mandatory in V2

V2 stays tightly coupled with internal LLM prompt generation in this revision.
No manual/non-LLM prompt source mode.

### 4) Server controls prompt output schema

Users cannot define prompt output schema structure directly. V2 synthesizes it
from selected `action_type` and providers.

### 5) Provider selection rules

- providers must be valid for selected `action_type`
- each provider can appear only once (no duplicates)
- provider list drives both prompt schema and display schema generation

### 6) Display schema ownership

Editor gives a default display schema when module is created.
Users may edit it. If they break behavior, execution fails (user-responsible);
server does not silently fall back in this revision.

### 7) Generated prompts are always exposed

`generated_prompts` is always output so workflows can map and reuse it later.

## Technical Specification

### Backend module

Add:

- `backend/workflow_engine/modules/media/generate_v2.py`

Type:

- `InteractiveModule`

Execution flow:

1. Resolve V2 inputs (`action_type`, providers, prompt config).
2. Validate provider constraints (valid set + uniqueness).
3. Build canonical prompt output schema from selected providers.
4. Construct `api.llm` inputs from V2 prompt config and canonical schema.
5. Invoke `LLMCallModule` to generate structured prompt payload.
6. Enrich prompts with `_provider_metadata` and `_generations` using current
   media generation enrichment helpers.
7. Resolve display schema (default generated + optional user-edited value).
8. Build media interaction payload with existing renderer-compatible shape.
9. Process response to return `selected_content*` and `generations`.

Sub-actions:

- reuse current task queue execution path in real mode
- reuse current mock placeholder behavior in mock mode

### V2 input contract

Required:

- `action_type`: `txt2img | img2vid | txt2audio`
- `providers`: array of unique provider ids
- `prompt_config`:
  - `provider`
  - `model` (optional)
  - `system` (standard structure)
  - `shared_user` (shared template)
  - `provider_prompts` (required prompt blocks per selected provider)
  - `ai_config` (optional)

Optional:

- `title`
- `source_image` (for `img2vid`)
- `display_schema`
- `sub_actions`
- `retryable`

### V2 output contract

- `selected_content_id`
- `selected_content`
- `generations`
- `generated_prompts`

### Prompt configuration policy

Per-provider prompt blocks are required for selected providers. Editor can
insert baseline defaults for new provider selections, but users are expected to
add workflow-specific context/examples.

### Display schema synthesis

V2 generates default display schema from selected providers and action type,
following current `tab.media[...]` and `input_schema` conventions.

## Editor Plan

Add new node implementation:

- `ui/editor/src/modules/media/generateV2/*`

Clarification: this is one module in the editor grid, but editing remains
separated by concern in the UI:

- prompt editor surface (existing prompt editor patterns, extended for
  per-provider prompt blocks)
- display schema editor surface

This keeps UX understandable while maintaining one runtime module contract.

## API Contracts

### Workflow module JSON

- `module_id: "media.generateV2"`

### Interaction payload shape

V2 keeps current media interaction payload conventions:

- `display_data.data`
- `display_data.schema`
- `display_data.sub_actions`
- `display_data.generations`
- `display_data.retryable`

Generated prompts must be present in interaction data where needed to keep UX
parity with current media generation experience.

### Mock mode

V2 follows existing mock execution context behavior across prompt generation and
media sub-actions.

## Database Schema

No DB migration required for initial V2 rollout.
Existing task queue and content metadata persistence are reused.

## Cross-Module Impact

### Backend

- new `media.generateV2` module
- direct reuse of `LLMCallModule`
- shared helper extraction from `media.generate` as needed

### Editor

- new V2 module registration + node UI
- keep existing `media.generate` editor for compatibility

### Workflows

- new workflows should use V2
- existing workflows continue unchanged

## Rollout Plan

1. Implement backend `media.generateV2` and `LLMCallModule` invocation path.
2. Implement editor node for V2 with unique-provider enforcement.
3. Extend prompt editor for required per-provider prompt blocks.
4. Add one CC pilot step using V2.
5. Validate mock mode, retry loop, sub-actions, and UX parity.

## Questions for Review

1. Should provider prompt blocks support a shared fallback when a provider block
   is empty, or should empty block be a hard validation error?

   <!--since user is required to add shared prompt which meant to include
   details of what image prompts should be in static context, we can just say
   that when provider doesnt have prompt, as it to use shared instructions-->

2. Should V2 emit `generated_prompts` into both interaction payload and module
   outputs, or only outputs with UI deriving from the same source in memory?

   <!--correct me if i am wrong here, generated_prompts has to be included in
   interaction reqyest -> data for ui to render prompts using display schema.
   for state, we can set it to state variable user define (or default value)-->
