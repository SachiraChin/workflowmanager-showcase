# media.generateV2

## Summary

Current prompt-media flow is split across two modules:

1. `api.llm` builds provider prompt payloads.
2. `media.generate` renders prompts and executes generation sub-actions.

This split causes contract drift across module boundaries and forces users to
maintain two configurations for one feature.

`media.generateV2` combines prompt generation and media generation into one
editor-grid module with one contract for providers, prompt schema, display
schema, and selection outputs.

## Design Decisions

### 1) Additive module id

Introduce `media.generateV2` without changing existing `media.generate`.

- existing workflows remain stable
- V2 can roll out incrementally

### 2) Reuse `api.llm` logic directly

V2 invokes `LLMCallModule` with constructed inputs/context. V2 does not
re-implement provider/model/message precedence behavior.

### 3) Prompt generation is mandatory in V2

V2 is tightly coupled to internal LLM prompt generation in this revision.
No manual/non-LLM prompt mode.

### 4) Server controls prompt output schema

Users cannot redefine prompt output schema structure. V2 synthesizes strict
schema from `action_type` + selected providers.

### 5) Provider selection rules

- providers must be valid for `action_type`
- providers are unique (no duplicate instances)
- provider set drives prompt and display schema generation

### 6) Display schema ownership

Editor provides default display schema at module creation.
Users may edit it and are responsible for resulting validity.

### 7) Generated prompts exposure

`generated_prompts` is always produced for downstream state mapping and reuse.

### 8) Shared prompt reference semantics

Provider prompts do not text-replace shared prompt content.

Shared instructions are emitted before provider-specific prompts. Provider
prompts should reference shared instructions via explicit reference key/tokens,
not by implicit content substitution.

## Technical Specification

### Backend module

Add:

- `backend/workflow_engine/modules/media/generate_v2.py`

Type:

- `InteractiveModule`

Execution flow:

1. Resolve inputs (`action_type`, providers, prompt config).
2. Validate provider validity + uniqueness.
3. Build canonical prompt output schema from providers.
4. Build `api.llm` inputs from prompt config + canonical schema.
5. Invoke `LLMCallModule` for structured prompt generation.
6. Enrich prompt payload with `_provider_metadata` and `_generations`.
7. Resolve display schema (generated default + user-edited schema).
8. Build media interaction payload for existing renderer shape.
9. Process response into `selected_content*` and `generations` outputs.

Sub-actions:

- reuse current task queue execution in real mode
- reuse current placeholder behavior in mock mode

### V2 input contract

Required:

- `action_type`: `txt2img | img2vid | txt2audio`
- `providers`: array of unique provider ids
- `prompt_config`:
  - `provider`
  - `model` (optional)
  - `system`
  - `shared_user`
  - `provider_prompts`
  - `ai_config` (optional)

Optional:

- `title`
- `source_image` (for `img2vid`)
- `display_schema`
- `sub_actions`
- `retryable`

### Prompt reference contract

`shared_user` defines common instructions.

Each `provider_prompts.<provider>` is a provider-specific prompt block. If a
provider block is missing, V2 generates a baseline provider block that includes
an explicit reference token to shared instructions.

Proposed reference token example:

- `{{shared_prompt_ref}}`

At render time, V2 builds prompt messages in deterministic order:

1. shared instructions block
2. provider-specific block(s) containing explicit shared reference token(s)

This keeps semantics clear and avoids hidden text substitution.

### V2 output contract

- `selected_content_id`
- `selected_content`
- `generations`
- `generated_prompts`

### Interaction data contract

`generated_prompts` must be present in interaction data for UI rendering with
display schema and must also be present in module outputs for state mapping.

## Editor Plan

Add node implementation:

- `ui/editor/src/modules/media/generateV2/*`

One module in grid, two editing surfaces:

- prompt editor surface (shared + provider blocks)
- display schema editor surface

Editor enforces unique provider selection and action-type compatibility.

## Database Schema

No DB migration required for initial V2 rollout.
Existing task queue/content metadata persistence are reused.

## API Contracts

### Workflow module JSON

- `module_id: "media.generateV2"`

### Interaction payload shape

V2 keeps current media interaction payload conventions:

- `display_data.data`
- `display_data.schema`
- `display_data.sub_actions`
- `display_data.generations`
- `display_data.retryable`

## Rollout Plan

1. Implement backend `media.generateV2` with `LLMCallModule` invocation.
2. Implement editor node for V2 with provider uniqueness checks.
3. Extend prompt editor for shared + provider prompt blocks.
4. Pilot one CC step with V2.
5. Validate mock mode, retry loop, sub-actions, and UX parity.

## Questions for Review

1. Confirm reference token shape for shared prompt reference.
   Example: `{{shared_prompt_ref}}`.
   <!--agreed-->

2. Should missing provider prompt block be auto-created at save time, or only
   at module creation/provider-add time?

   <!--lets make it so that all provider prompts get above text as soon as user
   delete content, and user delete that too, well, we dont include a provider
   promop-->
